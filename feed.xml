<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://jaeheon-lee486.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jaeheon-lee486.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-06-22T07:51:54+00:00</updated><id>https://jaeheon-lee486.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">[Paper Review] Learning efficient task-dependent representations with synaptic plasticity</title><link href="https://jaeheon-lee486.github.io/blog/2025/paper-review-learning-efficient-task-dependent-representations-with-synaptic-plasticity/" rel="alternate" type="text/html" title="[Paper Review] Learning efficient task-dependent representations with synaptic plasticity"/><published>2025-06-22T07:37:08+00:00</published><updated>2025-06-22T07:37:08+00:00</updated><id>https://jaeheon-lee486.github.io/blog/2025/paper-review-learning-efficient-task-dependent-representations-with-synaptic-plasticity</id><content type="html" xml:base="https://jaeheon-lee486.github.io/blog/2025/paper-review-learning-efficient-task-dependent-representations-with-synaptic-plasticity/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">[Probabilistic Machine Learning] Gaussian Process</title><link href="https://jaeheon-lee486.github.io/blog/2025/probabilistic-machine-learning-gaussian-process/" rel="alternate" type="text/html" title="[Probabilistic Machine Learning] Gaussian Process"/><published>2025-04-26T13:58:17+00:00</published><updated>2025-04-26T13:58:17+00:00</updated><id>https://jaeheon-lee486.github.io/blog/2025/probabilistic-machine-learning-gaussian-process</id><content type="html" xml:base="https://jaeheon-lee486.github.io/blog/2025/probabilistic-machine-learning-gaussian-process/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">[Paper Review] Disentangling Representations through Multi-task Learning</title><link href="https://jaeheon-lee486.github.io/blog/2025/paper-review-disentangling-representations-through-multi-task-learning/" rel="alternate" type="text/html" title="[Paper Review] Disentangling Representations through Multi-task Learning"/><published>2025-04-22T12:21:51+00:00</published><updated>2025-04-22T12:21:51+00:00</updated><id>https://jaeheon-lee486.github.io/blog/2025/paper-review-disentangling-representations-through-multi-task-learning</id><content type="html" xml:base="https://jaeheon-lee486.github.io/blog/2025/paper-review-disentangling-representations-through-multi-task-learning/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">[Paper Review] Competition Dynamics Shape Algorithmic Phases of In-Context Learning</title><link href="https://jaeheon-lee486.github.io/blog/2025/paper-review-competition-dynamics-shape-algorithmic-phases-of-in-context-learning/" rel="alternate" type="text/html" title="[Paper Review] Competition Dynamics Shape Algorithmic Phases of In-Context Learning"/><published>2025-04-22T12:17:57+00:00</published><updated>2025-04-22T12:17:57+00:00</updated><id>https://jaeheon-lee486.github.io/blog/2025/paper-review-competition-dynamics-shape-algorithmic-phases-of-in-context-learning</id><content type="html" xml:base="https://jaeheon-lee486.github.io/blog/2025/paper-review-competition-dynamics-shape-algorithmic-phases-of-in-context-learning/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">[Paper Review] Signatures of Criticality in Efficient Coding Networks</title><link href="https://jaeheon-lee486.github.io/blog/2025/paper-review-signatures-of-criticality-in-efficient-coding-networks/" rel="alternate" type="text/html" title="[Paper Review] Signatures of Criticality in Efficient Coding Networks"/><published>2025-03-07T17:42:41+00:00</published><updated>2025-03-07T17:42:41+00:00</updated><id>https://jaeheon-lee486.github.io/blog/2025/paper-review-signatures-of-criticality-in-efficient-coding-networks</id><content type="html" xml:base="https://jaeheon-lee486.github.io/blog/2025/paper-review-signatures-of-criticality-in-efficient-coding-networks/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">[Paper Review] Recurrence resonance - noise-enhanced dynamics in recurrent neural networks</title><link href="https://jaeheon-lee486.github.io/blog/2025/paper-review-recurrence-resonance-noise-enhanced-dynamics-in-recurrent-neural-networks/" rel="alternate" type="text/html" title="[Paper Review] Recurrence resonance - noise-enhanced dynamics in recurrent neural networks"/><published>2025-03-07T10:42:54+00:00</published><updated>2025-03-07T10:42:54+00:00</updated><id>https://jaeheon-lee486.github.io/blog/2025/paper-review-recurrence-resonance---noise-enhanced-dynamics-in-recurrent-neural-networks</id><content type="html" xml:base="https://jaeheon-lee486.github.io/blog/2025/paper-review-recurrence-resonance-noise-enhanced-dynamics-in-recurrent-neural-networks/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">[Paper Review] Fragmentation of grid cell maps in a multicompartment environment</title><link href="https://jaeheon-lee486.github.io/blog/2025/paper-review-fragmentation-of-grid-cell-maps-in-a-multicompartment-environment/" rel="alternate" type="text/html" title="[Paper Review] Fragmentation of grid cell maps in a multicompartment environment"/><published>2025-02-23T11:02:37+00:00</published><updated>2025-02-23T11:02:37+00:00</updated><id>https://jaeheon-lee486.github.io/blog/2025/paper-review-fragmentation-of-grid-cell-maps-in-a-multicompartment-environment</id><content type="html" xml:base="https://jaeheon-lee486.github.io/blog/2025/paper-review-fragmentation-of-grid-cell-maps-in-a-multicompartment-environment/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">[Probabilistic Machine Learning] Hidden Markov Model (forward-backward algorithm)</title><link href="https://jaeheon-lee486.github.io/blog/2025/probabilistic-machine-learning-hidden-markov-model-forward-backward-algorithm/" rel="alternate" type="text/html" title="[Probabilistic Machine Learning] Hidden Markov Model (forward-backward algorithm)"/><published>2025-02-23T09:08:37+00:00</published><updated>2025-02-23T09:08:37+00:00</updated><id>https://jaeheon-lee486.github.io/blog/2025/probabilistic-machine-learning-hidden-markov-model-forward-backward-algorithm</id><content type="html" xml:base="https://jaeheon-lee486.github.io/blog/2025/probabilistic-machine-learning-hidden-markov-model-forward-backward-algorithm/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">[Paper Review] Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space</title><link href="https://jaeheon-lee486.github.io/blog/2025/paper-review-emergence-of-hidden-capabilities-exploring-learning-dynamics-in-concept-space/" rel="alternate" type="text/html" title="[Paper Review] Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space"/><published>2025-02-06T14:00:14+00:00</published><updated>2025-02-06T14:00:14+00:00</updated><id>https://jaeheon-lee486.github.io/blog/2025/paper-review-emergence-of-hidden-capabilities-exploring-learning-dynamics-in-concept-space</id><content type="html" xml:base="https://jaeheon-lee486.github.io/blog/2025/paper-review-emergence-of-hidden-capabilities-exploring-learning-dynamics-in-concept-space/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">[Paper Review] Approximation and Optimization Theory for Linear Continuous-Time Recurrent Neural Networks</title><link href="https://jaeheon-lee486.github.io/blog/2025/paper-review-approximation-and-optimization-theory-for-linear-continuous-time-recurrent-neural-networks/" rel="alternate" type="text/html" title="[Paper Review] Approximation and Optimization Theory for Linear Continuous-Time Recurrent Neural Networks"/><published>2025-01-30T08:03:41+00:00</published><updated>2025-01-30T08:03:41+00:00</updated><id>https://jaeheon-lee486.github.io/blog/2025/paper-review-approximation-and-optimization-theory-for-linear-continuous-time-recurrent-neural-networks</id><content type="html" xml:base="https://jaeheon-lee486.github.io/blog/2025/paper-review-approximation-and-optimization-theory-for-linear-continuous-time-recurrent-neural-networks/"><![CDATA[]]></content><author><name></name></author></entry></feed>