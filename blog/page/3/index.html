<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>blog - page 3 | JaeHeon Lee</title> <meta name="author" content="JaeHeon Lee"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ğŸ§ </text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://jaeheon-lee486.github.io/blog/page/3/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">JaeHeon&nbsp;</span>Lee</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <div class="header-bar"> <h1>al-folio</h1> <h2>a simple whitespace theme for academics</h2> </div> <div class="tag-category-list"> <ul class="p-0 m-0"> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/formatting">formatting</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/images">images</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/links">links</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/math">math</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/code">code</a> </li> <p>&bull;</p> <li> <i class="fas fa-tag fa-sm"></i> <a href="/blog/category/blockquotes">blockquotes</a> </li> </ul> </div> <br> <div class="container featured-posts"> <div class="row row-cols-2"> <div class="card-item col"> <a href="/blog/2021/distill/"> <div class="card hoverable"> <div class="row g-0"> <div class="col-md-12"> <div class="card-body"> <div class="float-right"> <i class="fa-solid fa-thumbtack fa-xs"></i> </div> <h3 class="card-title text-lowercase">a distill-style blog post</h3> <p class="card-text">an example of a distill-style blog post and main elements</p> <p class="post-meta"> 8 min read &nbsp; &middot; &nbsp; <a href="/blog/2021"> <i class="fas fa-calendar fa-sm"></i> 2021 </a> </p> </div> </div> </div> </div> </a> </div> <div class="card-item col"> <a href="/blog/2015/code/"> <div class="card hoverable"> <div class="row g-0"> <div class="col-md-12"> <div class="card-body"> <div class="float-right"> <i class="fa-solid fa-thumbtack fa-xs"></i> </div> <h3 class="card-title text-lowercase">a post with code</h3> <p class="card-text">an example of a blog post with some code</p> <p class="post-meta"> 4 min read &nbsp; &middot; &nbsp; <a href="/blog/2015"> <i class="fas fa-calendar fa-sm"></i> 2015 </a> </p> </div> </div> </div> </div> </a> </div> </div> </div> <hr> <ul class="post-list"> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-DTFD-MIL-Double-Tier-Feature-Distillation-Multiple-Instance-Learning-for-Histopathology-Whole-Slide-Image-Classification" target="_blank">[Paper Review] DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="dtfd-mil-double-tier-feature-distillation-multiple-instance-learning-for-histopathology-whole-slide-image-classification">DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/442c4d14-8171-4395-baa2-84c699b3d18e/image.png" alt=""></p> <p>íŠ¹ì • dataset ì— ëŒ€í•´, MIL SOTA ì¹­í˜¸ë¥¼ ì–»ì€ ë…¼ë¬¸ì´ë‹¤. ë‹¤ë¥¸ ë…¼ë¬¸ì—ì„œ SOTA ë¡œì¨ ì¸ìš©ë˜ê¸°ë„ í•˜ê³  ì•„ì´ë””ì–´ë„ reasonable í•´ë³´ì´ê³  ì½”ë“œë„ ê³µê°œë˜ì–´ ìˆì–´ì„œ ê°€ì ¸ë‹¤ ì¨ë³´ë ¤ í•œë‹¤. (ì´ë¯¸ ëˆ„ê°€ ëŒë ¤ë´¤ë‹¤) í•µì‹¬ ì•„ì´ë””ì–´ëŠ” psudo-bag ì„ í†µí•´ number of bag ì„ ëŠ˜ë¦° ê²ƒ, ëŠ˜ë ¤ ë°œìƒí•œ ë¬¸ì œë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ double-tier êµ¬ì¡°ë¥¼ ì°©ì•ˆí•œ ê²ƒì— ìˆë‹¤. </p> <h2 id="introduction">Introduction</h2> <ul> <li>WSI ë¶„ì„ê³¼ MIL ë“±ì¥ ë°°ê²½</li> <li>ABMIL ê´€ë ¨ ì„œìˆ </li> <li>instance probability inference ê°€ infeasible í•˜ë‹¤ ì—¬ê²¨ì ¸ ì™”ê³ , ì°¨ì„ ì±…ìœ¼ë¡œ attention score ë¥¼ ì‚¬ìš©í•´ì˜´.</li> <li>ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ABMIL framework ì—ì„œ instance probability ë¥¼ derive í•¨.</li> <li>mutual-instance relation ê³¼ over-fitting problem ê°„ì— trade-off ê°€ ìˆìŒ.</li> <li>negative impact ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ pseudo-bag ì„ ë§Œë“¦.</li> <li>ì´ë¡œë¶€í„° ë°œìƒí•˜ëŠ” risk ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´, Grad-CAM ì„ í™œìš©í•œ double-tier MIL êµ¬ì¡°ë¥¼ ê³ ì•ˆí•¨.</li> </ul> <h2 id="method">Method</h2> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/55f134f7-2e94-4e72-a082-dc8b1d3f7233/image.png" alt=""></p> <h3 id="revisit-grad-cam-and-ab-mil">Revisit Grad-CAM and AB-MIL</h3> <h4 id="grad-cam">Grad-CAM</h4> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/21f7e061-cdfe-481d-9f0a-cac6a32ccb2d/image.png" alt=""></p> <p>end-to-end image classification ì—ì„œ DCNN ì˜ high level feature map DxWxH (D: number of channel, W,H dimension)ì„ global average pooling ì„ ê±°ì³ channel D dimension ì„ ê°€ì§„ feature ë¥¼ ì–»ëŠ”ë‹¤. ì´ ë•Œ f ë¥¼ MLP ì— í†µê³¼ì‹œí‚¤ê³  logit $s^c$ for class c (1,2,...,C) ë¥¼ ì–»ëŠ”ë°, ì•„ë˜ ì‹ì„ ê±°ì³ Grad-CAMì˜ class activation map ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/b0b93913-cd51-4de2-9d9c-4caf4615ba34/image.png" alt=""></p> <p>ì¦‰, softmax ì™€ input f ì— ì˜í•´ ê²°ì •ëœ signal strength ë¡œì¨ image ê°€ ê° class Cì— í•´ë‹¹í•  probability ë¥¼ ê³„ì‚°í•˜ê³ , ì•„ë˜ ì‹ê³¼ ê°™ì´ íŠ¹ì • ìœ„ì¹˜ì—ì„œ íŠ¹ì • class ì— ëŒ€í•´ ì–¼ë§ˆë‚˜ ì‹ í˜¸ê°€ ê°•í•œì§€ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆê²Œ ëœë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/c927a2b8-8450-42bf-9e50-6b3a8c70ca37/image.png" alt=""></p> <h3 id="attention-based-multiple-instance-learning">Attention-Based Multiple Instance Learning</h3> <p>ì•ì„  í¬ìŠ¤íŒ…ì—ì„œ ë§ì´ ì–¸ê¸‰ë˜ì—ˆë˜ ë‚´ìš©ì´ë¼ ê°„ë‹¨íˆ ìˆ˜ì‹ë“¤ë§Œ ì–¸ê¸‰í•˜ë„ë¡ í•˜ê² ë‹¤. Bag label - bag representation, bag classification task <img src="https://velog.velcdn.com/images/jaeheon-lee/post/f0457347-d604-4c29-85de-bc9759d05340/image.png" alt=""></p> <p>$G$ is an aggregation function, $h_k$: extracted feature for instance $k$ <img src="https://velog.velcdn.com/images/jaeheon-lee/post/dda8fbe0-ca09-44d1-89d4-fc1702aa0886/image.png" alt=""></p> <p>$a_k$ learnable scalar weight for $h_k$, D: dimension of vector $F$ and $h_k$ <img src="https://velog.velcdn.com/images/jaeheon-lee/post/ce78109e-0ba3-451d-928e-28c6a7de423a/image.png" alt=""></p> <p>weight from the classific AB-MIL, where $w, V_1, V_2$ are the learnable parameters <img src="https://velog.velcdn.com/images/jaeheon-lee/post/87c80dbc-89db-4a73-94d9-48af00a0498f/image.png" alt=""></p> <h3 id="derivation-of-instance-probability-in-ab-mil">Derivation of Instance Probability in AB-MIL</h3> <p>ë³¸ ë…¼ë¬¸ì—ì„œ í•µì‹¬ ë‚´ìš© ì¤‘ í•˜ë‚˜ì´ë‹¤. ìœ„ì—ì„œ ì–¸ê¸‰í•´ì™”ë“¯ attention score ì„ class probability ë¡œ ëŒ€ì‹  ì‚¬ìš©í•´ì™”ê³ , ì´ë¥¼ ê·¹ë³µí•˜ê³ ì AB-MIL framework ê°€ ê°€ì§€ëŠ” íŠ¹ìˆ˜ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ individual instance ì˜ predicted class probaility ë¥¼ ìœ ë„í•œë‹¤. ë‹¤ìŒ proposition ìœ„ì—ì„œ derivation ì´ ì´ë£¨ì–´ì§„ë‹¤.</p> <p><strong>Proposition 1</strong> The paradigm of AB-MIL is a special case of the framework of the classic deep-learning network for image classification </p> <p>supplmentary ì— proposition1 ì˜ ì¦ëª…ê³¼ ì„¤ëª…ì´ ìˆë‹¤. ì €ìì˜ ë…¼ë¦¬ëŠ” ì´ proposition 1 ì— ê¸°ì´ˆí•˜ì—¬, Grad-CAM ì˜ mechanism ì„ AB-MIL ì— ë°”ë¡œ ì ìš©í•˜ì—¬, ê° instance ì˜ signal strength ë¥¼ Grad-CAMê³¼ ê°™ì´ derive í•  ìˆ˜ ìˆë‹¤ê³  í•œë‹¤. </p> <p>supplementary ì˜ ì¦ëª…ì´ë¼ê³  í•˜ê¸°ì—” ì• ë§¤í•œ ì„¤ëª…ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. </p> <ul> <li>$F = \sum_{k=1}^Ka_kh_k = \frac{1}K\sum_{k=1}^Ka_kKh_k=\frac{1}K\sum_{k=1}^K\hat{h}_k$ : AB-MIL ì€ averaging pooling ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.</li> <li>$f =\frac{1}{W,H}\sum_{w,h}^{W,H}u_{w,h}$ : deep learning ì—ì„œì˜ GAPë„ ë‹¤ìŒê³¼ ê°™ì´ ì“¸ ìˆ˜ ìˆë‹¤</li> <li>deep learning ê³¼ MIL ëª¨ë‘ ë„“ê²Œ ë³´ë©´ classification problem ì´ë‹¤</li> <li>F ì™€ f ì˜ ìœ ì¼í•œ ì°¨ì´ëŠ” spatial relation ì´ Fì—ëŠ” ê³ ë ¤ë˜ì§€ ì•Šì•˜ë‹¤ëŠ” ì ì´ë‹¤.</li> <li>í•˜ì§€ë§Œ Grad-CAM ì—ì„œ attention map inference ëŠ” spatial relation ì´ ì•„ë¬´ ì—­í• ì„ í•˜ì§€ ì•ŠëŠ”ë‹¤</li> <li>ê·¸ëŸ¬ë¯€ë¡œ, DCNN ì—ì„œ signal strength ë¥¼ ë‚˜íƒ€ë‚´ëŠ” Grad-CAM ì‹ ì²˜ëŸ¼ </li> </ul> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/b0b93913-cd51-4de2-9d9c-4caf4615ba34/image.png" alt=""></p> <ul> <li>AB-MIL ì—ì„œ ê° instance ì˜ signal strength ë‚˜íƒ€ë‚´ëŠ” Grad-CAM ì‹ì„ ì•„ë˜ì²˜ëŸ¼ ì“¸ ìˆ˜ ìˆë‹¤</li> </ul> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/caef0deb-b182-41a3-b948-cc2b079b5844/image.png" alt=""></p> <p>ë³´ë©´, U ê°€ h ë¡œ ë°”ë€Œì—ˆê³ , $S^c$ ëŠ” output logic for class c from MIL classifier ì´ë‹¤. ì´ ì‹ì— softmax ë¥¼ ì ìš©í•˜ì—¬ pë¥¼ êµ¬í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/e1d9186a-0ad7-40b2-93f6-557829d210a9/image.png" alt=""></p> <p>supplementary ì— ë‚˜ì˜¨ ì„¤ëª…ì„ ë§ë¶™ì´ìë©´, ì´ ì‹ì€ instance ê°€ large enough attention score ë¥¼ ê°€ì§€ê³  ìˆì„ ë•Œë§Œ ìœ íš¨í•œ ê°’ì„ ê°€ì§„ë‹¤. ê·¸ ì´ìœ ëŠ”, certain patch ê°€ attention module ì—ì„œ deactivate ë˜ì–´ $a_k$ê°’ì´ 0ì— ê°€ê¹Œì›Œì§€ë©´, ê·¸ì— í•´ë‹¹í•˜ëŠ” $\hat{h}_k$ë„ 0ì— ê°€ê¹Œì›Œì§€ê³ , ì´ì— ë”°ë¼ $L_k^c$ëŠ” ëª¨ë“  classì— ëŒ€í•´ 0, $p_k^c$ ëŠ” ì •ë³´ëŸ‰ì´ ì—†ëŠ” 0.5ì— ê°€ê¹Œì›Œ ì§ˆ ê²ƒì´ê¸° ë•Œë¬¸ì´ë‹¤. ì´ëŸ° ì  ë•Œë¬¸ì— pseudo-bag ì„ ë§Œë“¤ê³  attention score ì— ë”°ë¥¸ patch selection ì‚¬ì „ì‘ì—…ì´ ì´ë£¨ì–´ ì¡Œë‹¤ëŠ” ì ì„ ì–¸ê¸‰í•˜ê³  ìˆë‹¤.</p> <h3 id="double-tier-feature-distillation-multiple-instance-learning">Double-Tier Feature Distillation Multiple Instance Learning</h3> <p>double-tier feature distillation MIL framework ì— ëŒ€í•´ ìì„¸íˆ ì–¸ê¸‰í•œë‹¤. ì—¬ê¸°ë¶€í„°ëŠ” í¬ê²Œ ì–´ë ¤ìš´ ë¶€ë¶„ì€ ì—†ë‹¤. ë‹¤ë§Œ notation ì´ ë§ì•„ì„œ ì¢€ í—·ê°ˆë¦°ë‹¤. ê·¸ë¦¼ ë³´ë©´ì„œ ë³´ì.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/442c4d14-8171-4395-baa2-84c699b3d18e/image.png" alt=""></p> <ul> <li>Given N bags (slides), each bag there are Kn instances (k=1,2, ..., Kn), (n=1, ..., N)</li> <li>i.e., $X_n = {x_{n,k}|k=1,2,...,K_n} ,n\in {1,2,...,N}$ with ground truth of bag $Y_n$</li> <li>feature of a patch, denoted as $h_{n,k}=H(x_{n,k})$</li> <li>randomly split into $M$ pseudo-bags, $X_n ={X_n^m | m=1,2,...,M}$</li> <li>inTier-1 model (AB-MIL model), estimated bag probability of pseudo-bag: $y^m_n$</li> </ul> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/f4128cf1-6f3a-41be-b3d0-772d794dc1a9/image.png" alt=""></p> <ul> <li>loss: cross-entropy L1</li> <li>in Tier-2, feature from each pseudo-bag is distilled, as $\hat{f}_n^m$</li> <li>ì´ë•Œ, ì°¸ê³ ë¡œ pseudo-bag mê°œì—ì„œ ë‚˜ì˜¨ feature ê°€ aggregation ë˜ì—ˆë‹¤.</li> </ul> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/ae7f6fd8-657d-462f-a33d-606a990c4f58/image.png" alt=""></p> <ul> <li>ì´ ë˜í•œ cross-entropy L2</li> <li>overall optimization process ëŠ” L1+L2 ê¼´</li> </ul> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/87123ba6-b621-4961-a5e3-c4b2f99b51c6/image.png" alt=""></p> <ul> <li>aggregation function ì€ ë‹¤ìŒ 4ê°€ì§€ë¡œ êµ¬ì„±ë¨ 1) Maximum selection 2) Maximum &amp; Minimum selection 3) Maximum attention score selection 4) Aggregated feature selection (attention ì¨ì„œ)</li> </ul> <h2 id="experiments">Experiments</h2> <h3 id="datasets">Datasets</h3> <p>two public histopathology WSI dataset</p> <ul> <li>CAMELYON-16</li> <li>TCGA lung cancer</li> <li>OTSU tissue, non-overlapping 256x256 patch on 20X mag, 3.7M + 8.3M patches</li> </ul> <h3 id="performance-comparison-with-existing-works">Performance comparison with existing works</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/35064373-1f14-46fe-9ea8-899ad64239b7/image.png" alt=""></p> <p>CAMELYON-16ì€ ëŒ€ë¶€ë¶„ ìŠ¬ë¼ì´ë“œì—ì„œ small portion of tumor ì´ê³ , MaxS ë°©ì‹ì´ ê°€ì¥ inferior í–ˆì§€ë§Œ ì—¬ì „íˆ ë‹¤ë¥¸ ëª¨ë¸ì— ë¹„í•´ì„œëŠ” ì„±ëŠ¥ì´ ì¢‹ì•˜ë‹¤. DTFD-MIL (AFS) ëŠ” 4% better on AUC.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/a58b74f2-c375-4975-a809-958204220cad/image.png" alt=""></p> <p>TCGA-lung cancer ì—ì„œ AUC 96.1% ë¥¼ ë³´ì—¬ì£¼ì—ˆë‹¤. ì—¬ê¸°ì„  attention ì„ ì“°ì§€ ì•Šì€ instance-level feature ì˜ MaxMinS ë°©ì‹ì—ì„œ ì„±ëŠ¥ì´ ì œì¼ ë†’ì•˜ëŠ”ë°, ì´ë¥¼ TCGA ì˜ large tumor region ê°€ ì›ì¸ì´ë¼ ì„¤ëª…í•œë‹¤. </p> <h3 id="visualization-of-detection-results">Visualization of Detection Results</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/c44604ba-6797-4d6a-aae1-9e26fb003cc0/image.png" alt=""></p> <p>ì˜¤í˜¸ Grad-CAM probability ì¨ì„œ ê·¸ëŸ°ì§€ í™•ì‹¤íˆ ê¸°ì¡´ attention score ì“°ë˜ê±°ë³´ë‹¤ ë‚«ë‹¤. ë…¼ë¬¸ì—ì„œë„ ë¹„ìŠ·í•˜ê²Œ ì–˜ê¸°í•œë‹¤.</p> <h2 id="conclusion">Conclusion</h2> <ul> <li>derivation of instance probability under framework of AB-MIL</li> <li>qualitatively demonstrate the derived instance probability was more reliable</li> </ul> <p>survival ì— ë¶™ì—¬ì„œ ë¹¨ë¦¬ ì½”ë“œ ëŒë ¤ë´ì•¼ í•˜ëŠ”ë°... ë‹¤ë¥¸ ì¥ê¸°ì—ì„œë„ í†µí–ˆìœ¼ë©´ ì¢‹ê² ë‹¤.</p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; April 15, 2023 &nbsp; &middot; &nbsp; jaeheon-lee </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-Exploring-Visual-Prompts-for-Whole-Slide-Image-Classification-with-Multiple-Instance-Learning" target="_blank">[Paper Review] Exploring Visual Prompts for Whole Slide Image Classification with Multiple Instance Learning</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="exploring-visual-prompts-for-whole-slide-image-classification-with-multiple-instance-learning">Exploring Visual Prompts for Whole Slide Image Classification with Multiple Instance Learning</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/bb7a88f5-20cb-47cf-b9bb-f501a9a13242/image.png" alt=""></p> <p>í›ˆë ¨ì†Œì— ë‹¤ë…€ì™”ë‹¤. 3ì£¼ ë‹¤ë…€ì™”ëŠ”ë° ì˜ ì•ˆ ì½íˆê³  ë°”ë³´ê°€ ëœ ê¸°ë¶„ì´ë‹¤. ê·¸ë˜ë„ í•´ì•¼ì§€. ì´ë²ˆ ë…¼ë¬¸ì€ WSI analysis ì—ì„œ ìì£¼ ì“°ì´ëŠ” Multiple Instance Learning ë¶„ì•¼ì˜ ë‚˜ì˜¨ì§€ ì–¼ë§ˆ ì•ˆëœ ë”°ëˆë”°ëˆí•œ ë…¼ë¬¸ì´ë‹¤. ë³‘ë¦¬ ìª½ì—ì„œëŠ” natural image (ex ImageNet) ë¡œ pretrain ëœ ëª¨ë¸ì„ backbone ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ê°€ ë§ì€ë°, ì´ëŸ¬í•œ pretrained model ì„ promopt learning ë°©ì‹ìœ¼ë¡œ ë¹„êµì  ì ì€ cost ë¡œ fine-tuning í•´ì„œ MIL ì„±ëŠ¥ì„ ë†’ì˜€ë‹¤ëŠ” ì—°êµ¬ì´ë‹¤.</p> <h2 id="introduction">Introduction</h2> <ul> <li>WSI ë¶„ì„ì— Multiple Instance Learning (MIL) ë§ì´ ì”€</li> <li>frozen feature extractor pretrain í•´ì„œ ì‚¬ìš©í•˜ì§€ë§Œ, overlook domain shift issue</li> <li>fine-tuning feature extractor ëŠ” large-scale dataset ì—ì„œ í•™ìŠµëœ ëª¨ë¸ì„ ì†ìƒí•  ìˆ˜ ìˆìŒ.</li> <li>NLPì—ì„œ ì˜ê°ë°›ì€ prompt learning ì„ ë³‘ë¦¬ì— ì ìš©í•˜ì—¬ improve performance, achieve domain transformation</li> </ul> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/945b2e10-5976-47f1-ad83-455ee263a35a/image.png" alt=""></p> <p>how?</p> <p>1) introduce visual promopts into WSI classification 2) end-to-end promopt training, involves representative patch selection 3) extensive validation experiment with Camelyon16, TCGA-NSCLC</p> <h2 id="method">Method</h2> <p>ì•„ë˜ ê·¸ë¦¼ì²˜ëŸ¼ ì„¸ step ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì„¤ëª…í•˜ê³  ìˆë‹¤.</p> <p>1) MIL classifier training 2) representative patch selection 3) promopt fine-tuning</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/bb7a88f5-20cb-47cf-b9bb-f501a9a13242/image.png" alt=""></p> <h3 id="attention-based-mil-classifier-with-frozen-feature-extractor">Attention-based MIL Classifier with Frozen Feature Extractor</h3> <p>attention-based MIL (ABMIL) ë°©ì‹ì—ì„œëŠ” ë‹¤ìŒ ì„¸ ì‹ìœ¼ë¡œ ìš”ì•½í•  ìˆ˜ ìˆë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/ff86cc84-9238-4b1e-9393-8acede2df4d1/image.png" alt=""></p> <p>FëŠ” attention-weighted average of all patch features in WSI, </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/2d890433-ca8b-4b8a-bc3e-21a0d7e5bc63/image.png" alt=""></p> <p>w, V1, V2 ëŠ” learnable parameters in MIL classifier. (gated attention ì´êµ°ìš”) ì´ë¥¼ ë‹¤ì‹œ MIL classifier h ì— ë„£ì–´ì„œ ìµœì¢… prediction of WSI label ì„ ë§Œë“¤ê³  CE loss ë¥¼ êµ¬í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/72e9fe6d-6a73-4840-977c-8f2deafb33c8/image.png" alt=""></p> <p>minimize the prediction error í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ MIL classifier ë¥¼ í•™ìŠµí•¨.</p> <h3 id="representative-patch-selection">Representative Patch Selection</h3> <ul> <li>ë°°ê²½: Camelyon16 ê´€ì‹¬ìˆëŠ” ì•” ì˜ì—­ì´ WSI ì „ì²´ì—ì„œ 10% ì´í•˜ì„. </li> <li>ë‚´ìš©: select top-K patches with highest attention score (K=200)</li> <li>íš¨ê³¼: reduce vast quantities of patches --&gt; enable end-to-end training</li> </ul> <h3 id="prompt-fine-tuning">Prompt Fine-tuning</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/90093a1f-2b2e-4fcd-914a-39b977c2a3b8/image.png" alt=""></p> <p>ì´ìª½ ë¶€ë¶„ì´ ì˜ ì´í•´ê°€ ì•ˆê°€ì„œ, reference í•˜ëŠ” ë…¼ë¬¸ì„ (ê½¤ë‚˜ ìì„¸íˆ) ì½ì–´ë³´ê³  ì™”ë‹¤. ë…¼ë¬¸ì˜ ì œëª©ì€ Exploring Visual Promopts for Adapting Large-Scale Models.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/b747b053-003a-4bb9-acc9-5933e5ae93c2/image.png" alt=""></p> <p>visual promopt ë¼ëŠ” random noise ê°™ì´ ìƒê¸´ ì•¡ìë¥¼ ì£¼ëª©í•´ì„œ ë³´ì. í•µì‹¬ì€ &quot;image perturbation&quot; ì´ë‹¤. ê¸°ì¡´ backbone model ì€ frozen ëœ ìƒíƒœë¡œ, learnable parameter ë¡œ ë§Œë“¤ì–´ì§„ image perturbation ì„ í†µí•´ task ìì²´ë¥¼ reprogramming (like adversarial attack) í•˜ê³ , frozen model ì„ ìƒˆë¡œ programming ëœ task ì— adapt í•˜ë„ë¡ í•˜ëŠ” ê²ƒì´ë‹¤. ì´ ë°©ì‹ì„ ì‚¬ìš©í•˜ë©´, ì‹ìœ¼ë¡œ ë³´ë©´ ì¡°ê¸ˆ ë” ì´í•´ê°€ í¸í•˜ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/03c155af-b0bb-4eb5-a676-0b8123fad434/image.png" alt=""></p> <p>task-specific visual promopt $v_{\phi}$ parameterized by $\phi$ ë¥¼ ë°°ìš°ëŠ” ê²ƒì´ ëª©ì ì´ë‹¤. ì´ ë…¼ë¬¸ì—ëŠ” promopt design (ì•¡ìì‹ìœ¼ë¡œ í•˜ëŠëƒ-padding, random location, fixed location), output transformation (hard-coded mapping?) ê³¼ ê°™ì€ ì„¸ë¶€ì ì¸ ë‚´ìš©ë„ ë‹´ê³  ìˆìœ¼ë‹ˆ ì°¸ê³ í•˜ë„ë¡ í•˜ì. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/99cfa9bb-3392-4ad4-9185-f483cc17cbfb/image.png" alt=""></p> <p>ë‹¤ì‹œ ë³´ë©´ ìœ„ ë“±ì¥í–ˆë˜ ê·¸ë¦¼ì´ ë” ì´í•´ê°€ ë  ê²ƒì´ë‹¤. ì´ë²ˆ ë…¼ë¬¸ì—ì„œëŠ” ì € $\phi$ ë¡œ parameterize ëœ visual prompt ë¥¼ ì—¬ê¸°ì„œ ì–´ë–»ê²Œ í‘œí˜„í–ˆëŠ”ì§€ ë³´ì.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/49e80796-e802-4f9e-9658-b72eee047b3c/image.png" alt=""></p> <p>ì¤‘ê°„ ë‹¨ê³„ì˜ feature map $f_i$ ë¥¼ ResNet block $g_i$ ì— í†µê³¼ì‹œí‚¤ $p_i$ ë¼ëŠ” D dimension ì„ ê°€ì§„ prompt vetor ë¥¼ ì–»ê³ , ì´ prompt vector ë¥¼ next blockì—ì„œ ë‹¤ì‹œ $f_{i+1}$ê³¼ channel-wise multiplication ì„ ê±°ì¹˜ê²Œ ëœë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/59d52760-7848-4ba0-a518-2c00e3ade132/image.png" alt=""></p> <p>ì´ë ‡ê²Œ í‘œí˜„í•¨ìœ¼ë¡œì¨, training process ì—ì„œ (feature extractor ëŠ” frozen ëœ ì±„ë¡œ) prompt block ì— í•´ë‹¹í•˜ëŠ” parameter ë§Œìœ¼ë¡œ, lightweight MIL classifier ê°€ end-to-end ë°©ì‹ìœ¼ë¡œ update ë˜ëŠ” ê²ƒì´ë‹¤. </p> <h2 id="experiments">Experiments</h2> <h3 id="datasets">Datasets</h3> <ul> <li>Camelyon16: 256x256, 20x magnification, with average of 11556 patch per WSI, 399 WSI</li> <li>TCGA-NSCLC: 256x256, 20x magnification, with average 3089 patch per WSI, 1053 WSI</li> </ul> <h3 id="implementation-details">Implementation Details</h3> <p>promopt block ê°œìˆ˜ëŠ” 2-6ê°œ, top 200 patches ëŠ” default</p> <h3 id="comparison-results">Comparison Results</h3> <p>sota MIL ì¸ DTFD, ABMIL ì— ì ìš©í•˜ì—¬ ì‹¤í—˜í•¨. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/af13ef04-99af-46b1-814f-6c3022d9b874/image.png" alt=""></p> <p>ëŒ€ë¶€ë¶„ì˜ ì‹¤í—˜ì—ì„œ prompt fine-tuning í–ˆì„ ë•Œ ì„±ëŠ¥ì´ ë” í–¥ìƒë˜ì—ˆë‹¤. ì´ ë•Œ ì£¼ëª©í•´ì•¼ í•  ì ì€ fine-tuning ì€ cost ê°€ í›¨ì”¬ ë§ì´ ë“ ë‹¤. ì´ëŠ” demonstrate the advantage of visual prompt ë¼ê³  ì„¤ëª…í•œë‹¤.</p> <h3 id="ablation-study">Ablation study</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/6297017d-a355-4575-96f1-16a356143d04/image.png" alt=""></p> <p>Camelyon16 ë°ì´í„°ì—ì„œ, promopt block ê°œìˆ˜, representative patch ê°œìˆ˜ë¥¼ ë‹¬ë¦¬í•˜ì—¬ ì‹¤í—˜í•˜ì˜€ë‹¤. (a)ë¥¼ ë³´ë©´, one prompt block ì´ˆê³¼ì¼ ë•Œ 1%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ë‹¤. (b) ì—ì„œëŠ” K value ì— ë”°ë¼ì„œ, FT ë°©ì‹ì— ë¹„í•´ 50% ì´í•˜ì˜ GPU resource ë¥¼ ì‚¬ìš©í•˜ê³ ë„ (ì´ëŠ” ë³¸ë¬¸ì— ë‚˜ì˜¨ ë‚´ìš©ì„) efficiency, effectiveness í–¥ìƒì´ ìˆì—ˆë‹¤ê³  ì„¤ëª…í•œë‹¤. - ëª‡ê°œë¥¼ ì„ íƒí•˜ëŠ”ê²Œ ë‚«ë‹¤ ë¼ëŠ” statement ëŠ” ì—†ìŒ.</p> <h3 id="conclusion">Conclusion</h3> <p>novel promopt learning method to learn domain-specific knowledge transformation from ImageNet pre-trained model to pathological images</p> <p>ëŒë ¤ë´ì•¼ê² ë‹¤ ê·¸ë¦¬ê³  sota ë¼ê³  ì–¸ê¸‰í•œ DTFD-MIL ë„...</p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; April 11, 2023 &nbsp; &middot; &nbsp; jaeheon-lee </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p></li> <li><h3> <a class="post-title" href="/blog/2023/tables/">displaying beautiful tables with Bootstrap Tables</a> </h3> <p>an example of how to use Bootstrap Tables</p> <p class="post-meta"> 3 min read &nbsp; &middot; &nbsp; March 20, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> &nbsp; &middot; &nbsp; <a href="/blog/tag/formatting"> <i class="fas fa-hashtag fa-sm"></i> formatting</a> &nbsp; <a href="/blog/tag/tables"> <i class="fas fa-hashtag fa-sm"></i> tables</a> &nbsp; &nbsp; &middot; &nbsp; <a href="/blog/category/sample-posts"> <i class="fas fa-tag fa-sm"></i> sample-posts</a> &nbsp; </p></li> <li><h3> <a class="post-title" href="/blog/2023/table-of-contents/">a post with table of contents</a> </h3> <p>an example of a blog post with table of contents</p> <p class="post-meta"> 3 min read &nbsp; &middot; &nbsp; March 20, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> &nbsp; &middot; &nbsp; <a href="/blog/tag/formatting"> <i class="fas fa-hashtag fa-sm"></i> formatting</a> &nbsp; <a href="/blog/tag/toc"> <i class="fas fa-hashtag fa-sm"></i> toc</a> &nbsp; &nbsp; &middot; &nbsp; <a href="/blog/category/sample-posts"> <i class="fas fa-tag fa-sm"></i> sample-posts</a> &nbsp; </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-Inductive-Representation-Learning-on-Large-Graphs" target="_blank">[Paper Review] Inductive Representation Learning on Large Graphs</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="inductive-representation-learning-on-large-graphs">Inductive Representation Learning on Large Graphs</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/d485b62f-aa08-4bc9-9b2b-beb95d7ff1dd/image.png" alt=""></p> <p>ë°”ë¡œ ì´ì „ í¬ìŠ¤íŒ…ì—ì„œ ë‹¤ë¤˜ë˜ ëŒ€í‘œì ì¸ spectral method ì¸ GCN ëŠ” edge ì •ë³´ë¥¼ í‘œí˜„í•˜ì§€ ëª»í•˜ê³ , scalable í•˜ì§€ ì•Šë‹¤ëŠ” ë‹¨ì ì´ ìˆì—ˆë‹¤. Message Passing Neural Networks (MPNN) ê³¼ Graph Attention Networks (GAT) ëŠ” edge feature ë„ ê³ ë ¤í•œ GNN architecture ë¥¼ ì‚¬ìš©í•œë‹¤. ê·¸ëŸ¼ì—ë„ node feature vector ëŠ” entire neighbourhood ì— dependent í•˜ê¸° ë•Œë¬¸ì— ì•„ì˜ˆ ì²˜ìŒ ë³¸ graph ì— ëŒ€í•´ì„œëŠ” ì ìš©ì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤ëŠ” í•œê³„ì ì´ ì¡´ì¬í•œë‹¤. ì´ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ general inductive framework ì¸ GraphSAGE ê°€ ë“±ì¥í•œë‹¤. ì´ ë°©ì‹ì€ ì§€ê¸ˆê¹Œì§€ë„ ì“°ì´ëŠ” graph ìª½ ëŒ€í‘œì ì¸ ë…¼ë¬¸ì´ë‹¤.</p> <h2 id="introduction">Introduction</h2> <p>ê¸°ì¡´ ë°©ì‹ ë¬¸ì œì </p> <ul> <li>only applied on fixed graph</li> <li>do not naturally generalize to unseen data</li> </ul> <p>Present work</p> <ul> <li>GraphSAGE (SAmple and aggreGatE)</li> <li>inductive node embedding</li> <li>learn the topological structure of each node&#39;s neighborhood</li> <li>distribution of node features in neighborhood</li> <li>instead of distinct embedding vector for each node, train aggregator functions</li> <li>design an unsupervised loss which could be simply replaced by supervised loss</li> </ul> <h2 id="proposed-method-graphsage">Proposed method: GraphSAgE</h2> <p>í•µì‹¬ ì•„ì´ë””ì–´ëŠ” how to aggregate feature information from a node&#39;s local neighborhood ì— ìˆë‹¤. íŠ¹íˆ Kê°œì˜ aggregator function $AGGREGATE_k$ ì™€ ê·¸ì— ë”°ë¥¸ weight matrices $W^k$ ëŠ” ê°ê° kë²ˆì§¸ search depths ë˜ëŠ” kë²ˆì§¸ ë‹¤ë¥¸ layer of model ì— propagate information í•œë‹¤. </p> <h3 id="embedding-generation-ie-forward-propagation-algorithm">Embedding generation (i.e., forward propagation) algorithm</h3> <p>ë‹¤ìŒì€ ê°€ì¥ í•µì‹¬ì¸ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/1d39f5c9-4cf3-4715-8158-cd1b42390323/image.png" alt=""></p> <p>ì²˜ìŒì— ì•Œê³ ë¦¬ì¦˜ë§Œ ë³´ê³  $AGGREGATE_k$ ì— ëŒ€í•œ ê°ì´ ì•ˆì™€ì„œ ì½”ë“œë¥¼ ì°¾ì•„ë³´ì•˜ë‹¤. ìš”ì•½í•œ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.</p> <p>1) input ì— ëŒ€í•´, hop (depth) ê°œìˆ˜ ë§Œí¼ loop ëŒê¸° 2) ê° loop ì—ì„œ target node vectorëŠ” weight ì— í†µê³¼ í›„ ì €ì¥ 3) ê° loop ì—ì„œ target node ì˜ neighbor node vector ë„ weight ì— í†µê³¼ í›„, aggregation í›„ weight ì— í†µê³¼ í›„ ì €ì¥ 4) ì €ì¥ëœ ë‘ vector ë¥¼ concatenation í›„ ì €ì¥ ì„ iteration í•´ì„œ ë§ˆì§€ë§‰ 1x32 vector ë¥¼ node ë§ˆë‹¤ ê³„ì‚°í•˜ëŠ” ê³¼ì •ì´ë‹¤.</p> <p>setting: two layer setting, K=2</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/e696de86-9cce-426a-9671-f33d81d651ba/image.png" alt=""></p> <p>ìœ„ ê·¸ë¦¼ì€ ì•„ë˜ ë¸”ë¡œê·¸ë¥¼ ì°¸ê³ í–ˆë‹¤. ì¶œì²˜: <a href="https://antonsruberts.github.io/graph/graphsage/">https://antonsruberts.github.io/graph/graphsage/</a></p> <p>ì´ ë•Œ, full neighborhood setì„ ì‚¬ìš©í•˜ëŠ” ê²ƒ ëŒ€ì‹ , computational footprint ë¥¼ ê° batch ë§ˆë‹¤ ì¼ì •í•˜ê²Œ ê³ ì •í•˜ê¸° ìœ„í•´ì„œ, ê° iteration ë§ˆë‹¤ different uniform sample ì„ ì‚¬ìš©í•˜ì˜€ë‹¤.</p> <h3 id="learning-the-parameters-of-graphsage">Learning the parameters of GraphSAgE</h3> <p>fully unsupervised learning setting ì—ì„œ predictive representation ì„ ì–»ê³ ì ë‹¤ìŒê³¼ ê°™ì€ loss ë¥¼ ì‚¬ìš©í–ˆë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/ba0e4e96-917a-453e-bf55-fe247a7ba90d/image.png" alt=""></p> <p>ì´ ë•Œ, ì˜¤ë¥¸ìª½ í•­ $P_n(v)$ ëŠ” negative sampling distribution, Q ëŠ” number of negative sample ì´ë‹¤. nearby node ê°„ì€ similar representation, disparatenode ê°„ì—ëŠ” highly distinct í•  ê²ƒì´ë¼ëŠ” ê°€ì •ì„ ë‹´ê³  ìˆë‹¤. (í ..)</p> <p>model output ì´ ê° node ì— ëŒ€í•œ feature vector ì´ê¸° ë•Œë¬¸ì—, unsupervised leanring ì´ ì•„ë‹ˆë¼ downstream task ë“±ì—ì„œ fully supervised learning setting ë°©ì‹ì„ ì´ìš©í•´ì•¼ í•  ë•Œ, ë‹¨ìˆœíˆ loss ë§Œ cross-entropy loss ë“±ì˜ task-specific objective function ìœ¼ë¡œ ë°”ê¿”ì£¼ë©´ ëœë‹¤.</p> <h3 id="aggregator-architectures">Aggregator Architectures</h3> <p>algorithm ì—ëŠ” $AGGREGATE_k$ ë¼ í‘œí˜„ë˜ì–´ ìˆë˜ function ì„ 4ê°€ì§€ ì‚¬ìš©í•´ì„œ ë¹„êµ ì‹¤í—˜í•œë‹¤. graph data ì—ì„œëŠ” node ê°„ì˜ sequence ë° structure ê°€ ì¤‘ìš”í•˜ê¸° ë•Œë¬¸ì—, ì´ìƒì ìœ¼ë¡œëŠ” aggregating í•˜ëŠ” ê³¼ì •ì´ permutation invariance (ë…¼ë¬¸ì—ì„œëŠ” symmetric) í•´ì•¼ í•œë‹¤. </p> <ul> <li>Mean aggregator (mean and GCN)</li> </ul> <p>ê°€ì¥ ê¸°ë³¸ì ìœ¼ë¡œ, ê³„ì‚°ëœ vector ${h_u^{k-1}, \forall u \in N(v)}$ ì˜ elementwise mean ì„ ì·¨í•˜ë©´ mean aggregator ì´ë‹¤.</p> <ul> <li>GCN aggregator</li> </ul> <p>ì´ë¥¼ ë³€í˜•í•˜ì—¬, target node ì™€ $h_v^{k-1}$ ì´ì›ƒ node ${h_u^{k-1}, \forall u \in N(v)}$ ë¥¼ concatenation í›„ weight ë¥¼ ì”Œìš°ëŠ” ë°©ì‹ì€, ê¸°ì¡´ graph convolution ê³¼ ë‹®ì•„ìˆë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/03c407ff-b89f-4f3b-95c7-aebe72c40856/image.png" alt=""></p> <p>í•˜ì§€ë§Œ, ê¸°ì¡´ graph convolution ì€ ì´ì „ hop ì„ í¬í•¨í•œ ê° hop ì„ concat í•˜ëŠ” ë°©ì‹ì´ê¸°ì—, ì´ì „ ë²„ì „ê³¼ ëª…í™•íˆ ë‹¤ë¥´ê³ , ì˜¤íˆë ¤ ì´ëŠ” &quot;skip connection&quot; between the different search depths or layers ë¼ê³  í‘œí˜„í•œë‹¤. (ë„ë•ë„ë•) </p> <ul> <li>LSTM aggregator</li> </ul> <p>aggregation ê³¼ì •ì—ì„œ RNN (LSTM) module ì„ ì‚¬ìš©í•œ ë°©ì‹ì´ë‹¤. ì´ëŠ” larger expressive capability ë¥¼ ê°€ì¡Œë‹¤ëŠ” ì¥ì ì´ ìˆì§€ë§Œ, not inherently symmetric í•˜ë‹¤ëŠ” ë¬¸ì œê°€ ìˆë‹¤. (not permutation invariant) - ì´ëŠ” ì–´ë–¤ ë°©ì‹ì—ì„œë“  bias ê°€ ë°œìƒí•  êµ¬ì‹¤ì„ ì œê³µí•œë‹¤. </p> <ul> <li>Pooling Aggregator</li> </ul> <p>4ë²ˆì§¸ ë§ˆì§€ë§‰ aggregator ëŠ” trainble í•˜ë©´ì„œë„ symmetric í•˜ë‹¤. ë‹¤ë¥¸ ë°©ì‹ê³¼ëŠ” ë‹¤ë¥´ê²Œ, aggregation ì „ì— ê° ì´ì›ƒë…¸ë“œì— ëŒ€í•´ì„œ weight ë¥¼ í†µê³¼ (MLP í†µê³¼) ì‹œí‚¤ê³ , elementwise í•˜ê²Œ max operation ì„ ì·¨í•œë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/018e09cf-c00b-4580-8659-51a6294b1674/image.png" alt=""></p> <p>ì´ëŠ” ëª¨ë¸ë¡œ í•˜ì—¬ê¸ˆ íš¨ìœ¨ì ìœ¼ë¡œ neighborhood set ì˜ different aspect ë¥¼ ì¡ì•„ë‚´ê²Œ ë” í•œë‹¤. ë˜, max operator ëŒ€ì‹  mean operator ë„ ì‚¬ìš©í•´ë³´ì•˜ì§€ë§Œ no significant difference ë¥¼ ë³´ì˜€ë‹¤ê³  í•œë‹¤.</p> <h2 id="experiments--results">Experiments &amp; Results</h2> <p>ë‹¤ìŒ ì„¸ê°€ì§€ ë°ì´í„°ì…‹ì—ì„œ ì‹¤í—˜í•˜ì˜€ë‹¤.</p> <p>1) classifying academic papers into different subjects using the web of sicence citation dataset 2) classifying reddit posts as belonging to different communities 3) classisfying protein functions across various biological protein-protein iteration (PPI) graphs</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/652834f1-936e-4aed-8694-cc741199772f/image.png" alt=""></p> <p>ì†ë„ ë©´ì—ì„œë„ GraphSAGE ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ ì›”ë“±íˆ íš¨ìœ¨ì ì´ì—ˆë‹¤. DeepWalk ë³´ë‹¤ 100-500x ë¹¨ëë‹¤. GraphSAGE variants ì—ì„œ K=2 setting ì€ 10-15%ì˜ ì„±ëŠ¥ê°œì„ ì„ ë³´ì˜€ì§€ë§Œ, ê·¸ ìœ„ë¡œ ë„˜ì–´ê°€ë©´ ê°ˆìˆ˜ë¡ marginal return ê³¼ í•¨ê»˜ prohibitvely large factor of runtime ì„ ê¸°ë¡í•˜ì˜€ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/1ddfe657-fd23-4f52-9749-c7d2fe4d3051/image.png" alt=""></p> <p>ì „ë°˜ì ìœ¼ë¡œ, LSTM- and pool-based aggregator ë°©ì‹ì„ ì°¨ìš©í•œ ëª¨ë¸ì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤. ì´ ë‘ ëª¨ë¸ì— ëŒ€í•´ì„œ ë” ì •ëŸ‰ì ì¸ í‰ê°€ë¥¼ ìœ„í•´ ë‹¤ë¥¸ aggregator ë°©ì‹ê³¼ Wilcoxon Singed-Rank Test ë¥¼ ì§„í–‰í–ˆê³ , T-statistic ê³¼ p-value ë¥¼ ê¸°ë¡í•˜ì˜€ë‹¤. LSTM-, pool- aggregator ëª¨ë‘ GCN-based approach ì™€ ë¹„êµí–ˆì„ ë•Œ, T=1, p=0.02 í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ê²°ê³¼ë¥¼ ì–»ì—ˆë‹¤. </p> <h2 id="theoretical-analysis">Theoretical analysis</h2> <p>ì´ë²ˆ ì„¹ì…˜ì—ì„œëŠ” GraphSAGE ê°€ ì–¼ë§ˆë‚˜ graph structure ë¥¼ ì˜ ë°°ìš°ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ expressive capability ë¥¼ íƒìƒ‰í•˜ì˜€ë‹¤. ê·¸ ë°©ì‹ìœ¼ë¡œ, clustering coefficient of a node ê·¸ ì¤‘ì—ì„œë„ the proportion of triangles that are closed within the node&#39;s 1-hop neighborhood ë¡œ í™•ì¸í•˜ì˜€ë‹¤. ê·¸ë¦¬ê³  ë‹¤ìŒ Theoremì„ ì¦ëª…í•˜ì˜€ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/e8443861-e877-4a3f-8b74-6a70313be2f4/image.png" alt=""></p> <p>ìœ„ Theorem ì€ ì–´ë–¤ graph ì— ëŒ€í•´ì„œ, Algorithm 1 ì˜ parameter settingì´ ì¡´ì¬í•˜ëŠ”ë°, st ì´ëŠ” ëª¨ë“  node ì˜ feature ê°€ ë‹¤ë¥´ë‹¤ëŠ” ê°€ì •í•˜ì—, approximate clustering coefficient to an arbitrary precision ì´ ê°€ëŠ¥í•œ setting ì´ë‹¤. </p> <h2 id="conclusion">Conclusion</h2> <ul> <li>novel approach allowing embeddings effectively generated for unseen nodes</li> <li>outperform sota baselines</li> <li>effectively trade of performance and runtime by samplinbg node neighborhoods</li> <li>proved expressive capability about local graph structure</li> </ul> <p>ì˜¤... ì´ëŸ° algorithm ì„ ë³´ê³  elegant í•˜ë‹¤ í•˜ëŠ”êµ¬ë‚˜ 2017ë…„ì—” ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚œê±¸ê¹Œ</p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; February 24, 2023 &nbsp; &middot; &nbsp; jaeheon-lee </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p></li> </ul> <nav aria-label="Blog page naviation"> <ul class="pagination pagination-lg justify-content-center"> <li class="page-item "> <a class="page-link" href="/blog/page/2/" tabindex="-1" aria-disabled="2">Newer</a> </li><li class="page-item "><a class="page-link" href="/blog/page/2/index.html" title="blog - page 2">2</a></li> <li class="page-item active"><a class="page-link" href="/blog/page/3/index.html" title="blog - page 3">3</a></li> <li class="page-item "><a class="page-link" href="/blog/page/4/index.html" title="blog - page 4">4</a></li> <li class="page-item "><a class="page-link" href="/blog/page/5/index.html" title="blog - page 5">5</a></li> <li class="page-item "><a class="page-link" href="/blog/page/6/index.html" title="blog - page 6">6</a></li> <li class="page-item "> <a class="page-link" href="/blog/page/4/">Older</a> </li> </ul> </nav> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> &copy; Copyright 2023 JaeHeon Lee. Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>