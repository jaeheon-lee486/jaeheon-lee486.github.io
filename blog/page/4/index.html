<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>blog - page 4 | JaeHeon Lee</title> <meta name="author" content="JaeHeon Lee"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ğŸ§ </text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://jaeheon-lee486.github.io/blog/page/4/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">JaeHeon&nbsp;</span>Lee</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <div class="header-bar"> <h1>al-folio</h1> <h2>a simple whitespace theme for academics</h2> </div> <div class="tag-category-list"> <ul class="p-0 m-0"> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/formatting">formatting</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/images">images</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/links">links</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/math">math</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/code">code</a> </li> <p>&bull;</p> <li> <i class="fas fa-tag fa-sm"></i> <a href="/blog/category/blockquotes">blockquotes</a> </li> </ul> </div> <br> <div class="container featured-posts"> <div class="row row-cols-2"> <div class="card-item col"> <a href="/blog/2021/distill/"> <div class="card hoverable"> <div class="row g-0"> <div class="col-md-12"> <div class="card-body"> <div class="float-right"> <i class="fa-solid fa-thumbtack fa-xs"></i> </div> <h3 class="card-title text-lowercase">a distill-style blog post</h3> <p class="card-text">an example of a distill-style blog post and main elements</p> <p class="post-meta"> 8 min read &nbsp; &middot; &nbsp; <a href="/blog/2021"> <i class="fas fa-calendar fa-sm"></i> 2021 </a> </p> </div> </div> </div> </div> </a> </div> <div class="card-item col"> <a href="/blog/2015/code/"> <div class="card hoverable"> <div class="row g-0"> <div class="col-md-12"> <div class="card-body"> <div class="float-right"> <i class="fa-solid fa-thumbtack fa-xs"></i> </div> <h3 class="card-title text-lowercase">a post with code</h3> <p class="card-text">an example of a blog post with some code</p> <p class="post-meta"> 4 min read &nbsp; &middot; &nbsp; <a href="/blog/2015"> <i class="fas fa-calendar fa-sm"></i> 2015 </a> </p> </div> </div> </div> </div> </a> </div> </div> </div> <hr> <ul class="post-list"> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-Semi-Supervised-Classification-with-Graph-Convolutional-Networks" target="_blank">[Paper Review] Semi-Supervised Classification with Graph Convolutional Networks</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="semi-supervised-classification-with-graph-convolutional-networks">Semi-Supervised Classification with Graph Convolutional Networks</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/778aa56d-a3ed-4a9e-b01c-eace4e3f27fa/image.png" alt=""></p> <p>ë“œë””ì–´ ASCO í•™íšŒ ì œì¶œì´ ëë‚¬ë‹¤! ì¡°ê¸ˆ ì—¬ìœ ê°€ ìƒê¸°ê¸°ë„ í–ˆê³  graph ìª½ì„ ì „ë¶€í„° ê³µë¶€í•´ë³´ê³  ì‹¶ì—ˆëŠ”ë° ë§ˆì¹¨ ë™ë£Œë¶„ì´ graph ì‚¬ìš©í•´ì„œ whole slide image ë¶„ì„í•˜ëŠ” ëª¨ë¸ ì‹œë„í•´ ë³´ì‹ ë‹¤ê³  í•´ì„œ ê²¸ì‚¬ê²¸ì‚¬ ë‚˜ë„ ì‹œì‘í–ˆë‹¤. Graph ìª½ ì²˜ìŒ ë³¸ ë…¼ë¬¸ì€ ì‚¬ì‹¤ ì´ ë…¼ë¬¸ì´ ì•„ë‹ˆë¼ nature biomedical ë…¼ë¬¸ì¸ë° ê·¸ê±´ ë‹¤ìŒ ë…¼ë¬¸ë¦¬ë·°ë¡œ ì‘ì„±í•´ë³´ë„ë¡ í•˜ê² ë‹¤. ì´ë²ˆ ë…¼ë¬¸ GCN ì€ spectral ê´€ì ì—ì„œ graph node ê°„ì˜ ê´€ê³„ë¥¼ ê³ ë ¤í•´ì„œ, node ê°€ ê°€ì§€ê³  ìˆëŠ” feature ë¥¼ layer ì— í†µê³¼ì‹œì¼œ ê° ë…¸ë“œê°€ ì–´ë–¤ class ì— í•´ë‹¹í•˜ëŠ”ì§€ ë¶„ë¥˜í•˜ëŠ” ë¬¸ì œë¥¼ í‘¸ëŠ” ì—°êµ¬ë¥¼ ë‹´ê³  ìˆë‹¤. </p> <h2 id="introduction">Introduction</h2> <p>graph data íŠ¹ì„± ìƒ ê° node ë§ˆë‹¤ label ì´ ë§¤ìš° ì ê²Œ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì— graph node classification problem ì€ ë³´í†µ semi-supervised learning ìœ¼ë¡œ frame ëœë‹¤. ê¸°ì¡´ ë°©ì‹ë“¤ì€ label ì´ ì¡´ì¬í•˜ëŠ” ë°ì´í„°ì— ëŒ€í•´ loss ë¥¼ ë”°ë¡œ ê³„ì‚°í•˜ê³ , label ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ì— ëŒ€í•´ graph Laplacian regularization term ì„ ì´ìš©í•´ì„œ ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•´ ì™”ì—ˆë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/1f1b1712-b36d-4244-a6dc-7c5cba2e5837/image.png" alt=""></p> <p>í•˜ì§€ë§Œ ì´ regularization term ì€ &quot;ë…¸ë“œ ì‚¬ì´ì˜ ê±°ë¦¬ê°€ ê°€ê¹Œìš°ë©´, feature ê°€ ë¹„ìŠ·í•  ê²ƒì´ë‹¤&quot; ë¼ëŠ”, ë‹¤ì†Œ ë‹¤ë¥¸ ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ ë²„ë¦´ ìœ„í—˜ì´ ìˆëŠ” term ì´ê¸° ë•Œë¬¸ì—, ì €ìëŠ” ì´ëŸ¬í•œ term (explicit graph-based regularization) ì‚¬ìš©ì„ ì§€ì–‘í•˜ê³ ì í•˜ì˜€ë‹¤.</p> <p>ì´ë“¤ì˜ contribution ì€ ë‹¤ìŒìœ¼ë¡œ ìš”ì•½í•  ìˆ˜ ìˆë‹¤.</p> <ul> <li>introduce simple and well-behaved layer-wise propagation rule for NN moel which operate directly on graphs</li> <li><blockquote> <p>how it can be motivated from a first-order approximation of spectral graph convolutions</p> </blockquote> </li> <li>demonstrate speed and scalability in semi-supervised classification of nodes in a graph</li> </ul> <h2 id="background-notes">Background, notes</h2> <p>ì—¬ê¸°ë¶€í„°ëŠ” ê·¸ ì „ ë…¼ë¬¸ë“¤ì—ì„œ ë‹¤ë£¨ê³  ìˆëŠ” spectral graph convolution ì— ëŒ€í•œ ì´í•´ê°€ í•„ìš”í•˜ë‹¤. ë”°ë¼ì„œ ë…¼ë¬¸ì˜ ë‚´ìš©ì„ ì„¤ëª…í•˜ê¸° ì „ ë‹¤ìŒ ë¸”ë¡œê·¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì •ë¦¬í•œ ë…¸íŠ¸ë¥¼ ì²¨ë¶€í•œë‹¤. ë…¸íŠ¸ì˜ Chebyshev expansion ê¹Œì§€ê°€ background ì´ê³ , reparameterization ë° rescaling ë“±ì˜ trick ì€ ì´ë²ˆ GCN ë…¼ë¬¸ì—ì„œ ì†Œê°œëœë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/c70e205f-15d8-4ec7-a619-b833c12c0a2e/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/8fb2e393-3d14-4a6f-8003-8fd3b9c76f93/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/21671647-7277-49b4-9123-474f57a375bc/image.png" alt=""></p> <p>ì´ ë•Œ, computationally expensive í•˜ê¸° ë•Œë¬¸ì— Chebyshev polynomial ì„ ì‚¬ìš©í•œë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/144737da-cf27-4f65-883f-32aba869c9de/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/a4cb737c-5802-43b8-9ed1-40f85761e945/image.png" alt=""></p> <p>ì¶œì²˜: <a href="https://theaisummer.com/graph-convolutional-networks/">https://theaisummer.com/graph-convolutional-networks/</a> </p> <h2 id="fast-approximate-convolutions-on-graphs">Fast Approximate Convolutions on Graphs</h2> <p>multi-layer Graph Convolutional Network (GCN) ì€ ë‹¤ìŒê³¼ ê°™ì€ layer-wise propagation rule ë¡œ ì •ì˜ëœë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/a75ea228-1837-474c-b946-1197b23eca35/image.png" alt=""></p> <p>ì´ ë•Œ AëŠ” self-connection ì´ ì¶”ê°€ëœ adjacency matrix ì´ê³ , DëŠ” self-connection ì´ ì¶”ê°€ëœ Aì˜ Dì´ë‹¤. non linear function ì€ ReLU function ì„ ì‚¬ìš©í–ˆê³ , $H^{(l)}$ ì€ N x D lë²ˆì§¸ layer ì„ ëœ»í•˜ë©°, ì´ì— ìƒì‘í•˜ì—¬ $H^{(0)}$ ì€ ë°ì´í„° ê·¸ ìì²´ $x \in$ N ì´ë‹¤</p> <h3 id="spectral-graph-convolutions">Spectral Graph Convolutions</h3> <p>x ë¼ëŠ” graph signal ì— $g_{\theta}=diag(\theta)$ filter parameterized by $\theta \in \real^N$ in Fourier domain ë¥¼ ë¶™ì¸ í˜•íƒœë¡œ, spectral convolution ì´ ì •ì˜ëœë‹¤. ex) <img src="https://velog.velcdn.com/images/jaeheon-lee/post/8c692fb0-15cb-402b-bd13-dfa0df309f69/image.png" alt=""></p> <p>ì´ ë•Œ, U ëŠ” normalized graph Laplacian ì˜ eigenvector ì´ê³ , eigenvalue ëŠ” graph Fourier transform of x ê°€ ëœë‹¤. í•˜ì§€ë§Œ ì´ëŸ° ë°©ì‹ì„ ì‚¬ìš©í•˜ë©´, 1) L ì— ëŒ€í•´ SVD ë¥¼ ì ìš©í•´ì•¼ í•˜ê³  2) eigenvalue matrix U ë¥¼ multiplication í•´ì•¼ í•¨ìœ¼ë¡œ computation cost ê°€ í¬ë‹¤. ì´ëŸ¬í•œ ë¬¸ì œì ì„ ê·¹ë³µí•˜ê¸° ìœ„í•´, ì´ì „ì— Chebyshev expansion ì„ ì‚¬ìš©í•˜ì—¬ series í˜•íƒœë¡œ <strong>ê° locality ì— í•´ë‹¹í•˜ëŠ” filter í†µê³¼ feature</strong> $T_k(x)$ ì˜ í•©ì„ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í–ˆë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/f846ead3-3e4c-406c-afdc-3c3c2798fd32/image.png" alt=""></p> <p>$$$ Y = g_\theta(\tilde{L_h})X = [\tilde{X_0}, \tilde{X_1}, ... , \tilde{X_{k-1}}]\theta_v, \tilde{X_p}=T_p({\tilde{L_h}} )X $$$</p> <p>ì—¬ê¸°ê¹Œì§€ ì‚¬ì „ì§€ì‹ì— í•´ë‹¹í•œë‹¤. ê° locality k ì— ëŒ€í•´ ê³„ì‚°ëœ filter ë¥¼ í†µê³¼í•œ feature ë“¤ì´ concat ëœ í˜•íƒœë¡œ, inception module ê³¼ ë‹®ì•„ìˆë‹¤.</p> <h3 id="layer-wise-linear-model">Layer-wise Linear Model</h3> <p>ìœ„ì—ì„œ í•œ layer ë¥¼ í‘œí˜„í–ˆê¸° ë•Œë¬¸ì—, neural network model ë„ convolution layer í˜•íƒœë¥¼ ëˆ Equation (5) ë¥¼ ì—¬ëŸ¬ê°œ stacking í•¨ìœ¼ë¡œì¨ ë§Œë“¤ì–´ ë‚¼ ìˆ˜ ìˆë‹¤. ì´ ë•Œ í•œ layer ë¥¼ ì •ì˜í•˜ê¸° ìœ„í•´, $\lambda_{max}$ ê°€ ëŒ€ëµ 2ë¼ê³  ê°€ì •í•˜ê³  K=1 ì¸ ê²½ìš°ë¥¼ ìƒê°í•´ë³´ë©´, free parameter $\theta&#39;_0,\theta&#39;_1$ ì™€ í•¨ê»˜ ë‹¤ìŒì²˜ëŸ¼ í‘œí˜„ëœë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/25a65794-7064-4f07-a295-5dfc95312a6d/image.png" alt=""></p> <p>ì´ ë•Œ, filter parameter ëŠ” whole graph ì—ì„œ share ê°€ëŠ¥í•œ í˜•íƒœì´ë¯€ë¡œ, successive application of filter ë¥¼ stack í•´ì„œ ì‚¬ìš©í•˜ë‹¤ë©´, kth - order neighborhood of node ë¥¼ í‘œí˜„í•  ìˆ˜ ìˆê²Œ ë˜ëŠ” ê²ƒì´ë‹¤. (ìœ„ì—ì„œ k ëŠ” locality ë¼ê³  í‘œí˜„í–ˆì—ˆìŒ.)</p> <p>ë˜í•œ ì‹¤ìš©ì ì¸ ì¸¡ë©´ì—ì„œ ì €ìëŠ” ìƒˆë¡œìš´ renormalization trick ì„ ì œì•ˆí•œë‹¤. ë‘ê°œì˜ free parameter ê°’ì„, ë‘ parameter ê°„ì˜ ê´€ê³„ë¥¼ ì •ì˜í•¨ìœ¼ë¡œì¨ í•˜ë‚˜ë¡œ ë³€ê²½í•˜ê³  í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„ëœë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/b8910f58-56a7-49aa-852b-4a5c982ccc0e/image.png" alt=""></p> <p>ì´ ë•Œ, ê°€ìš´ë° In+DAD í•­ì€ ê°€ì •ëœ ëŒ€ë¡œ 0-2 ì‚¬ì´ì˜ eigenvalue ê°’ì„ ê°€ì§€ê²Œ ë˜ëŠ”ë°, repeated application ì„ ê±°ì¹˜ë©´ numerical instability ì™€ exploding/vanishing gradient ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/9e47d29f-0bf8-415a-9f65-a87e86e85f90/image.png" alt=""></p> <p>ë‹¤ìŒê³¼ ê°™ì€ renormalization ê³¼ì •ì„ ê±°ì³, ë‹¤ìŒê³¼ ê°™ì€ ì¼ë°˜ì ì¸ í˜•íƒœë¥¼ ì–»ë„ë¡ í•˜ì˜€ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/aedb56a6-6598-43c6-8c47-97798c6df0d4/image.png" alt=""></p> <h2 id="semi-supervised-node-classification">Semi-Supervised Node Classification</h2> <p>ìœ„ì—ì„œ ì–¸ê¸‰í•œ êµ¬ì¡°ë¥¼ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/8a488d4f-9718-447a-8cd6-ec05816730e5/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/78de0f55-a7d2-48a1-a45f-35e821180b94/image.png" alt=""></p> <p>ì´ ë•Œ loss ëŠ” <strong>labeled examples</strong> ì— ëŒ€í•´ì„œ cross-entropy í˜•íƒœë¡œ ì‚¬ìš©í•œë‹¤.</p> <h2 id="experiment--result">Experiment &amp; Result</h2> <p>3ê°œì˜ citation network ì—ì„œì˜ document classification task ë¡œ ìˆ˜í–‰í•˜ì˜€ë‹¤. Dataset ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/6e873d9c-a1ff-4219-bbfa-7192e3263bc7/image.png" alt=""></p> <p>model ì€ ê¸°ë³¸ì ìœ¼ë¡œ 2-layer shallow network ë¥¼ ì‚¬ìš©í•˜ì˜€ê³ , supplementary result ì— layer ê°œìˆ˜ë¥¼ ëŠ˜ë¦° ì‹¤í—˜ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚´ì—ˆë‹¤. 1000ê°œì˜ labeled example ë¡œ test í•˜ì˜€ê³ , ì—¬ëŸ¬ baseline ê³¼ í•¨ê»˜ ì„±ëŠ¥ì„ ê¸°ë¡í•˜ì˜€ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/dc458c70-1885-4ca3-8ecf-7aaafd4fe701/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/5559e279-54e4-4923-ba7e-7425db250f3a/image.png" alt=""></p> <p>ë‹¤ë¥¸ propagation logic ì„ ì‚¬ìš©í•´ì„œ ì„±ëŠ¥ì„ ë¹„êµí•˜ì˜€ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/cda4047f-8ec0-4391-b2d5-cfabc55d1327/image.png" alt=""></p> <h2 id="discussion">Discussion</h2> <p>ë‹¤ìŒê³¼ ê°™ì€ í•œê³„ì ì„ ì–¸ê¸‰í•˜ì˜€ë‹¤.</p> <ul> <li>Memory requirement grows linearly in the size of the dataset</li> <li>Directed edges and edge features are limited </li> <li>Limiting assumptions </li> <li>-&gt; self connection ê³¼ edge ê°„ì˜ importance ë¥¼ ë™ì¼í•˜ê²Œ ì·¨ê¸‰í•¨.</li> <li>-&gt; implicití•˜ê²Œ locality ë¥¼ ê°€ì •í•¨. (Kth layer ëŠ” Kth order neighborhoodì´ë‹¤.)</li> </ul> <p>ì¬ë°Œêµ¬ë§Œ</p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; February 22, 2023 &nbsp; &middot; &nbsp; velog.io </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-Development-and-validation-of-a-deep-learning-algorithm-for-improving-Gleason-scoring-of-prostate-cancer" target="_blank">[Paper Review] Development and validation of a deep learning algorithm for improving Gleason scoring of prostate cancer</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="development-and-validation-of-a-deep-learning-algorithm-for-improving-gleason-scoring-of-prostate-cancer">Development and validation of a deep learning algorithm for improving Gleason scoring of prostate cancer</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/e2f33b55-4342-4db5-b05b-50672a220a15/image.png" alt=""></p> <p>ìµœê·¼ ë§¡ì•„ ì§„í–‰ì¤‘ì¸ í”„ë¡œì íŠ¸ì™€ ê°€ë ¤ëŠ” ë°©í–¥ì´ ë¹„ìŠ·í•œ ë…¼ë¬¸ì´ë‹¤. nature npj digital medicine ë…¼ë¬¸ìœ¼ë¡œ 2019ë…„ì— accept ë˜ì–´ 311ë²ˆ ì¸ìš©ë˜ì—ˆë‹¤. (ì´ ë…¼ë¬¸ì€ ê¼­ ë¦¬ë·° í•´ì•¼ê² ë‹¤ ë‹¤ì§í–ˆëŠ”ë° ì§€ê¸ˆì—ì„œì•¼ ... í•˜ê²Œ ë˜ì—ˆë‹¤.)</p> <h2 id="introduction">Introduction</h2> <p>Prostate adenocarcinoma (cancer) ëŠ” ë‚¨ì„±ì—ê²Œ 2ë²ˆì§¸ë¡œ ë§ì´ ë°œë³‘ë˜ëŠ” ì•”ì¢…ì´ë‹¤. ì´ í™˜ìì˜ ì¤‘ì¦ë„ë¥¼ stratify í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ, prostate resection ì´ë‚˜ prostate biopsy ì˜ H&amp;E image ë¥¼ ë³´ê³  pathologist ê°€ morphologic feature ì— ë”°ë¼ gleason score ë¥¼ ë©”ê²¨ clinical treatment ë¥¼ ì •í•˜ê±°ë‚˜ í™˜ìì˜ ì˜ˆí›„ë¥¼ ì˜ˆì¸¡í•˜ëŠ”ë° ì´ìš©í•´ ì™”ë‹¤. í•˜ì§€ë§Œ ì´ëŸ¬í•œ ë°©ë²•ì€, pathologist ì— ë”°ë¼ subjective í•œ scoring ì´ ì¦ê³  (ë³´ê³ ë˜ì–´ ì™”ê³ ) ê°™ì€ í™˜ìì— ëŒ€í•´ reproducibility ê°€ ë–¨ì–´ì§„ë‹¤ëŠ” ë¬¸ì œê°€ ìˆì–´ì™”ë‹¤. ì €ìëŠ” ì´ëŸ¬í•œ ë¬¸ì œë“¤ì„ í•´ê²°í•˜ê¸° ìœ„í•´ deep learning ì•Œê³ ë¦¬ì¦˜ì„ ì´ìš©í•œ ë” ì„¸ë¶„í™”ëœ gleason score ë¥¼ propose í–ˆê³  ì´ì— ëŒ€í•´ validation í•˜ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í–ˆë‹¤.</p> <h2 id="results">Results</h2> <h3 id="overview-of-the-deep-learning-system-and-data-acquisition">Overview of the deep learning system and data acquisition</h3> <p>two-stage deep learning system ì„ í™œìš©í•˜ì˜€ë‹¤. ì²«ë²ˆì§¸ëŠ”, regional Gleason pattern classification, ê·¸ ë’¤ë¡œ K-nearest-neighbor-based whole-slide Gleason Grade group classification ì„ ìˆ˜í–‰í–ˆë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/3cbd4c16-27bf-4a65-9a25-38ed031ef3a6/image.png" alt=""></p> <p>ì²«ë²ˆì§¸ ê³¼ì •ì€, pathologist ì˜ pixel-level annotation ì„ ê¸°ë°˜ì˜ ì§€ë„í•™ìŠµìœ¼ë¡œ í•™ìŠµë˜ì—ˆê³ , ì´ 912 ì¥ì˜ ìŠ¬ë¼ì´ë“œë¡œë¶€í„° 112,000,000 ì¥ì˜ patch ê°€ ì‚¬ìš©ë˜ì—ˆë‹¤. validation set ì€ 3 source ë¡œë¶€í„° 331 patient ì˜ 331 slide ê°€ ì´ìš©ë˜ì—ˆë‹¤. (TCGA, Tertiary teaching hospital, Medical laboratory)</p> <h3 id="comparision-of-dls-to-pathologists-on-whole-slide-gleason-scoring">Comparision of DLS to pathologists on whole-slide Gleason scoring</h3> <p>Validation dataset ì— ëŒ€í•˜ì—¬, ë‘ ê·¸ë£¹ì˜ ë¦¬ë·° (ì˜ˆì¸¡) ì„ ë¹„êµí•˜ì˜€ë‹¤. </p> <ul> <li>29 pathologists in classifying each slide&#39;s Gleason Grade Group</li> <li>Deep learning system (DLS) performance <img src="https://velog.velcdn.com/images/jaeheon-lee/post/3b6070aa-c871-4c3e-87f6-240e8229932a/image.png" alt=""></li> </ul> <p>a ê²°ê³¼ DLS 0.7 acc &gt; pathologist 0.61 acc ì˜€ë‹¤. b 10ëª…ì˜ subgroup ì„ ë½‘ì•„, ê°ê° DLS ì™€ ë¹„êµí•œ ê²°ê³¼, 8ëª…ì˜ pathologist ê°€ DLS ë³´ë‹¤ ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.</p> <p>ì¶”ê°€ë¡œ, GG &gt;= 2, 3, 4 ì— ëŒ€í•´ decision threshold ë¥¼ ê´€ì°°í–ˆë‹¤. DLS ëŠ” AUC ê°’ 0.95-0.96 ì„ ë³´ì˜€ê³ , íŠ¹íˆ Grade group &gt;= 4 ì—ì„œ 10ëª…ì˜ pathologist ì¤‘ 9ëª…ì˜ pathologist ë³´ë‹¤ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤. </p> <h3 id="comparison-of-dls-to-pathologists-on-gleason-pattern-quantitation">Comparison of DLS to pathologists on GLeason pattern quantitation</h3> <p>ISUPì™€ CAP, WHO, recent publication ì—ì„œ ê¶Œì¥ë˜ëŠ” ë°©ë²•ì€ ê° íŒ¨í„´ì´ ìŠ¬ë¼ì´ë“œì—ì„œ ì°¨ì§€í•˜ëŠ” ì •í™•í•œ ë¹„ìœ¨ì´ ì¤‘ìš”í•˜ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 5% ê°€ ë„˜ëŠ”ì§€ì— ë”°ë¥¸ ì¶”ê°€ rule ì´ ì¡´ì¬í•œë‹¤. ì´ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´, ë¯¸ë¦¬ ì–»ì—ˆë˜ pathologistì˜ pixel-level annotation ê³¼ DLS score ë¥¼ ë¹„êµí•˜ì˜€ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/5702a284-e6f1-4c3a-a2f2-70f5b354526a/image.png" alt=""></p> <p>ê²°ê³¼ GP5 ì˜ ë¹„ìœ¨ì—ì„œëŠ” ê·¼ì†Œí•œ ì°¨ì´ë¥¼ ë³´ì˜€ìœ¼ë‚˜, GP3, 4 ì—ì„œëŠ” significant í•œ accuracy ì°¨ì´ë¥¼ ë³´ì—¬ì£¼ì—ˆë‹¤. ë˜í•œ, 5% ruleì— ë”°ë¼ grade group ì´ ë°”ë€” ìˆ˜ ìˆëŠ” ì¼ë¶€ ìŠ¬ë¼ì´ë“œë§Œ subgroup í•´ì„œ ê°™ì€ ë¶„ì„ì„ ì§„í–‰í•˜ì˜€ê³ , ì´ validation set ì—ì„œë„ acc ì°¨ì´ë¥¼ ë³´ì˜€ë‹¤.</p> <h3 id="insights-from-dls-region-level-classifications">Insights from DLS region-level classifications</h3> <p>region-level classification of DLS ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ 3ëª…ì˜ pathologistì˜ 79ì¥ ìŠ¬ë¼ì´ë“œ annotation ê³¼ DLS prediction ê²°ê³¼ë¥¼ ë‹¤ê°ë„ë¡œ ë¶„ì„í•˜ì˜€ë‹¤. DLSëŠ” 97%, 3 pathologist ëŠ” 88% concur í•˜ì˜€ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/df925c81-2907-45a0-8b56-c72b0bd62264/image.png" alt=""></p> <p> b ì—ì„œ DLS ì˜ confidence score (ê° íŒ¨í„´ ë³„ probability) ë¥¼ as a function of inter-pathologist aggreement ì— ë”°ë¼ ë‚˜íƒ€ë‚´ì—ˆë‹¤. pathologist ê°€ Gleason pattern 3 ì—ì„œ concordant, gleason pattern 3ê³¼ 4 ì‚¬ì´ì—ì„œ disconcordant, concordant on GP4 í–ˆë˜ tissue region ì— ëŒ€í•´ì„œ, DLSì˜ prediction score ê²°ê³¼ëŠ” smooth í•˜ê²Œ ë°”ë€Œì—ˆë‹¤. ì¦‰ confidence score ê°€, pathologist ì˜ scoring ê³¼ì • ì¤‘ ambiguous í–ˆë˜ ë¶€ë¶„ê¹Œì§€ ë°˜ì˜í–ˆë‹¤ëŠ” ê²ƒì„ ì•”ì‹œí•œë‹¤. ì´ëŸ¬í•œ trend ê°€ 3-4 ë¿ë§Œ ì•„ë‹ˆë¼ 4-5 pattern ì—ì„œë„ ê´€ì°°ë˜ì—ˆë‹¤. </p> <p>ì´ë¥¼ fine-grained Gleason patterns (3.3ì´ë‚˜ 3.7ê³¼ ê°™ì€) ë¡œ ë¶„ë¥˜í•˜ì—¬ ë³´ì—¬ì¤€ ê²°ê³¼, spectrum ìƒì— well-to-poor differentiation ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤.</p> <h3 id="measuring-effectiveness-of-gleason-scoring-in-risk-stratification-for-disease-progression">Measuring effectiveness of Gleason Scoring in risk stratification for disease progression</h3> <p>ë§ˆì§€ë§‰ìœ¼ë¡œ DLS ë° pathologist cohort ì˜ ability ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´, ê° prediction ì´ biochemical recurrence ë˜ëŠ” disease progression ì´ë¼ëŠ” ì´ë²¤íŠ¸ì— ëŒ€í•œ patient ì˜ ìœ„í—˜ë„ë¥¼, well-~ staratify í•˜ëŠ”ì§€ ë¶„ì„í•˜ì˜€ë‹¤.</p> <p>c-index ìƒìœ¼ë¡œ í™•ì¸í–ˆì„ ë•Œ, pathologist-provided grade group ì€ in average c-index 0.63 ì„ ê¸°ë¡í–ˆê³ , DLS-predicted grade group ì€ in average c-index 0.65 ë¥¼ ê¸°ë¡í•˜ì˜€ë‹¤. Kaplan-Meier and hazard ratio analyses using a binary GG&gt;=3 threshold ë¥¼ conduct í•œ ê²°ê³¼, ì˜ ë‚˜ë‰˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/6bef15b1-1b0b-42d9-8292-70656b09833b/image.png" alt=""></p> <p>ì¶”ê°€ ë¶„ì„ì„ ì§„í–‰í–ˆê³ , ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ê´€ì°°í•  ìˆ˜ ìˆì—ˆë‹¤.</p> <ul> <li>Cox model ì„ ì¨ì„œ quantified Gleason patterns ì˜ prognostic ability ë¥¼ í™•ì¸í•œ ê²°ê³¼, DLS 0.697, 29 cohort 0.674 ë¥¼ ê¸°ë¡í–ˆë‹¤.</li> <li>Fine grained Gleason pattern ì„ poc í•˜ê¸° ìœ„í•´, GP3.5 ë¥¼ ì¶”ê°€í•˜ì—¬ Cox model ë¡œ í™•ì¸í•œ ê²°ê³¼, DLS 0.704, GP4.5 ì¶”ê°€í•œ ê²°ê³¼ 0.702 ë¡œ í–¥ìƒ.</li> </ul> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; January 25, 2023 &nbsp; &middot; &nbsp; velog.io </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-LassoNet-Neural-Networks-with-Feature-Sparsity" target="_blank">[Paper Review] LassoNet: Neural Networks with Feature Sparsity</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="lassonet-neural-networks-with-feature-sparsity">LassoNet: Neural Networks with Feature Sparsity</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/d08f731a-31b6-465d-a0a9-4523c9723065/image.png" alt=""></p> <p>ì´ë²ˆ ë…¼ë¬¸ì€ 2020ë…„ ìŠ¤íƒ í¬ë“œì—ì„œ ì“´ XAI ê´€ë ¨ ì—°êµ¬ì´ë‹¤. ì´ ì—°êµ¬ì˜ í›„ì† ì—°êµ¬ì¸ FastCPH model ì´ ì–¼ë§ˆì „ 1ì›”ì— ë‚˜ì™€ì„œ ì½ëŠ” ì¤‘ì— ì´ ë…¼ë¬¸ì€ ë¦¬ë·°í•˜ë©´ ì¬ë°Œì„ ê²ƒ ê°™ì•˜ë‹¤. ì§€ê¸ˆê¹Œì§€ í•´ì„ ê°€ëŠ¥í•œ AI ì™€ ê´€ë ¨ëœ ë§ì€ ì—°êµ¬ê°€ ì´ë£¨ì–´ì¡Œê³ , í•˜ë‚˜ì˜ ì ‘ê·¼ ë°©ì‹ì€, ë„¤íŠ¸ì›Œí¬ê°€ ì¤‘ìš”í•œ feature ë§Œ ì‚¬ìš©í•˜ë„ë¡ arrange í•˜ëŠ” ê²ƒì´ë‹¤. ì£¼ë¡œ Linear model ì—ì„œ Lasso (l1-penalty) regularization ì€ ê°€ì¥ ê´€ë ¨ì—†ëŠ” feature ì— 0 ì„ ë¶€ì—¬í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµì´ ì´ë£¨ì–´ì§€ë„ë¡ í•˜ì§€ë§Œ, linear model ì—ë§Œ ì ìš© ê°€ëŠ¥í–ˆë‹¤. ì´ë²ˆ ë…¼ë¬¸ì—ì„œëŠ” nonlinearity ë¥¼ ë¨¸ê¸ˆê³  ìˆëŠ” neural network ì— feature sparsity ë¥¼ ìˆ˜í–‰í•˜ë„ë¡ ê°•ì œí•˜ëŠ” ìƒˆë¡œìš´ í•™ìŠµ ë°©ë²• ë° ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•œë‹¤. í•´ë‹¹ ë…¼ë¬¸ì˜ ìš”ì•½ì€ ë‹¤ìŒ ì˜ìƒì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤. <a href="https://www.youtube.com/watch?v=bbqpUfxA_OA">https://www.youtube.com/watch?v=bbqpUfxA_OA</a></p> <h2 id="introduction">Introduction</h2> <ul> <li>ì˜ˆì¸¡ ë¬¸ì œì—ì„œ much of information in features is irrelevant</li> <li>high dimensional data - speech, object recognition, protein data</li> <li>benefits of feature selection include, 1) reduce experimental cost, 2) enhance interpretability 3) speed up 4) memory</li> <li>motivating question: Are there redundant or unnecessary features?</li> </ul> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/e67d00be-5da3-447f-8f40-21439af52fed/image.png" alt=""></p> <p>MICE protein dataset ì—ì„œ 20%ì˜ feature ë§Œìœ¼ë¡œ 70%ì˜ signal ì„ ì¡ì•„ëƒ„. ì ˆë°˜ ì´í•˜ 35ê°œì˜ feature ë§Œìœ¼ë¡œ ì¢‹ì€ ì„±ëŠ¥.</p> <h3 id="proposed-method">Proposed method</h3> <p>new approach LassoNet : extends Lasso regression and its feature sparsity - to FeedForwardNeuralNetworks. : input-to-output residual connection ì„ í™œìš©í•˜ì—¬, allow a feature to have non-zero weight in a hidden unit only if its linear connection is active : linear-nonlinear components are optimized jointly, allowing to capture arbitrary nonlinearity : outperforms state-of-the-art methods for feature selection and regression</p> <h2 id="our-proposal-lassonet">Our proposal: LassoNet</h2> <h3 id="background-and-notation">Background and notation</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/fde22ade-8b9d-4d1e-9925-5f3ea3250911/image.png" alt=""></p> <p>n: total number of training points d: data dimension $f_W$: fully connected feed-forward network with parameters W K: the size of the first hidden lyaer $W^{(1)}$: first hidden layer (dxK-dimensional) $\theta$: residual layer (d-dimensional) $S_{\lambda}(x)$: sign(x)max(|x|-$\lambda$, 0), soft thresholding operator</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/97ccf9e8-00a0-415d-8939-696d7b54ecf0/image.png" alt=""></p> <p>green: single residual connection, black: arbitrary feed-forward neural network. The residual layer and the first hidden layer are jointly passed through a hierarchical soft-thresholding optimizer</p> <p>1) penalty ëŠ” ê¸°ì¡´ feature sparsity ë¡œ ì´ë„ëŠ” empirical risk minimization ì„ ë”°ë¥¸ë‹¤. combinatorial search ì—ì„œ continuous search by varying the level of the penalty. 2) proximal gradient algorithm ì€ ìˆ˜í•™ì ìœ¼ë¡œ elegant way ë¡œ ì ìš©ë˜ì–´, simple - efficient ì ìš©ì´ ê°€ëŠ¥í•˜ë‹¤. </p> <h3 id="formulation">Formulation</h3> <p>ì´ ë…¼ë¬¸ì—ì„œ ê°€ì¥ í•µì‹¬ì´ë¼ ë§í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì´ ë‹¤ìŒ ì‹ì´ë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/7dd28f62-7fc2-4f26-b6d2-af43c7d4f01c/image.png" alt=""></p> <p>íŠ¹íˆ ì•„ë˜ constraint ë¶€ë¶„ì´ í¬ì¸íŠ¸ë¼ê³  í•  ìˆ˜ ìˆë‹¤. M ì´ë¼ëŠ” constant ì— ë”°ë¼, non-linearity involving feature j according to the relative effect importnace of $X_j$ ì˜ ì–‘ì´ ì¡°ì ˆëœë‹¤. ì¦‰, M=0 ì¼ ë•Œ formulation ì€ linear model ì—ì„œì˜ LASSO ì™€ ê°™ì•„ì§„ë‹¤. ë°˜ëŒ€ë¡œ M-&gt;inf ë¡œ ê°€ë©´ standard feed-forward network with $l_1$-penalty on first layer ê°€ ëœë‹¤. </p> <p>ì´ formulation ì€ ëª‡ê°€ì§€ ì¥ì ì´ ìˆëŠ”ë°, (ì˜ì—­ ë¶ˆê°€) linear component of the signal above the nonlinear one and ì´ë¥¼ feature sparsityë¡œ ì´ëˆë‹¤. (ì´ëŠ” hierarchy priciple ì´ë¼ëŠ” í†µê³„í•™ì˜ ê°œë…ê³¼ ìœ ì‚¬í•˜ë‹¤ê³  í•œë‹¤. ì™„ì „íˆ ìƒˆë¡œìš´ ê²ƒì€ ì•„ë‹ˆë¼ í•¨) ë˜í•œ, linear and non-linear component ë¥¼ í•™ìŠµ ê³¼ì • ìƒ &quot;simultaneously&quot; ë°°ìš°ê²Œ ëœë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/7baf7467-8019-4a4e-ab88-c83f435c4ce4/image.png" alt=""></p> <p>ìœ„ ì•Œê³ ë¦¬ì¦˜ì€ LassoNet ì˜ training ê³¼ì •ì´ë‹¤. ë¨¼ì € ëª¨ë¸ íŒŒë¼ë¯¸í„°ëŠ” stochastic gradient descent ë¡œ ì—…ë°ì´íŠ¸ ëœë‹¤. ì´í›„ <strong>hierarchical proximal operator</strong> - optimization section ì— ë“±ì¥ - ê°€ input layer pair $(\theta, W^{(1)})$ ì— ì ìš©ëœë‹¤. elegant í•˜ë‹¤ëŠ” í‘œí˜„ì´ ì°¸ ì í•©í•˜ë‹¤ ëŠê»´ì¡Œë‹¤. í•˜ì§€ë§Œ ë’¤ì— ë¬´ì‹œë¬´ì‹œí•œ ì¦ëª… ê³¼ì •ì´ ê¸°ë‹¤ë¦¬ê³  ìˆë‹¤.</p> <h3 id="hyper-parameter">Hyper-parameter</h3> <p>LassoNet ì—ëŠ” ë‘ ê°€ì§€ hyper-parameter ê°€ ì¡´ì¬í•œë‹¤.</p> <ul> <li>the $l_1$-penalty coefficient $\lambda$ : controls complexity of the fitted model. </li> <li>the hierarchy coefficient $M$: controls the relative strength of the linear and nonlinear components</li> </ul> <p>íŠ¹íˆ hierarchy coefficient ëŠ” domain knowledge ì—†ì´ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì–´ë µë‹¤ê³  í•œë‹¤. ë¯¸ë¦¬ ì •í•´ë‘” hyperparameter set ì—ì„œ parallel í•˜ê²Œ tuning í–ˆë‹¤ê³  í•œë‹¤.</p> <h2 id="optimization">Optimization</h2> <h3 id="warm-starts-a-path-from-dense-to-sparse">Warm starts: a path from dense to sparse</h3> <p>feature selection ê³¼ì •ì„ ìƒê°í•´ë³´ë©´ forward selection, reverse selection ì´ ìˆë‹¤. ì €ìëŠ” ì „ìì™€ í›„ìë¥¼ ê°ê° ì‹¤í—˜í–ˆê³ , ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ì—ˆë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/5bb9ec03-1ea3-45a4-9123-19e0ef2cba1b/image.png" alt=""></p> <p>ì˜¤ë¥¸ìª½ figure ë¥¼ ë³´ë©´, Lasso ì™€ LassoNet sparse to dense (red) ì— ë¹„í•´, LassoNet dense to sparse (green) ì˜ Test error ê°€ ì›”ë“±íˆ ë‚®ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. </p> <h3 id="hierarchical-proximal-optimization">Hierarchical proximal optimization</h3> <p>ìœ„ ì•Œê³ ë¦¬ì¦˜ì— ë“±ì¥í–ˆë˜ HIER-PROX() ë¼ëŠ” operator ì— ëŒ€í•œ ë‚´ìš©ì´ë‹¤. ì•ì„œë„ ê°„ë‹¨íˆ ì„¤ëª…í–ˆì§€ë§Œ, ì´ëŠ” numerically efficient &quot;algorithm&quot; ì´ë‹¤. (not DL model) ë¯¸ë¦¬ ê·¸ ì¡´ì¬ì™€ ìœ ì¼ì„±ì´ ì¦ëª…ëœ global minima ì‹ì„ í†µí•´ ê° node ì˜ weight ë“¤ì„ ìµœì í™” í•˜ëŠ” ê³¼ì •ì´ë‹¤. í•„ìëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì„¤ëª…í•œë‹¤. Underlying its development is the derivation of equivalent optimality conditions that completely characterize the global solution of the no-convex minimization porblem defining the proximal operator. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/5e46cafb-b011-4c95-a910-1fb80d55a600/image.png" alt=""></p> <p>í•´ë‹¹ ì‹ì—ì„œ ì£¼ëª©í•  ì ì€, inner loop ì—ì„œ ê° input feature ë§ˆë‹¤ ë”°ë¡œ ê³„ì‚°ì´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì ì´ë‹¤. ë˜í•œ ranking ì„ ì •í•´ì„œ í•˜ë‚˜ì˜ m ì„ ì¡ê³  ì´ë¥¼ ì´ìš©í•´ì„œ update í•œë‹¤ëŠ” ì ì´ë‹¤. ì´ê²ƒì´ ê°€ëŠ¥í•œ ì´ìœ ëŠ” ë‹¤ìŒ proposition ì´ ì¦ëª…ë˜ì—ˆê¸° ë•Œë¬¸ì´ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/305c7bb1-4bcc-478e-8c01-0062b619c854/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/30f7f967-1669-45e0-9855-02dc3cf71832/image.png" alt=""></p> <p>ì¦ëª…ê³¼ì •ì„ ê°„ë‹¨íˆ ìš”ì•½í•˜ë©´, non-convex optimization problem - (KKT condition, strong duality) ì„ ë‘ ê°€ì§€ subproblem ìœ¼ë¡œ ë‚˜ëˆˆë‹¤. ì´ ë‘ subproblem ì€ ê°ê° stochastic gradient descent ì™€ analyticí•œ ê´€ì ì—ì„œ iterative í•˜ê²Œ ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤. </p> <h2 id="experiments">Experiments</h2> <p>ë‹¤ìŒ ë°ì´í„°ì…‹ì„ ì´ìš©í•´ ì‹¤í—˜í•œë‹¤.</p> <ul> <li>ISOLET (617 dimension): speech data of people speaking the names of letter (alphabet)</li> </ul> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/cf3a5286-23fe-452c-a70f-9d81ab47cce2/image.png" alt=""></p> <p>LassoNet ìœ¼ë¡œ ìœ ì˜ë§ˆí•œ feature extraction ì„ ìˆ˜í–‰í•œ ë’¤, decoder classification acc ì™€ XTree classification acc ë¥¼ ê´€ì°°í•˜ì˜€ë‹¤. </p> <h2 id="application-to-unsupervised-feature-selection">Application to Unsupervised Feature Selection</h2> <p>MNIST ë°ì´í„°ì…‹ì„ ì´ìš©í•œ feature extraction ì„±ëŠ¥ì„ í™•ì¸í•˜ê¸° ìœ„í•´, decoder ë¡œ ì´ë¯¸ì§€ë¥¼ ë³µì›í–ˆë‹¤. íŠ¹íˆ, GROUP-LASSO ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬, ëª¨ë“  ê°™ì€ set ì˜ selected feature ê°€ all reconstructed input ì— ë™ì¼í•˜ê²Œ ì ìš©ë˜ë„ë¡ í•˜ì˜€ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/58737a03-7afe-43ee-a985-fadbb2e46f6b/image.png" alt=""></p> <p>ì™¼ìª½ì€ test images, ì˜¤ë¥¸ìª½ì€ LassoNet ìœ¼ë¡œ ë³µì›í•œ ê²°ê³¼ì´ë‹¤.</p> <h2 id="application-to-matrix-completion">Application to Matrix Completion</h2> <p>ëª‡ëª‡ biomedical data ë“±ì˜ ë°ì´í„°ëŠ” ì¢…ì¢… measurement ìì²´ì˜ cost ê°€ ë†’ê±°ë‚˜ ë°ì´í„° ìˆ˜ì§‘ ë‚ ì§œ ë“±ì˜ ë‹¤ì–‘í•œ ìš”ì¸ì— ì˜í•´ ë°ì´í„° ì†Œì‹¤ ë¬¸ì œì— ë¶€ë”ªíŒë‹¤. ì¦‰ missing row ê°€ ë§ì€ í¸ì´ë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ matrix completion problem ì´ ì—°êµ¬ë˜ì–´ ì™”ëŠ”ë°, ëŒ€í‘œì ìœ¼ë¡œ soft-impute algorithm ì€ underlying data ê°€ low-rank ê°€ì •ì„ ìš”í•œë‹¤. (singular value ì´ìš©) </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/a09a97c3-7ba5-4747-978f-2bb5e898be09/image.png" alt=""></p> <p>LassoNet ì˜ ê²°ê³¼ì™€ í•¨ê»˜ ê¸°ì¡´ ë°©ì‹ì˜ í•œê³„ì ì„ ì§€ì í•œë‹¤.</p> <ol> <li>low rank assumption ì´ í•­ìƒ ëª¨ë“  ë°ì´í„°ì— ì í•©í•˜ì§€ ì•Šë‹¤. </li> <li>model ì˜ linear assumption ì´ ë“¤ì–´ë§ì§€ ì•Šì„ ë•Œ ì„±ëŠ¥ì´ í¬ê²Œ í•˜ë½í•œë‹¤.</li> </ol> <p>LassoNet ì€ iterative í•˜ê²Œ ì ì ˆí•œ feature ë¥¼ ì„ íƒí•˜ë©° feature ê°œìˆ˜ê¹Œì§€ tuning ê°€ëŠ¥í•˜ê³ , hyperparameter ë¥¼ í†µí•´ ë°ì´í„°ì˜ linearity ë¿ë§Œ ì•„ë‹ˆë¼ non-linearity ë˜í•œ í¬í•¨í•  ìˆ˜ ìˆê¸°ì— ì„±ëŠ¥ì´ ë” ì˜ ë‚˜ì˜¬ ìˆ˜ ìˆì—ˆë‹¤ê³  ì„¤ëª…í•œë‹¤.</p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; January 25, 2023 &nbsp; &middot; &nbsp; velog.io </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p></li> <li><h3> <a class="post-title" href="/blog/2022/giscus-comments/">a post with giscus comments</a> </h3> <p>an example of a blog post with giscus comments</p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; December 10, 2022 </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> &nbsp; &middot; &nbsp; <a href="/blog/tag/comments"> <i class="fas fa-hashtag fa-sm"></i> comments</a> &nbsp; &nbsp; &middot; &nbsp; <a href="/blog/category/sample-posts"> <i class="fas fa-tag fa-sm"></i> sample-posts</a> &nbsp; <a href="/blog/category/external-services"> <i class="fas fa-tag fa-sm"></i> external-services</a> &nbsp; </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-VICRegL-Self-Supervised-Learning-of-Local-Visual-Features" target="_blank">[Paper Review] VICRegL: Self-Supervised Learning of Local Visual Features</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="vicregl-self-supervised-learning-of-local-visual-features">VICRegL: Self-Supervised Learning of Local Visual Features</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/b7c932cc-cc96-4b1d-a3a9-d890e8ba3d3c/image.png" alt=""></p> <p>2021ë…„ facebook AI (FAIR) ì—ì„œ ì—°êµ¬í–ˆë˜ VICReg ì˜ í›„ì† ì—°êµ¬ë¡œ VICRegL ê°€ ì–¼ë§ˆì „ Neurips2022 ì— accept ë˜ì—ˆë‹¤. VICReg ëŠ” contrastive learning loss ì™€ non-contrastive loss ì„ ë™ì‹œì— ê³„ì‚°í•´ weighted sum í•˜ì—¬ ëª¨ë¸ì˜ collapse ë¥¼ ë°©ì§€í•˜ê³ ì í•˜ì˜€ë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” VICRegì˜ loss ë¥¼ ì‚¬ìš©í•˜ë˜, ì¤‘ê°„ ë‹¨ê³„ì—ì„œ local property ë¥¼ í™œìš©í•˜ê³ ì feature map ì„ í™œìš©í•´ local criterion ì„ ì¶”ê°€í•˜ì—¬, local view ê°€ ì¤‘ìš”í•œ segmentation task ì—ì„œ state-of-the-art ì„±ëŠ¥ì„ ê¸°ë¡í•˜ê³ , coefficient ì— ë”°ë¥¸ trade-off ë¥¼ ê´€ì°°í•˜ì˜€ë‹¤. </p> <h2 id="introduction">Introduction</h2> <p>ìµœê·¼ self-supervised learning ë°©ì‹ì€ image augmentation ì„ í†µí•´ ìƒì„±ëœ different view ì˜ image ë¥¼, joint embedding architecture ì™€ loss function ë¡œ global feature ë¥¼ í•™ìŠµí•œë‹¤. semantic segmentation ê³¼ ê°™ì€, spatial information ì´ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ëŠ” task ì—ì„œëŠ”, local image structure ë„ focus í•œë‹¤. </p> <p>small parts of image ë¥¼ ë¬˜ì‚¬í•˜ëŠ” local feature ë¥¼ ë°°ìš°ê¸° ìœ„í•œ ë°©ë²•ìœ¼ë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì„¸ ê°œë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤. </p> <ol> <li>pixel level, which forces consistency between pixels at similar location </li> <li>feature map level, which forces consistency between groups of pixels</li> <li>image region level, which forces consistency between large regions that overlap in different views</li> </ol> <p>í•µì‹¬ì€, forces consistency, ë¹„ìŠ·í•˜ê²Œ ìƒê°í•  ê²ƒì€ ë¹„ìŠ·í•˜ê²Œ ì²˜ë¦¬í•˜ë„ë¡ ëª…ë ¹í•˜ê³ , ë‹¤ë¥´ê²Œ ìƒê°í•  ê²ƒì€ ë‹¤ë¥´ê²Œ ì²˜ë¦¬í•˜ë„ë¡ ëª…ë ¹í•˜ëŠ” ê²ƒì´ë‹¤. VICRegL ëŠ” feature map level ì—ì„œ, pixel space ìƒ ê°€ê¹Œì´ ìˆëŠ” ëŒ€ìƒë“¤ë¿ë§Œ ì•„ë‹ˆë¼, ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆëŠ” object ê°„ ê³ ë ¤í•  ìˆ˜ ìˆëŠ” ì•„í‚¤í…ì³ë¥¼ ì œì•ˆí•œë‹¤. </p> <h2 id="method">Method</h2> <h3 id="background">Background</h3> <p>VICReg ëŠ” variance term, invariance term, covariance term ì„ í™œìš©í•œ self-supervised learning ì´ë‹¤. variance term ì€ embedding vector ê°„ì˜ variance ë¥¼ íŠ¹ì • standard deviation ì•„ë˜ë¡œ ë–¨ì–´ì§€ì§€ ì•Šë„ë¡ hinge loss ë¥¼ ì‚¬ìš©í•œë‹¤. invariance term ì€ l2 loss ë¥¼ ì´ìš©í•´ Siamese architecture ì˜ ë‘ branch ë¡œë¶€í„° ë‚˜ì˜¨ feature ê°„ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•œë‹¤. covariance term ì€ embedding vectoro ì˜ covariance matrix ì˜ off-diagnoal term ì„ 0ìœ¼ë¡œ ë³´ëƒ„ìœ¼ë¡œì¨, different dimension ì„ decorrelate í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•œë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/3763462b-f912-473e-9df1-9d30becaed92/image.png" alt=""></p> <h3 id="vicregl-feature-vectors-matching">VICRegL: feature vectors matching</h3> <p>ìœ„ ê·¸ë ¤ì§„ VICReg ì˜ êµ¬ì¡°ë¥¼ ë³´ë©´, y ê°€ ê·¸ëŒ€ë¡œ global expander ë¥¼ í†µê³¼í•´ íŠ¹ì • dimension (D) ë¡œ mapping ëœë‹¤. VICRegL ì€ VICReg ì˜ global expanderì™€ loss ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë˜, local feature ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ê²½ë¡œë¥¼ ë„ì…í•œë‹¤. seed image x ê°€ convolutional encoder ë¥¼ í†µê³¼í•œ feature map (C x H x W) ì„ y, x&#39;ì˜ feature map (C x H x W) ì˜ feature map ì„ y&#39; ì´ë¼ í•˜ì. ì´ ë•Œ, $y_{i,j}$ ëŠ” C dimension ì„ ê°€ì§„, ì¦‰ H x W grid ìƒ í•œ ì ì´ë¼ê³  í•˜ì. ì´ ë…¼ë¬¸ì˜ í•µì‹¬ì€ ì´ $y_{i,j}$ ì™€ $y&#39;<em>{i,j}$ ë¥¼ ì ì ˆíˆ match ì‹œì¼œ VICreg ì˜ criterion ì„ ì ìš©í•˜ëŠ” ê²ƒì´ë‹¤. ê·¸ ì „ì—, y ì™€ y&#39; ì„ local projector ë¥¼ í†µí•´ (D x H x W) dimension ì„ ê°€ì§„ z ì™€ z&#39; ë¥¼ ë§Œë“¤ê³ , y ì™€ y&#39; ì˜ ì •ë³´ &amp; z ì™€ z&#39;ì˜ ì •ë³´ë¡œ ì–´ë–¤ $z</em>{i,j}$ ì™€ $z&#39;_{i,j}$ ì„ ë§¤ì¹˜í•´ì„œ ê³„ì‚°í• ì§€ ê²°ì • ì§“ëŠ” ê²ƒì´ë‹¤. ì•ì„œ ì–¸ê¸‰í–ˆë“¯ì´ matching ê³¼ì •ì€, feature map ìƒ ì‹¤ì œ ê±°ë¦¬ë¥¼ ê³ ë ¤í•œ location-based matching ê³¼, ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆì–´ë„ ê°™ì€ object ì¸ small part ë„ ê³ ë ¤í•˜ê¸° ìœ„í•œ feature-based matching ë¡œ êµ¬ì„±ëœë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/b7c932cc-cc96-4b1d-a3a9-d890e8ba3d3c/image.png" alt=""></p> <h3 id="location-based-matching">Location-based matching</h3> <p>image I ì— ëŒ€í•´ ë‘ view x, x&#39; ì˜ similar location ìœ¼ë¡œë¶€í„° ë‚˜ì˜¨ feature ë¥¼ match ì‹œì¼œ VICReg criterion ì„ ì ìš©í•œë‹¤. ë¨¼ì € absolute position in I ì— ë”°ë¼, each feature vector $z_p$ at position p ëŠ”, its spatial nearest neighbor ê³¼ match ëœë‹¤ (1:1 match). ê·¸ë¦¬ê³  ê³„ì‚°ëœ H x W pairs ì¤‘ only top-$\gamma$ ê°œì˜ pairs ë§Œ keep ëœë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/66874db2-982a-4ddf-9790-a05744088f09/image.png" alt=""></p> <p>ì´ë•Œ, P ëŠ” H x W ìƒì˜ ì  í•˜ë‚˜ë¥¼ ì˜ë¯¸í•˜ê³ , $z&#39;_{NN(p)}$ ëŠ” pì— ë”°ë¼ ê²°ì •ë˜ëŠ” spatially closest coordinate p&#39; ë¥¼ ì˜ë¯¸í•œë‹¤. (ìœ„ ì‹ì—ëŠ” top-$\gamma$ì— ëŒ€í•œ ì •ë³´ëŠ” ìƒëµë˜ì–´ ìˆë‹¤.)</p> <h3 id="feature-based-matching">Feature-based matching</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/01bdc36a-10a6-4da9-bfd2-2a4dc15c2bf8/image.png" alt=""></p> <p>Feature-based matching ì„ ìœ„í•´, embedding space ì—ì„œì˜ l2-distance ì •ë³´ë¥¼ ì´ìš©í•œë‹¤. feature vector $z_p$ì— ëŒ€í•´, feature map z&#39; ì—ì„œ, l2 distance ê°€ ê°€ì¥ ì‘ì€ feature vector NN&#39;($z_p$) ì™€ matching í•˜ì—¬ VICReg criterion ì„ ì ìš©í•œë‹¤. ì´ë¥¼ í†µí•´, same location ì—ì„œ pooled ëœ feature ê°€ ì•„ë‹ˆë”ë¼ë„, long-range interaction ì„ capture í•  ìˆ˜ ìˆë‹¤. </p> <p>General idea of top-$\gamma$ filtering ì€ 1) location-based filtering ì—ì„œ ë„ˆë¬´ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆëŠ” feature vector ê°„ì˜ mismatch ë§‰ê¸° ìœ„í•¨ì´ ìˆê³ , ë¬´ì—‡ë³´ë‹¤ë„ 2) training ì˜ ì´ˆê¸° ë‹¨ê³„ì—ì„œ, feature-based matching ê³¼ì •ì—ì„œ ë‹¤ë¥¸ texture ë‚˜ ë‹¤ë¥¸ object ê°„ì˜ mismatch ë¥¼ ë§‰ê¸° ìœ„í•¨ì´ë‹¤. (ë‚˜ì¤‘ì— gamma ë¥¼ ë°”ê¿”ê°€ë©° ì‹¤í—˜í•¨.) ë˜í•œ, location-based matching ì˜ ê²½ìš°, two view ê°€ ê²¹ì¹˜ì§€ ì•Šì„ ìˆ˜ ìˆëŠ”ë°, ì´ëŠ” í™•ë¥ ì´ ë‚®ê³  ê´€ë ¨ ì‹¤í—˜ë„ ì§„í–‰í–ˆì„ ë•Œ, ì„±ëŠ¥ì— í° ì˜í–¥ì„ ì£¼ì§€ ì•Šì•˜ìŒë„ ì–¸ê¸‰í•˜ì˜€ë‹¤. </p> <h3 id="final-loss-function">Final loss function</h3> <p>ìµœì¢… loss term ì€ location-based &amp; feature-based loss function ì„ combination í•œ ê²ƒê³¼, global view ì— VICReg criterion ì„ ì ìš©í•œ loss function ì„ í•œ ë²ˆ ë” alpha ë¼ëŠ” coefficient ë¡œ combination í•œ í˜•íƒœë¥¼ ëˆë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/32efe6c5-d234-4f50-8ad9-46f4d289f389/image.png" alt=""></p> <h3 id="vicregl-with-the-convnext-backbone">VICRegL with the ConvNeXt backbone</h3> <p>ì´ë²ˆ ë…¼ë¬¸ì—ì„œ ResNet-50 backbone ì„ ì‚¬ìš©í•œ experimental result ë„ ë³´ê³  í–ˆì§€ë§Œ, ë‹¤ë¥¸ backbone ì„ í™œìš©í•´ì„œë„ ì‹¤í—˜í–ˆê³  ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆìŒì„ í™•ì¸í•˜ì˜€ë‹¤. 2022ë…„ ì œì•ˆëœ ConvNeXt architecture ë¥¼ í™œìš©í•˜ì—¬ state-of-the-art ì„±ëŠ¥ì„ í™•ì¸í•˜ì˜€ê³ , ì´ëŠ” self-supervised learning ì—ì„œ ConvNeXt ë¥¼ ì‚¬ìš©í•œ ì²« ì‹œë„ë¼ê³  ì–¸ê¸‰í•˜ê³  ìˆë‹¤.</p> <p>ë˜í•œ Swav ë…¼ë¬¸ì—ì„œ ì œì•ˆë˜ì–´ ì‚¬ìš©ë˜ê³  ìˆëŠ” multi-crop strategy ë„ ì‚¬ìš©í•˜ì˜€ë‹¤. ê°„ë‹¨íˆ ì–¸ê¸‰í•˜ë©´, ê¸°ì¡´ contrastive loss ëŠ” ë‘ ê°œì˜ different view ë“¤ë¡œë¶€í„° ê³„ì‚°í•˜ì§€ë§Œ, multi-crop strategy ëŠ” N ê°œì˜ different view ë“¤ë¡œë¶€í„° loss ë¥¼ ê³„ì‚°í•œë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, 2ê°œì˜ large crop ê³¼ N-2 ê°œì˜ small crop ì„ ì‚¬ìš©í•˜ê³ , large image ë§Œì„ pivot ì‚¼ì•„ large-small (ë˜ëŠ” large-large) view ê°„ì˜ ë¹„êµë¥¼ í†µí•´ computational efficient ì™€ performance importance ë‘ ì¸¡ë©´ì˜ trade-off ë¥¼ ìµœì†Œí™” í•˜ëŠ” ë°©ì‹ì´ë‹¤. ë§ë¡œë§Œ í•˜ë©´ ì´í•´ê°€ ì•ˆë í…Œë‹ˆ ì‹ìœ¼ë¡œ ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. ($\gamma_1$=20, $\gamma_2$=4) </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/fba1da46-3b35-4fdd-8d25-76e7798b107c/image.png" alt=""></p> <p>m ì€ large crop image, n ì€ small crop image ë¥¼ ì˜ë¯¸í•œë‹¤. ì›ë˜ N ê°œì˜ different view ë¥¼ ì‚¬ìš©í•˜ë©´, $N^2$ ë²ˆì˜ ë¹„êµë¥¼ ê±°ì³ì•¼ í•˜ì§€ë§Œ, ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ì„ ì‚¬ìš©í•˜ë©´ $2(N-1)$ ë²ˆì˜ computation ë§Œ ê±°ì¹˜ë©´ ëœë‹¤. location-based matching loss ì´ì™¸ì—ë„ feature-based matching loss ì™€ ê¸°ì¡´ global loss ì—ë„ ë¹„ìŠ·í•˜ê²Œ ì ìš©ëœë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/d1b86e03-26ef-4819-bcb3-09456860aa11/image.png" alt=""></p> <h3 id="implementation-details">Implementation details</h3> <ul> <li>best ResNet-50, ConvNeXts</li> <li>pretrained on the 100-class unlabeled ImageNet dataset</li> <li>most hyperparameter unchanged, Bardes et al., 2022</li> <li>VICReg criterion coefficient ratio 25:25:1</li> <li>global expander is 3-layers fully-connected network (2048-8192-8192-8192)</li> <li>local projector, due to memory limitation, small (2048-512-512-512)</li> <li>GPU: Nvidia Tesla V100-32Gb GPU, R50:32(2048), Cs:8(384), Cb:16(572)</li> </ul> <h2 id="experimental-results">Experimental Results</h2> <p>ë‹¤ì–‘í•œ ì¡°ê±´ì„ ë°”ê¿”ê°€ë©° ì‹¤í—˜í•˜ì˜€ë‹¤. main observation ìœ¼ë¡œ, VICRegL ì€ strongly improves on segmentation results over VICReg ì™€ ë™ì‹œì—, preserving classification performance ì˜€ë‹¤. </p> <h3 id="comparision-with-prior-work">Comparision with prior work</h3> <p><strong>ResNet-50 Backbone</strong></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/d421687b-0607-49c5-ac28-af9220b09ad1/image.png" alt=""></p> <p>made improvement of VICRegL over VICReg on linear segmentation, cityscape ëŠ” ëŒ€ë¶€ë¶„ ì„±ëŠ¥ ì•ˆì¢‹ìŒ, global feature ì™€ local feature ë¥¼ ë™ì‹œì— ì‚¬ìš©í•œ ê²ƒì— ê¸°ì¸í•œ robustness.</p> <p><strong>ConvNeXt Backbone</strong></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/d2db5f2f-611a-4b17-b871-fe4f9f72a982/image.png" alt=""></p> <p>linear segmentation task ì—ì„œ, CNX-XL ì„ ì‚¬ìš©í–ˆì„ ë•Œ state-of-the-art ë‹¬ì„± alpha ê°’ì— ë”°ë¥¸ classification / segmentation performance trade-off</p> <h3 id="ablations">Ablations</h3> <p>CNX-S ImageNet over 100 epoch ê²°ê³¼ë¡œ í†µì¼. linear classification ë° linear frozen segmentation mIOU ê°ê° ImageNet ê³¼ Pascal VOC ì—ì„œ ì¸¡ì •</p> <p><strong>Trade-off between the local and global criterion</strong> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/35202acd-4725-494a-9720-f5347f7af18c/image.png" alt=""></p> <p>alpha&lt;1 ì„ ì ìš©í–ˆì„ ë•Œ, segmentation performance is greatly increased existence of a sweet spot, where the model performs both tasks</p> <p><strong>Study of the importance between feature-based and location-based local criteria</strong> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/294ce5b2-5a5a-4a4e-8067-875b600d0ef7/image.png" alt=""></p> <p>ë‘ component ê°€ í•¨ê»˜ í•  ë•Œ classification performance ë°©ì–´ì™€ segmentation performance improvement ë©´ì—ì„œ ì˜ë¯¸ê°€ ìˆìŒ.</p> <p><strong>Study of the number of matches</strong> multicrop ì„ ì‚¬ìš©í•˜ë©´, large viewì™€ small view ê°€ ë§Œë“¤ì–´ì§€ê³  ê·¸ì— ë”°ë¥¸ feature map í¬ê¸°ë„ (7x7), (3x3) ìœ¼ë¡œ ë‹¬ë¼ì§„ë‹¤. ì´ì— ë”°ë¼ top-$\gamma$ ì˜ gamma1, gamma2 ë¥¼ ë‚˜ëˆ„ì—ˆê³  ì´ ê°’ë“¤ì„ ë‹¬ë¦¬í•˜ì—¬ ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ìŒ.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/1ff6d2ee-6d00-42a3-8c72-4b5a291c5d5b/image.png" alt=""></p> <p>ìµœì†Œí•œìœ¼ë¡œ ì¤„ì´ê±°ë‚˜ ìµœëŒ€ë¡œ ëŠ˜ë ¸ì„ ë•Œë„ ì„±ëŠ¥ì´ ê´œì°®ì•˜ì§€ë§Œ, between ê°’ì„ í–ˆì„ ë•Œ ê°€ì¥ ì¢‹ìŒ.</p> <p><strong>Study of VICReg components for the local criterion, Multi-crop strategy</strong> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/b7cd6144-20d8-4c99-a6f8-9b251d633512/image.png" alt=""></p> <p><strong>SimCLR + local feature network</strong> local feature network ì—ì„œ ì‚¬ìš©í•˜ë˜ VICReg criterion ëŒ€ì‹  SimCLR loss ë¥¼ ì ìš©í•¨. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/24462f4c-27ba-49d9-834e-95e571586c5e/image.png" alt=""></p> <p>SimCLR ë³´ë‹¤ SimCLR-L ì—ì„œ additional benefit ì´ í™•ì¸ë˜ì—ˆê³ , VICRegì™€ VICRegL ì‚¬ì´ì˜ additional benefit ì˜ í­ì´, SimCLRì˜ ê·¸ê²ƒë³´ë‹¤ ë” ì»¸ìŒ.</p> <h3 id="visualization">Visualization</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/cb95589a-182f-4432-8d4a-ef9781f3abbc/image.png" alt=""></p> <p>ì™¼ìª½ column ì˜ ë¹¨ê°•íŒŒë‘ì€ feature-based matching, ì˜¤ë¥¸ìª½ colum ì˜ ë¹¨ê°• íŒŒë‘ì€ location-based matching ì„ ì˜ë¯¸í•œë‹¤. ì‹¤í—˜ ìƒ 20ê°œì˜ best match ë¥¼ ê³¨ëì§€ë§Œ ì—¬ê¸°ëŠ” visualziation ì„ ìœ„í•´ ëª‡ê°œë¥¼ ìƒëµí•˜ì˜€ë‹¤. ë˜í•œ, ë…¸ë€ ì„ ì€ matching ëœ pair ë¥¼ ì˜ë¯¸í•˜ê³ , grid ë¡œ ë‚˜ëˆ„ì—ˆì§€ë§Œ ì‹¤ì œ receptive field ëŠ” í›¨ì”¬ í¬ë‹¤. </p> <p>ë¹„ì˜¤ëŠ” ë‚ ì—” ì¹´í˜ì—ì„œ ë…¼ë¬¸ ë¦¬ë·°... ì§‘ì¤‘ ì˜ëœë‹¤ íˆíˆ</p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; October 9, 2022 &nbsp; &middot; &nbsp; velog.io </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p></li> </ul> <nav aria-label="Blog page naviation"> <ul class="pagination pagination-lg justify-content-center"> <li class="page-item "> <a class="page-link" href="/blog/page/3/" tabindex="-1" aria-disabled="3">Newer</a> </li><li class="page-item "><a class="page-link" href="/blog/page/3/index.html" title="blog - page 3">3</a></li> <li class="page-item active"><a class="page-link" href="/blog/page/4/index.html" title="blog - page 4">4</a></li> <li class="page-item "><a class="page-link" href="/blog/page/5/index.html" title="blog - page 5">5</a></li> <li class="page-item "><a class="page-link" href="/blog/page/6/index.html" title="blog - page 6">6</a></li> <li class="page-item "><a class="page-link" href="/blog/page/7/index.html" title="blog - page 7">7</a></li> <li class="page-item "> <a class="page-link" href="/blog/page/5/">Older</a> </li> </ul> </nav> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> &copy; Copyright 2023 JaeHeon Lee. Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>