<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>blog - page 6 | JaeHeon Lee</title> <meta name="author" content="JaeHeon Lee"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ğŸ§ </text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://jaeheon-lee486.github.io/blog/page/6/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">JaeHeon&nbsp;</span>Lee</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <div class="header-bar"> <h1>al-folio</h1> <h2>a simple whitespace theme for academics</h2> </div> <div class="tag-category-list"> <ul class="p-0 m-0"> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/formatting">formatting</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/images">images</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/links">links</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/math">math</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/code">code</a> </li> <p>&bull;</p> <li> <i class="fas fa-tag fa-sm"></i> <a href="/blog/category/blockquotes">blockquotes</a> </li> </ul> </div> <br> <div class="container featured-posts"> <div class="row row-cols-2"> <div class="card-item col"> <a href="/blog/2021/distill/"> <div class="card hoverable"> <div class="row g-0"> <div class="col-md-12"> <div class="card-body"> <div class="float-right"> <i class="fa-solid fa-thumbtack fa-xs"></i> </div> <h3 class="card-title text-lowercase">a distill-style blog post</h3> <p class="card-text">an example of a distill-style blog post and main elements</p> <p class="post-meta"> 8 min read &nbsp; &middot; &nbsp; <a href="/blog/2021"> <i class="fas fa-calendar fa-sm"></i> 2021 </a> </p> </div> </div> </div> </div> </a> </div> <div class="card-item col"> <a href="/blog/2015/code/"> <div class="card hoverable"> <div class="row g-0"> <div class="col-md-12"> <div class="card-body"> <div class="float-right"> <i class="fa-solid fa-thumbtack fa-xs"></i> </div> <h3 class="card-title text-lowercase">a post with code</h3> <p class="card-text">an example of a blog post with some code</p> <p class="post-meta"> 4 min read &nbsp; &middot; &nbsp; <a href="/blog/2015"> <i class="fas fa-calendar fa-sm"></i> 2015 </a> </p> </div> </div> </div> </div> </a> </div> </div> </div> <hr> <ul class="post-list"> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-Unsupervised-Learning-of-Visual-Features-by-Contrasting-Cluster-Assignments-SwAV" target="_blank">[Paper Review] Unsupervised Learning of Visual Features by Contrasting Cluster Assignments (SwAV)</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="unsupervised-learning-of-visual-features-by-contrasting-cluster-assignments">Unsupervised Learning of Visual Features by Contrasting Cluster Assignments</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/a21ca611-9ff8-4991-9cef-1d32addf68ca/image.png" alt=""></p> <p>SSL ë¶„ì•¼ì—ì„œ ìì£¼ ì¸ìš©ë˜ëŠ” SwAV ëª¨ë¸ì˜ í˜ì´í¼ì´ë‹¤. ê¸°ì¡´ contrastive learning ë°©ì‹ì„ ì‚¬ìš©í•˜ë˜, pairwise comparison ì„ ê³„ì‚°í•  í•„ìš” ì—†ì–´ online ìœ¼ë¡œë„ ì‚¬ìš©í•œ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤. Swapping Assignments between multiple Views of the same image (SwAV) ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê°™ì€ ì´ë¯¸ì§€ë¡œë¶€í„° ìƒì„±ëœ representation vector ê°€ ê°™ì€ prototype class ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµëœë‹¤. memory bank ë‚˜ momentum network ëŒ€ì‹  prototype (class) matrix ë¥¼ í™œìš©í•˜ê¸°ì— íš¨ìœ¨ì ì´ê³ , multi-crop ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ resolution ì´ë¯¸ì§€ëŠ” standard crop (full resolution crop) ê³¼ ë‹¬ë¦¬ prototype ì— í• ë‹¹í•˜ì§€ ì•ŠìŒìœ¼ë¡œì¨ ë©”ëª¨ë¦¬ì™€ ì†ë„ ë©´ì—ì„œ í–¥ìƒì´ ìˆì—ˆë‹¤. í•™ìŠµì— ì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦¬ê¸°ëŠ” í•˜ë‚˜, ì„±ëŠ¥ ë©´ì—ì„œ supervised learning ì— ê°€ì¥ ê·¼ì ‘í•œ unsupervised learning ë°©ì‹ìœ¼ë¡œ ì†Œê°œëœë‹¤. </p> <h2 id="introduction">Introduction</h2> <p>Self-supervised learning ë°©ì‹ì—ì„œëŠ”, same image ì—ì„œ ë‹¤ë¥¸ augmentation ì„ ì ìš©ëœ image ë¥¼ ìƒì„± í›„ ê·¸ë“¤ë¼ë¦¬ëŠ” ê°€ê¹ê²Œ, ë‹¤ë¥¸ imageë¡œë¶€í„° ìƒì„±ëœ augmentated image ì™€ëŠ” ë©€ë¦¬ embedding í•˜ëŠ” ê²ƒì´ ê°€ì¥ ê¸°ë³¸ì´ ëœë‹¤. í•˜ì§€ë§Œ ëª¨ë“  instance ë¼ë¦¬ ë¹„êµí•˜ëŠ” ê²ƒì€ ì‚¬ì‹¤ìƒ ë¶ˆê°€ëŠ¥í•˜ê¸°ì—, random subset (batch) ì•ˆì˜ instance ë¼ë¦¬ ë¹„êµí•˜ê±°ë‚˜, clustering ì„ í†µí•´ ì´ instance discrimination problemì„ relax í•´ì¤€ë‹¤. (í›„ì ë°©ì‹ì˜) ì˜ˆë¥¼ ë“¤ì–´ DeepCluster ë°©ì‹ì—ì„œëŠ” instance ë¼ë¦¬ì˜ contrastive learning ì´ ì•„ë‹ˆë¼ group of instances ì¦‰ clustering ë¼ë¦¬ì˜ contrastive learning ì´ ì´ë£¨ì–´ì§„ë‹¤. í•˜ì§€ë§Œ, (ì´ ë°©ì‹ì€ tractable í•¨ì—ë„ ë¶ˆêµ¬í•˜ê³ ) scalable í•˜ì§€ ì•Šë‹¤. í•™ìŠµì„ í†µí•´ í˜•ì„±ë˜ëŠ” clustering assignments ëŠ” ê²°êµ­ ëª¨ë“  dataset image ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì´ë‹¤. </p> <p>ê·¸ë ‡ê¸°ì— ì´ ë…¼ë¬¸ì—ì„œëŠ” same image ë¡œë¶€í„° ë‹¤ë¥¸ augmentationì„ ì ìš©í•´ ë‚˜ì˜¨ code (clustering assignment)ë“¤ë¼ë¦¬ì˜ consistencyëŠ” ìœ ì§€í•´ì£¼ë©´ì„œ, &quot;online&quot; ë°©ì‹ìœ¼ë¡œ codeë¥¼ ê³„ì‚°í•˜ëŠ” ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•œë‹¤. <em>deepcluster ë°©ì‹ì„ ì•„ì§ ì•ˆ ì½ì–´ë´ì„œ ëª¨ë¥´ì§€ë§Œ, ì´ ë…¼ë¬¸ì—ì„œëŠ” code (prototype) matrix ë¥¼ encoderì™€ ë¶„ë¦¬í•˜ì—¬ ë§Œë“¤ê³ , error propagation ì´ ë”°ë¡œ ì´ë£¨ì–´ì§„ë‹¤.</em> </p> <p>ë˜í•œ ê¸°ì¡´ contrastive method ëŠ” ì´ë¯¸ì§€ í•˜ë‚˜ ë‹¹ í•œ ìŒì˜ transformation ë¼ë¦¬ ë¹„êµí–ˆë˜ ê²ƒê³¼ ë‹¬ë¦¬, SwAV ëŠ” multi-crop ë°©ì‹ìœ¼ë¡œ ìƒì„±ëœ small-sized ì´ë¯¸ì§€ë“¤ë„ loss ê³„ì‚° ê³¼ì • ì•ˆì— ë„£ì–´ ì„±ëŠ¥ì„ ê°œì„ í•œë‹¤. </p> <p>ê·¸ ê²°ê³¼ scalable online clustering loss ëŠ” momentum encoderë‚˜ large memory bank ì—†ì´ ImageNet ì—ì„œ +2% ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì˜€ê³ , multi-crop ë°©ì‹ì€ ë‹¤ë¥¸ SSL ë°©ì‹ë“¤ ë³´ë‹¤ 2%-4% í–¥ìƒë˜ì—ˆìœ¼ë©°, self-supervised on ImageNet with a standard ResNet model ë¡œ 4.2% í–¥ìƒ, supervised ImageNet pretrainingë¥¼ ê±°ì§„ ì—¬ëŸ¬ downstream task ì— ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ë‹¤.</p> <h2 id="related-work">Related Work</h2> <p>ë³´í†µ ì´ íŒŒíŠ¸ëŠ” ê±´ë„ˆ ë›°ëŠ”ë° ë‹¤ë¥¸ contrastive learning ë°©ì‹ê³¼ ë¹„êµí–ˆì„ ë•Œ SwAV ì´ ê°€ì§€ëŠ” ê²½ìŸë ¥, ì°¨ë³„ì ì„ ë´ì•¼í•  í•„ìš”ê°€ ìˆì–´ë³´ì—¬ ì‘ì„±í•œë‹¤.</p> <h3 id="instance-and-contrastive-learning">Instance and contrastive learning</h3> <p>ê¸°ì¡´ unsupervised learning ì—ì„œëŠ” ê° ì´ë¯¸ì§€ë¥¼ class ì— í• ë‹¹í•˜ê³ , ì´ class ë’¤ì— linear classifier ë¥¼ ë¶™ì—¬ í•™ìŠµì„ ì§„í–‰í–ˆë‹¤. í•˜ì§€ë§Œ ì´ ê³¼ì •ì€ ë¹ ë¥´ê²Œ become intractable í–ˆê¸°ì—, ì´ì „ì— ê³„ì‚°ëœ representationì„ ì €ì¥í•˜ëŠ” memory bank ë¥¼ classifier ëŒ€ì‹  ì‚¬ìš©í•˜ì—¬ ë¬¸ì œë¥¼ ê°œì„ í•˜ì˜€ë‹¤. ë³´í†µ noise contrastive estimation, ë‹¤ì‹œ ë§í•´ InfoNCE ë°©ì‹ì„ ì‚¬ìš©í•˜ì˜€ê³ , MoCo ì—ì„œëŠ” reprsentation ì„ momentum encoder ì— ì €ì¥í•˜ì˜€ë‹¤. SimSiam ì—ì„œëŠ” momentum encoder ì—†ì´ batch size ê°€ í¬ë‹¤ë©´ í•™ìŠµì´ ì´ë£¨ì–´ì§ë„ ë°í˜€ì¡Œë‹¤. ì´ë ‡ê²Œ ëª¨ë“  instance ë¼ë¦¬ pairwiseí•˜ê²Œ similarity ë¥¼ ê³„ì‚°í•˜ë˜ ê¸°ì¡´ ì—°êµ¬ì™€ëŠ” ë‹¬ë¦¬, SwAV ì—ì„œëŠ” image feature ë¥¼ í•™ìŠµ ê°€ëŠ¥í•œ (trainable) prototype vector ì— mapping í•˜ì—¬ ì´ë¥¼ í•™ìŠµì— í™œìš©í•˜ëŠ” ë°©ì‹ì„ ì·¨í•œë‹¤.</p> <h3 id="clustering-for-deep-representation-learning">Clustering for deep representation learning</h3> <p>DeepCluster ì—ì„œ k-means assignments ë¥¼ pseudo-label ë¡œ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí–ˆì„ ë•Œ large uncurated dataset ì— ëŒ€í•´ì„œë„ í™•ì¥ ê°€ëŠ¥í•˜ê³  downstream task ì—ë„ ì‚¬ìš© ê°€ëŠ¥í•¨ì„ ë³´ì˜€ë‹¤. í•˜ì§€ë§Œ ì´ ë°©ì‹ì€ formulation is not principled ë˜ì—ˆì—ˆê³  ì¶”í›„ ì—°êµ¬ (Asano <em>et al.</em>) ì—ì„œ psuedo-label problem ê³¼ optimal transport problem ì—°ê²° ì§“ëŠ” ë°©ë²• (how to cast ~) ì„ ì œì‹œí•˜ì˜€ë‹¤. ì´ ì—°êµ¬ì—ì„œë„ ë¹„ìŠ·í•œ formulation ì„ ì‚¬ìš©í•˜ì˜€ì§€ë§Œ Asano ì˜ ì—°êµ¬ì²˜ëŸ¼ Sinkhorn-Knopp algorithm output ì„ hard label ì— approximating í•˜ì§€ ì•Šê³ , soft label ë¡œ ì‚¬ìš©í•˜ì—¬ prototype vector ë¥¼ í•™ìŠµí•˜ì˜€ë‹¤. ë˜í•œ Asano ì˜ ì—°êµ¬ì™€ëŠ” ë‹¬ë¦¬ online assignment ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì–´ë– í•œ í° ë°ì´í„°ì…‹ì—ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë°©ì‹ìœ¼ë¡œ ë°œì „ì‹œì¼°ë‹¤.</p> <h2 id="method">Method</h2> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/33192de7-f71e-40e1-81fc-6bc000b4a1ff/image.png" alt=""></p> <p>ê°€ì¥ ê°„ë‹¨í•˜ê²Œ (ì´í•´ëŠ” ì•ˆë˜ê² ì§€ë§Œ) ì„¤ëª…í•˜ìë©´ í•œ image ì— ë‹¤ë¥¸ augmentation ì„ ì ìš©í•˜ì—¬ encoder ë¥¼ í†µê³¼ì‹œí‚¨ representation ì„ ê°ê° z ì™€ z&#39; ì´ë¼ê³  í•´ë³´ì. z ë¥¼ trainable í•œ prototype matrix C ë¥¼ í†µí•´ ê°ê°ì˜ code q, q&#39; ë¥¼ ìƒì„±í•œë‹¤. ì´ ë•Œ ë‹¤ë¥¸ augmentation ì„ ì ìš©í–ˆë”ë¼ë„ í•œ image ì—ì„œ ë‚˜ì˜¨ code ì´ê¸° ë•Œë¬¸ì—, z ë¡œ q&#39; ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆì–´ì•¼ í•˜ê³  z&#39; ë¡œ q ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤ëŠ” ì•„ì´ë””ì–´ë¡œë¶€í„°, ë‹¤ìŒê³¼ ê°™ì€ loss ë¥¼ ì‚¬ìš©í•˜ê²Œ ëœë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/b206ca5b-e089-462f-a5bb-2b3ef706d55b/image.png" alt=""></p> <p>ì´ì œ ê¸°ë³¸ theme ì„ ì•Œì•˜ìœ¼ë‹ˆ ê·¸ ë‚´ë¶€ë¥¼ ê¹Œì„œ code ëŠ” ì–´ë–»ê²Œ ìƒì„±ë˜ëŠ” ê²ƒì¸ì§€, prototype matrix C ëŠ” ë¬´ì—‡ì¸ì§€, intro ì— ì†Œê°œëœ multi-crop method ëŠ” ë¬´ì—‡ì¸ì§€ ê·¸ë¦¬ê³  ì™œ ì‚¬ìš©í•˜ëŠ”ì§€ì— ëŒ€í•´ ì†Œê°œí•˜ë„ë¡ í•˜ê² ë‹¤.</p> <h3 id="online-clustering">Online clustering</h3> <p>ê° image $x_n$ ëŠ” transformation t sampled from the set $\tau$ ì„ ì ìš©í•˜ì—¬ $x_{nt}$ ë¥¼ ìƒì„±í•œë‹¤. ì´ë“¤ì€ non-linear mapping (encoder) ë¥¼ ê±°ì³ $z_{nt}$ ë¡œ í‘œí˜„ë˜ê³ , ê° feature ëŠ” normalize ë˜ì–´ unit sphere ìƒì— projection ëœë‹¤. ì´ ë’¤ëŠ” ë…¼ë¬¸ì˜ ì„¤ëª…ì´ë‹¤. </p> <p>We then compute a code $q_{nt}$ from this feature by mapping $z_{nt}$ to a set of K trainable prototypes vectors, {$c_1$ , ..., $c_k$}. We denote by C the matrix whose columns are the $c_1$ , ... , $c_K$. </p> <p>z ë¥¼ c (prototype vector) ë¥¼ í™œìš©í•´ì„œ që¡œ ë§Œë“ ë‹¤ëŠ” ëœ»ì´ë‹¤. ë¶€ì—°ì„¤ëª…ì„ í•˜ìë©´, q ëŠ” z ì™€ c ë¥¼ ì´ì–´ì£¼ëŠ” graph í˜•íƒœì´ë‹¤. C ë¼ëŠ” k ê°œì˜ ëŒ€í‘œ prototype vector ë¥¼ ê°€ì§€ê³  ìˆëŠ” matrix ì™€, z í•˜ë‚˜í•˜ë‚˜ë¥¼ ë¹„êµí–ˆì„ ë•Œ, (ex) ${q_1}$ ëŠ” ${z_1}$ ì´ K ê°œ ì¤‘ ëª‡ ë²ˆì§¸ prototype vector ì™€ ì œì¼ ê°€ê¹Œìš´ì§€ë¥¼ ê³„ì‚°í•˜ì—¬ ì–´ë–¤ prototype vector ì— &quot;í• ë‹¹&quot; í•˜ë©´ ë ì§€ë¥¼ &quot;ì•ˆë‚´&quot; í•´ì£¼ëŠ” ì¼ì¢…ì˜ path í˜¹ì€ label ì´ë¼ê³  ìƒê°í•˜ë©´ í¸í•˜ë‹¤. ê·¹ë‹¨ì ìœ¼ë¡œ ${z_1}$ ì´ (0.06 0.08 0) ì´ê³ , 2ê°œì˜ class vector ê°ê° (0.06, 0.08, 0) (0.08, 0.06, 0) ì„ ê°€ì§„ matrix C ê°€ ìˆì„ ë•Œ (<em>ì´ë ‡ê²Œ ë˜ë©´ matrix C ëŠ” [[0.06 0.08 0]; [0.08 0.06 0]]</em> ) ${q_1}$ ì€ (1, 0) ì´ ë˜ëŠ” ê²ƒì´ë‹¤.</p> <h3 id="swapped-prediction-problem">Swapped prediction problem</h3> <p>ì•„ì§ ëª…í™•íˆ ë‚©ë“ê°€ì§€ëŠ” ì•Šì•˜ê² ì§€ë§Œ, ë‹¤ìŒ ì†Œê°œëœ loss ë¥¼ í•¨ê»˜ ì´í•´í•´ë³´ë„ë¡ í•˜ì. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/842f624a-bbf8-423a-8421-ace3b9c66c61/image.png" alt=""></p> <p>ì–´ë””ì„œ êµ‰ì¥íˆ ë§ì´ ë³¸ loss ì´ì§€ ì•ŠëŠ”ê°€? cross entropy ì‹ ì•ˆì— ë“¤ì–´ê°„ q ì™€ p ì˜ ì²¨ìë¥¼ ìì„¸íˆ ë³´ë©´ ê°ê° s ì™€ t ì´ë‹¤. ì¦‰ ë‹¤ë¥¸ augmentation ì´ ì ìš©ëœ loss ì¸ ê²ƒì´ë‹¤. infoNCE loss ì•ˆì„ ë“¤ì—¬ë‹¤ ë³´ë©´, (ìš°ì„  temperatureê°€ ì“°ì˜€ê³ ), z_t ì™€ ë‹¤ë¥¸ ëª¨ë“  prototype vector ë“¤ê°„ì˜ ê±°ë¦¬ì— ë¹„í•´, ìƒëŒ€ì ì¸ í•´ë‹¹ prototype k vector c_k ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ëœ»í•œë‹¤. ì¦‰ q ëŠ” ì‹¤ì œë¡œ z_s ê°€ ì–´ëŠ prototype vector ì™€ ê°€ì¥ ê°€ê¹Œìš´ì§€ë¥¼ íŠ¹ë³„í•œ ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•´ì„œ &quot;ë‹µì§€ label&quot;ë¥¼ ë§Œë“¤ì–´ë‚¸ ê²ƒì´ê³ , p ëŠ” z ì™€ c_k ì‚¬ì´ì˜ ìƒëŒ€ì ì¸ ê±°ë¦¬ë¥¼ êµ¬í•´ë²„ë¦° ê²ƒì´ë‹¤. ì´ë ‡ê²Œ í•´ì„œ ë‘ í™•ë¥ ì´ ë‹¤ë¥´ë©´ loss ê°€ ì»¤ì§€ê²Œ ë˜ëŠ” ê²ƒì´ë‹¤. </p> <p>ìš”ì•½í•˜ìë©´, z_s ë¥¼ ì£¼ì–´ì§„ C prototype matrix ë¥¼ í†µí•´ ì–´ëŠ prototype vector ì™€ ê°€ê¹Œìš´ì§€ë¥¼ ì„¤ëª…í•˜ëŠ” ë‹µì§€ q_s ë¥¼ ìƒì„±í•˜ê³ , z_t ì™€ C prototype vector ì™€ì˜ ìƒëŒ€ì ì¸ ê±°ë¦¬ë¥¼ êµ¬í•œ p_t ë¥¼ ìƒì„±í•˜ì—¬, q_s ì™€ p_t ì‚¬ì´ì˜ cross entropy loss ë¥¼ êµ¬í•˜ê³ , ê·¸ ë°˜ëŒ€ì¸ p_s, q_t ì‚¬ì´ì—ì„œë„ CE loss ë¥¼ êµ¬í•˜ì—¬ ë”í•´ì£¼ë©´ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ìµœì¢… loss ë¥¼ êµ¬í•  ìˆ˜ ìˆëŠ” ê²ƒì´ë‹¤. ì € ìœ„ì˜ ì‹ì„ ëª¨ë“  Nê°œì˜ image ì— ëŒ€í•´ í’€ì–´ ì“°ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì‹ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/a359a53a-db04-4df3-ad16-99994799bf1a/image.png" alt=""></p> <h3 id="computing-codes-online---sinkhorn-algorithm">Computing codes online - Sinkhorn Algorithm</h3> <p>ê·¸ë ‡ë‹¤ë©´ ë‹µì§€ë¼ê³  ì„¤ëª…í–ˆë˜ code q ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ zì™€ c ë¥¼ ì´ìš©í•œë‹¤ ì„¤ëª…í–ˆëŠ”ë°, êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ëŠ”ì§€ì— ëŒ€í•´ ì„¤ëª…í•˜ë„ë¡ í•˜ê² ë‹¤. </p> <p>ê·¸ ì „ì— ë¬¸ì œ ì •ì˜ë¥¼ ë‹¤ì‹œ í•´ì•¼ í•œë‹¤. ë¹µì„ ìƒì‚°í•˜ëŠ” ë² ì´ì»¤ë¦¬ A, Bê°€ ìˆê³ , ì´ë¥¼ ë°›ì•„ì•¼ í•˜ëŠ” í•™êµ X, Y, Z ê°€ ìˆë‹¤. A ëŠ” 300ê°œ, B ëŠ” 700ê°œì˜ ë¹µì„ ìƒì‚°í•˜ê³ , í•™êµ X, Y, Z ëŠ” ê°ê° 400ê°œ, 500ê°œ, 100ê°œë¥¼ ìˆ˜ê¸‰í•´ì•¼ í•œë‹¤. ì´ë•Œ, ë² ì´ì»¤ë¦¬ì™€ í•™êµ ì‚¬ì´ì˜ ì´ë™ ê±°ë¦¬ë¥¼ cost value C graph í˜•íƒœë¡œ í‘œí˜„ì„ í–ˆì„ ë•Œ, ì´ ì´ë™ê±°ë¦¬ë¥¼ ìµœì†Œí™” í•˜ë©´ì„œë„ í•™êµì—ê²Œ ì•Œë§ì€ ë¹µì„ ê³µê¸‰í•˜ëŠ” ë£¨íŠ¸ P (transportation plan) ë¥¼ êµ¬í•˜ëŠ” ë¬¸ì œë¥¼ transportation polytope problem ì´ë¼ ë¶€ë¥¸ë‹¤.</p> <p>ê·¸ ì•„ë˜ë¶€í„°ëŠ” í•„ê¸° ì„¤ëª…ìœ¼ë¡œ ëŒ€ì²´í•˜ê² ë‹¤..</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/b8102164-c9dc-4d66-aa52-9280feb61e85/image.jpg" alt=""></p> <p>ê²°êµ­ ìš”ì•½í•˜ìë©´, ë§ì´ ìƒì‚°í•˜ëŠ” ë¹µì§‘ì€ (ì¼ë‹¨ cost matrix ë¥¼ ë¹¼ê³  ìƒê°í–ˆì„ ë•Œ) path ê°€ ë§ì´ ëš«ë ¤ ìˆì–´ì•¼ í•˜ê³ , ë§ì´ ì†Œë¹„í•˜ëŠ” í•™êµë„ path ê°€ ë§ì´ ëš«ë ¤ ìˆì–´ì•¼ í•œë‹¤ëŠ” ì•„ì´ë””ì–´ì— ì°©ì•ˆí•˜ì—¬, rc^T ì™€ P ì‚¬ì´ì˜ KL divergence ë¥¼ ì¼ì • parameter ì´í•˜ë¡œ ë³´ë‚´ìëŠ” constraint ê°€ í•˜ë‚˜ ì¶”ê°€ë˜ì—ˆë‹¤. ê²°êµ­ ì´ëŠ” P ì˜ ê´€ì ì—ì„œ ë´¤ì„ ë•Œ P ì˜ entropy ë¥¼ maximize í•˜ëŠ” ì‹ì´ê³ , ì´ëŠ” optimization ê´€ì ì—ì„œ ë´¤ì„ ë•Œ non-convex problem ì´ê¸° ë•Œë¬¸ì—, convex problem ìœ¼ë¡œ ë°”ê¿”ì£¼ê¸° ìœ„í•´ duality ë¥¼ ì´ìš©í•˜ì—¬ ìƒˆë¡œìš´ convex problem ì„ ë§Œë“  ì‹ì´ ì´ì œ 3ë²ˆ ì•„ë˜ ìˆëŠ” ë„¤ëª¨ë°•ìŠ¤ ì‹ì´ë‹¤. ê²°êµ­ ì´ë¥¼ ë¼ê·¸ë‘ì£¼ ì‹ì„ ì´ìš©í•´ì„œ í’€ë©´, ì–´ë–¤ ë‘ ìƒìˆ˜ m, n ì˜ function ì¸ u ì™€ v vector ì™€ exp(-lambda c) ì˜ ê³±ìœ¼ë¡œ P ê°€ ê²°ì •ë˜ê²Œ ëœë‹¤. ì´ ë•Œ, u ì™€ v ëŠ” diagonal ì— P ëŠ” doubly stochastic (ë‹¤ normalized ë˜ì—ˆë‹¤ëŠ” ëœ») ì´ê¸° ë•Œë¬¸ì— sinkhorn theorem ì„ ì ìš©í–ˆì„ ë•Œ, normalize iterationì„ ìˆ˜í–‰í•˜ë©´ converge í•œë‹¤. ê·¸ë ‡ê¸°ì— ë§¨ ë§ˆì§€ë§‰ì— ì„¤ëª…ë˜ì–´ ìˆëŠ” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ê·€ê²°ë˜ëŠ” ê²ƒì´ë‹¤.. . . . .</p> <p><a href="https://amsword.medium.com/a-simple-introduction-on-sinkhorn-distances-d01a4ef4f085">https://amsword.medium.com/a-simple-introduction-on-sinkhorn-distances-d01a4ef4f085</a> ì„¤ëª…ì€ ì´ ê¸€ì„ ì°¸ê³ í•˜ì˜€ë‹¤..</p> <p>ì´ì œ ë‹¤ì‹œ ìš°ë¦¬ì˜ ë¬¸ì œë¡œ ëŒì•„ì™€ì„œ, ë‹¤ìŒ ì‹ê³¼ ë§ˆì£¼í•˜ê²Œ ëœë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/6ca2d368-5d28-4c41-a30c-8e09f04593fe/image.png" alt=""></p> <p>Q ëŠ” zì™€ cë¥¼ ì´ì–´ì£¼ëŠ” code matrix ì´ê³ , $C^TZ$ ëŠ” ë‘ matrix entry ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ í‘œí˜„í•´ì£¼ëŠ”, ì¦‰ ìœ„ ë¬¸ì œì—ì„œì˜ cost matrix ê°€ ë˜ì–´ì¤€ë‹¤. ìœ„ optimization ì‹ì˜ ê²°ê³¼ì™€ consistent í•˜ê²Œ, ì—¬ê¸°ì„œë„ optimal Q ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/77761d64-1e3b-433c-ac2a-bcd8188bd7b7/image.png" alt=""></p> <p>ì´ ë•Œ ë…¼ë¬¸ì—ì„œ ë³¸ì¸ë“¤ì€ soft code ë¥¼ ì‚¬ìš©í•œë‹¤ í‘œí˜„í•˜ì˜€ë‹¤. ì›ë˜ Q matrix ìì²´ëŠ” discrete í•˜ê²Œ z_1 ì€ c_3 ë¡œ ì´ì–´ì§€ê³  z_2 ëŠ” c_4 ë¡œ ì´ì–´ì§€ëŠ” entry ê°€ 0, 1 ì¸ graph í˜•íƒœë¡œ í‘œí˜„í•˜ë ¤ í–ˆìœ¼ë‚˜, ì‹¤ì œë¡œ ê²°ê³¼ë¥¼ ë‚´ë³¸ ê²°ê³¼ z_1 ì€ c_3 ì— 0.5 c_2 ì— 0.2 ... ì´ëŸ°ì‹ìœ¼ë¡œ continuous solution Q ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ ì„±ëŠ¥ì´ ë” ì˜ ë‚˜ì™”ë‹¤ê³  í•œë‹¤. ì´ëŠ” discrete solution ìœ¼ë¡œ ë°”ê¾¸ëŠ” ê³¼ì •ì—ì„œ rounding ì´ ì‚¬ìš©ë˜ì—ˆê³  ì´ëŠ” aggressive optimization ì´ê¸° ë•Œë¬¸ì´ë¼ ì„¤ëª…í•œë‹¤. </p> <p>ë˜í•œ í•˜ë‚˜ì˜ í¬ì¸íŠ¸ê°€ ë” ìˆëŠ”ë°, Q ì˜ entropy ë¥¼ penalty term ìœ¼ë¡œ ë†“ì•˜ê¸° ë•Œë¬¸ì—, Q matrix ê°€ í•˜ë‚˜ì˜ prototype vector ë¡œ ì ë¦¬ê²Œ í• ë‹¹ì„ í•˜ê²Œ ëœë‹¤ë©´ (ì–´ì©Œë©´ ì´ëŠ” collapse) penalty ë¥¼ ë¶€ì—¬í•˜ê²Œ ëœë‹¤. ì¦‰ ê° representation z ë¥¼ ëª¨ë“  prototype vector ì— ê³¨ê³ ë£¨ í• ë‹¹í•˜ë„ë¡ í•˜ëŠ” í•˜ë‚˜ì˜ constraint ë¡œ ì‘ë™í•œë‹¤ê³  ì„¤ëª…í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/c6cbc9fb-533c-4ccf-adb6-f28d22377bdf/image.png" alt=""></p> <h3 id="multi-crop-augmenting-views-with-smaller-images">Multi-crop: Augmenting views with smaller images</h3> <p>í•˜ë‚˜ì˜ image ë¥¼ ì—¬ëŸ¬ view ë¡œ ë³´ëŠ” ê²ƒì´ ì„±ëŠ¥ ê°œì„ ì´ ë„ì›€ì´ ë˜ëŠ” ê²ƒì´ ì•Œë ¤ì ¸ ìˆì§€ë§Œ, augmentation ì„ ëŠ˜ë¦´ìˆ˜ë¡ compute / memory requirement ê°€ quadratic í•˜ê²Œ ëŠ˜ì–´ë‚˜ê²Œ ëœë‹¤. ì´ ë¬¸ì œë¥¼ íƒ€ê°œí•˜ê¸° ìœ„í•´, two standard resolution crop ì€ ëª¨ë“  ë‹¤ë¥¸ augmentation ê³¼ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ê³ , ë‹¤ë¥¸ multi-crop sample V additional low resolution crop ë“¤ì— ëŒ€í•´ì„œëŠ” ì„œë¡œì„œë¡œ ê³„ì‚°í•˜ì§€ ì•Šê³  ì˜¤ì§ two standard resolution crop ë“¤ê³¼ë§Œ loss ê³„ì‚°ì„ ìˆ˜í–‰í•œë‹¤. ë‹¤ìŒê³¼ ê°™ì€ ì‹ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/94f6cc47-95ee-4ae0-93fe-8ccfdcb940e7/image.png" alt=""></p> <p>code ë¥¼ ê³„ì‚°í•˜ëŠ” ë¶€ë¶„ì€ ì˜¤ì§ 2 standard resolution ì— ëŒ€í•´ì„œë§Œ ìˆ˜í–‰ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì•„ë˜ ì„¹ì…˜ì—ì„œ ì„±ëŠ¥ì°¨ì´ë¥¼ ë³´ì—¬ì£¼ë©°, multi-crop ì€ ì—¬ëŸ¬ self-supervised method ì—ì„œ ì„±ëŠ¥ í–¥ìƒì— ë„ì›€ì„ ì£¼ì—ˆê³  promising augmentation strategy ë¼ ì„¤ëª…í•˜ê³  ìˆë‹¤.</p> <h2 id="main-results">Main Results</h2> <p>SwAV ë¥¼ í†µí•´ feature ë¥¼ í•™ìŠµí•˜ê³ , ì´ë¥¼ multiple dataset ì— transfer learning í•˜ì—¬ ì„±ëŠ¥ì„ ì°ì—ˆë‹¤. SimCLR ì—ì„œ ì‚¬ìš©ëœ LARS, cosine learning rate, MLP projection head ë¥¼ êµ¬í˜„í•˜ì˜€ê³  ì„±ëŠ¥ í–¥ìƒì„ ì´ë¤„ëƒˆë‹¤. </p> <h3 id="evaluating-the-unsupervised-features-on-imagenet">Evaluating the unsupervised features on ImageNet</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/c3a54662-0600-4748-8bf4-97369632acbf/image.png" alt=""></p> <p>left: frozen feature ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ ê¸°ì¡´ sota ë¥¼ +4.2% outperform í•˜ê³  supervised learning ê³¼ 1.2% ì°¨ì´ë°–ì— ë‚˜ì§€ ì•ŠëŠ” ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤. (800 epoch, 4096 large batch) right: ë˜í•œ ResNet-50 width ì— 2, 4, 5 ë¥¼ ê³±í•œ variants ì—ì„œë„ supervised learning ê³¼ ë¹„ìŠ·í•œ ê²½í–¥ì„±ì„ ë³´ì˜€ê³  ê·¸ì— ì¤€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/b9cc8201-33f0-4bda-90f2-9ce22b9fd003/image.png" alt=""></p> <p>semi-supervised learning ì„ íƒ€ê²Ÿí•˜ê³  ì„¤ê³„ëœ ëª¨ë¸ì´ ì•„ë‹˜ì—ë„, sota semi-supervised learning ê³¼ ë‹¤ë¥¸ self-supervised learning ì„ outperform í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆë‹¤. </p> <h3 id="transferring-unsupervised-features-to-downstream-tasks">Transferring unsupervised features to downstream tasks</h3> <p>ImageNet ì„ label ì—†ì´ ResNet-50ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•œ SwAV ì˜ generalization ì„±ëŠ¥ì„ ë³´ê¸° ìœ„í•´, ëª‡ëª‡ downstream vision task ì— transfer í•˜ì—¬ ì„±ëŠ¥ì„ ë¹„êµí–ˆë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/5952e840-eba0-4994-b328-9bc1104bd487/image.png" alt=""></p> <p>ì™¼ìª½ supervised learning - linear classification ê²°ê³¼ë¥¼ outperform í–ˆë‹¤. í  ì™œì§€ appendix - places205 28 epoch, iNat18 84 epoch - ì´ë¯¸ì§€ ëª‡ê°œ ì¼ëŠ”ì§€ëŠ” ë‚˜ì™€ìˆì§€ ì•ŠìŒ. Our SwAV ResNet-50 model surpasses supervised ImageNet pretraining on all the considered transfer tasks and datasets.</p> <h3 id="training-with-small-batches">Training with small batches</h3> <p>SwAV ë¥¼ (ì´ì „ì—” large batch 4096) small batch 256 images on 4 GPU setting ì—ì„œ ì‹¤í—˜í•˜ê³ , MoCov2 ì™€ SimCLR ê³¼ ë¹„êµí•˜ì˜€ë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/a2c6b81a-bf1c-42b3-b60f-9441597ea6fa/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/cd7979c5-4b2d-4e84-a6cd-4c29286aa90c/image.png" alt=""></p> <p>ë‹¤ë¥¸ ë°©ì‹ê³¼ ë¹„êµí–ˆì„ ë•Œ sota ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆë‹¤. SwAV ëŠ” 3840ê°œì˜ feature ê°€ ë“¤ì–´ê°€ëŠ” queue ë¥¼ ì‚¬ìš©í–ˆê³ , MoCov2 ëŠ” momentum encoder network ë¥¼ ëŒë¦¬ë©´ì„œë„ 65536 ê°œì˜ featureê°€ ë“¤ì–´ê°€ëŠ” queue ë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤. ë˜í•œ running time ì„ ê¸°ì¤€ìœ¼ë¡œ í•œ epoch ë‹¹ ê±¸ë¦¬ëŠ” ì‹œê°„ì€ MoCov2ë‚˜ SimCLR ì´ ë” ë¹¨ëì§€ë§Œ good downstream performance ë¥¼ ì–»ê¸°ê¹Œì§€ì˜ epoch ìˆ˜ëŠ” SwAV ì´ ë” ì ì—ˆë‹¤. (ex MoCov2 800 epoch 71.1, SwAV 200 epoch 72.0) ë§ˆì§€ë§‰ìœ¼ë¡œ, SwAV ëŠ” large batch + momentum encoder ì™€ë„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ”ë°, ì´ëŠ” future work ë¡œ ë‚¨ê²¨ë‘ì—ˆë‹¤ê³  í•œë‹¤.</p> <h2 id="ablation-study">Ablation study</h2> <h3 id="clustering-based-self-supervised-learning">Clustering based self-supervised learning</h3> <h4 id="improving-prior-clustering-based-approaches">improving prior clustering-based approaches</h4> <p>ê³¼ê±° clustering-based model ì„ ì¬êµ¬í˜„í•˜ê³  í˜„ì¡´ contrastive method SimCLR ê³¼ ë¹„êµí•˜ì˜€ë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/5332d11f-3286-41e5-b288-30282ea477d9/image.png" alt=""> DeepCluster-v2 ëŠ” ê¸°ì¡´ deepcluster ì˜ two consecutive (ex epoch 1, 2 ì—ì„œì˜) cluster assignments ë¼ë¦¬ correspondence ê°€ ì—†ì–´, epoch ì´ ìƒˆë¡œ ì‹œì‘ë  ë•Œë§ˆë‹¤ cluster assignment ì™€ final classification layer ì´ irrelevant í•˜ê²Œ ë˜ì–´ ë‹¤ì‹œ ì²˜ìŒë¶€í„° í•™ìŠµë˜ì–´ì•¼ í•œë‹¤ëŠ” í° ë‹¨ì ì´ ìˆì—ˆë‹¤. ì´ë¥¼ ë³´ì™„í•˜ê³ ì, k-means clustering centroidì˜ explicit comparison ì„ ì¶”ê°€í•¨ìœ¼ë¡œì¨ stability ì™€ performance ë¥¼ í–¥ìƒí•˜ì˜€ë‹¤. </p> <h4 id="comparing-clustering-with-contrastive-instance-learning">comparing clustering with contrastive instance learning</h4> <p>SimCLR ê³¼ì˜ fair comparison ì„ ìœ„í•´ SwAP ì—ì„œ ì‚¬ìš©í–ˆë˜ same data augmentation, epoch ìˆ˜, batch size ë“±ì„ ë§ì¶”ì–´ ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ê³ , í–¥ìƒëœ ê¸°ì¡´ clustering-based model ê³¼ SwAV ì´ SimCLR ì„ ì„±ëŠ¥ ë©´ì—ì„œ ëŠ¥ê°€í•˜ì˜€ë‹¤. ì´ëŠ” learning potential of clusteirng-based methods over instance classification ì„ ë³´ì—¬ì¤€ë‹¤ ì„¤ëª…í•œë‹¤.</p> <h4 id="advantage-of-swav-compared-to-deepcluster-v2">advantage of SwAV compared to DeepCluster-v2</h4> <p>ì„±ëŠ¥ ë©´ì—ì„œ DeepCluster-v2 ê°€ SwAV ì„ ëŠ¥ê°€í•˜ì§€ë§Œ, ê²°ì •ì ìœ¼ë¡œ DeepCluster-v2 ëŠ” online algorithm ì´ ì•„ë‹ˆë¼ì„œ large dataset ì— ëŒ€í•´ì„œëŠ” ì‘ë™í•  ìˆ˜ ì—†ë‹¤. ë˜í•œ DeepCluster-v2 ëŠ” ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•œ swapping ë°©ì‹ì˜ special case ë¼ ë³¼ ìˆ˜ ìˆëŠ”ë°, swapping ì´ batch ë‚´ì—ì„œ instance ë¼ë¦¬ ì´ë£¨ì–´ì§€ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ <strong>across epoch</strong> ì—ì„œ ì¼ì–´ë‚˜ëŠ” ê²ƒì´ë¼ í•´ì„í•  ìˆ˜ ìˆë‹¤. </p> <h3 id="applying-the-multi-crop-strategy-to-different-methods">Applying the multi-crop strategy to different methods</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/5332d11f-3286-41e5-b288-30282ea477d9/image.png" alt=""> figure 3 ì˜ left ë¥¼ ë³´ë©´, multi-crop strategy ê°€ ê°€ì§„ ì„±ëŠ¥ê°œì„  íš¨ê³¼ì— ëŒ€í•´ ì•Œ ìˆ˜ ìˆë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/0c762192-3d62-418d-b3ac-979de4cfcb96/image.png" alt=""> ë‹¤ìŒ loss function ì€ SimCLR ì—ì„œ multi-crop strategy ë¥¼ ì–´ë–»ê²Œ ì ìš©í–ˆëŠ”ì§€ë¥¼ ë³´ì—¬ì¤€ë‹¤. M ì€ number of crops per instance ì´ê³ , 2x160+4x96 crops ì´ ìˆìœ¼ë©´ M=6ì´ ë˜ëŠ” ê²ƒì´ë‹¤.</p> <h3 id="unsupervised-pretraining-on-a-large-uncurated-dataset">Unsupervised pretraining on a large uncurated dataset</h3> <p>online algorithm ì„ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ ì–»ì„ ìˆ˜ ìˆëŠ” scalability ë¥¼ ì¦ëª…í•˜ê¸° ìœ„í•´, instagram ìœ¼ë¡œë¶€í„° 1 billion random public non-EU image (uncurated dataset) ìœ¼ë¡œ SwAV ë¥¼ pretrain í•˜ê³ , ImageNet ì—ì„œ frozen feature linear classifier / finetuned feature linear classifier ì„±ëŠ¥ì„ ë¹„êµí•˜ì˜€ë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/b1a48d6e-332f-4b83-988b-57f09987ea4f/image.png" alt=""></p> <p>ê²°ê³¼ SwAVì—ì„œ random initialized / SimCLR pretrained ë³´ë‹¤ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ê³ , fined-tuned ì—ì„œë„ ì—­ì‹œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆë‹¤. ë˜í•œ ê¸°ì¡´ ResNet-50 ë³´ë‹¤ capacity ë¥¼ ëŠ˜ë¦° ResNext ë¥¼ ì´ìš©í•˜ì—¬ ë™ì¼ ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ê³  supervised models trained from scratch on ImageNet ê³¼ ë¹„êµí–ˆì„ ë•Œ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆë‹¤. </p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; July 27, 2022 &nbsp; &middot; &nbsp; velog.io </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-When-Does-Contrastive-Visual-Representation-Learning-Work" target="_blank">[Paper Review] When Does Contrastive Visual Representation Learning Work?</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="when-does-contrastive-visual-representation-learning-work">When Does Contrastive Visual Representation Learning Work?</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/1804c970-4962-49cb-bf43-84d2970870f4/image.png" alt=""></p> <p>self-supervised representation learning ì´ ì–´ë–¤ ì¡°ê±´ í•˜ì— ì˜ ì‘ë™í•˜ëŠ”ì§€ì— ëŒ€í•œ insight ë¥¼ ì œê³µí•˜ëŠ” ë…¼ë¬¸ì´ë‹¤. í¬ê²Œ ImageNet, iNat21, Places365, GLC20 dataset ì„ ì‚¬ìš©í•˜ì—¬, 1) Dataset size, 2) Domain, 3) Quality, 4) Task granularity ë¥¼ ë‹¬ë¦¬í•œ ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ë‹¤. ëŒ€ë¶€ë¶„ì˜ ì‹¤í—˜ì´ SimCLRê³¼ ResNet-50 ìœ¼ë¡œ ì§„í–‰ë˜ì—ˆë‹¤. </p> <h2 id="introduction">Introduction</h2> <p>Under what conditions do self-supervised contrastive representation learning methods produce good visual representations?</p> <ul> <li>What is the impact of data quantity?</li> <li>What is the impact of the pretraining domain?</li> <li>What is the impact of data quality?</li> <li>What is the impact of task granularity?</li> </ul> <h2 id="methods">Methods</h2> <p>Datasets: ImageNet (1.3M images, 1k classes), iNat21 (2.7M images, 10k classes), Places365 (1.8M images, 365 classes), GLC20 (1M images, 16 classes) Fixed-size subsets: uniformly random í•˜ê²Œ ì„ íƒí•˜ì—¬ 1M, 500k, 250k, 125k, 50k images ë“±ì„ êµ¬ì„±í•¨. Training details: ResNet-50 backbone ì„ ì‚¬ìš©í•œ SimCLR ë¡œ self-supervised learning ì„ ì§„í–‰í•¨.</p> <h2 id="experiments">Experiments</h2> <h3 id="data-quantity-datasize">Data Quantity (datasize)</h3> <p>SSL ì—ì„œ good representation ì„ ë°°ìš°ê¸° ìœ„í•´ í•„ìš”í•œ ë°ì´í„°ì˜ ì–‘ì€ ì–¼ë§ˆì¸ê°€? </p> <p>ë‹¤ìŒ ë‘ê°€ì§€ ì¡°ê±´ì„ ë°”ê¾¸ì–´ ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ë‹¤.</p> <p>1) # of unlabeled images used for pretraining 2) # of labeled images used to subsequently train a classifier</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/c210cd4c-43f9-4eb1-bb78-47ace1e451bc/image.png" alt=""></p> <p>black line ì€ supervised training ì„ from scratch training í•œ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. linear evaluation ëŠ” fine tuning ê³¼ ë‹¬ë¦¬ ëª¨ë“  parameter ë¥¼ freeze í•´ë†“ê³  ë§ˆì§€ë§‰ì— linear layer ë§Œ ì¶”ê°€í•˜ì—¬ ì´ parameterë§Œ í•™ìŠµë˜ë„ë¡ í•œ ì„¸íŒ…ì´ë‹¤. </p> <h4 id="there-is-little-benefit-beyond-500k-pretraining-images">There is little benefit beyond 500k pretraining images</h4> <p>ì €ìëŠ” 500k (blue) ì™€ 1M (orange) pretraining image curve ë¥¼ ë¹„êµí–ˆì„ ë•Œ 1-2% ë°–ì— ì°¨ì´ ë‚˜ì§€ ì•ŠìŒì— ì£¼ëª©í•œë‹¤. 250k (green) ì™€ 50k (pink) ë¥¼ ë¹„êµí–ˆì„ ë•Œ 10% ì´ìƒì˜ ì°¨ì´ë¥¼ ë³´ì´ëŠ” êµ¬ê°„ë„ ì¡´ì¬í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì•„, pretraining ì‹œì— image ê°œìˆ˜ë¥¼ 500k ì´ìƒìœ¼ë¡œ ëŠ˜ë ¤ë„ í° íš¨ê³¼ë¥¼ ë³´ê¸° ì–´ë µë‹¤ê³  í•´ì„í•œë‹¤.</p> <h4 id="ssl-pretraining-can-be-a-good-initializer-when-there-is-limited-supervision">SSL pretraining can be a good initializer when there is limited supervision</h4> <p>bottom row ë¥¼ ë´¤ì„ ë•Œ, labeled image ê°€ 10k, 50kì¸ ê²½ìš° supervised learning ë³´ë‹¤ SSL ë¡œ pretraining í›„ fine-tuning í•˜ëŠ” ê²ƒì´ significantly better í–ˆë‹¤. ë˜í•œ labeled image ê°€ ì»¤ì§ì— ë”°ë¼ supervised learning ì˜ ê²°ê³¼ì™€ ë¹„ìŠ·í•´ì§€ëŠ” ì–‘ìƒì„ ë³´ì˜€ë‹¤. ì €ìëŠ” ì´ë¥¼ ë³´ê³  SSL ì´ good initializer ë¼ í•´ì„í•˜ëŠ”ë°, ì´ì „ ì—°êµ¬ ì¤‘ supervised learning ì´ˆê¸°ì— distort augmentation ì´ ë“¤ì–´ê°„ image ë¥¼ ì‚¬ìš©í•˜ë©´ í›„ë°˜ì— ê°€ë„ ì¼ë°˜ learning setting ì˜ ê²°ê³¼ë¥¼ ë”°ë¼ì¡ì§€ ëª»í•˜ëŠ” ê²°ê³¼ì™€ í•¨ê»˜ ë†“ê³  ë´¤ì„ ë•Œ í¥ë¯¸ë¡­ë‹¤ í•´ì„í•œë‹¤.</p> <h4 id="ssl-representation-can-approach-fully-supervised-performance-for-some-dataset-but-only-by-using-lots-of-labeld-images">SSL representation can approach fully supervised performance for some dataset, but only by using lots of labeld images</h4> <p>ImageNet ê³¼ Places365 ì˜ ê²°ê³¼ ê·¸ë˜í”„ë¥¼ ë´¤ì„ ë•Œ, labeled image ê°€ 100k ì¼ ë•Œì—ë„ pretrainingì„ 1M image ë¡œ ì§„í–‰í•œ ì‹¤í—˜ ê²°ê³¼ ì„±ëŠ¥ (orange) ëŠ” supervised learning ì˜ ì„±ëŠ¥ (black) ê³¼ í° ì°¨ì´ê°€ ë‚˜ì§€ ì•ŠëŠ”ë‹¤ í•´ì„í•œë‹¤. </p> <h4 id="inat21-is-a-valuable-ssl-benchmark">iNat21 is a valuable SSL benchmark</h4> <p>iNat21 ì˜ ê²½ìš° SSL pretraining ê²°ê³¼ë“¤ê³¼ supervised learning ê²°ê³¼ (black) ì‚¬ì´ì— large gap ì´ ì¡´ì¬í•œë‹¤. ì´ë¥¼ ë³´ê³  SimCLR ì´ì™¸ì— MoCo, BYOL ë¡œ ì‹¤í—˜ì„ ì§„í–‰í•˜ì§€ë§Œ ì—¬ì „íˆ í° ì°¨ì´ë¥¼ ë³´ì˜€ë‹¤. (species point ë¥¼ ë³´ë©´ ë¨) ì €ìëŠ” ì´ë¥¼ ë³´ê³  iNat21 dataset ì´ SSLì˜ challenge, ì¦‰ ì•„ì§ í•´ê²°ë˜ì§€ ì•Šì€ ê³¼ì œë¡œì¨ í–¥í›„ SSL ì—°êµ¬ë¡œ ì£¼ëª©í• ë§Œí•œ benchmark ë¼ ì–¸ê¸‰í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/6fa926ff-c86f-4aa2-9da9-64f82970a112/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/13853058-0a19-4126-833f-32a3402c3d85/image.png" alt=""></p> <h3 id="data-domain">Data Domain</h3> <p>what kind of images should be use for pretraining? ì–´ë–¤ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ê°€?</p> <p>ë‹¤ìŒê³¼ ê°™ì€ ì„¸ê°€ì§€ ì‹¤í—˜ì„ ì§„í–‰í•œë‹¤.</p> <p>1) in-domain and cross-domain linear evaluation results 2) pretraining on pooled datasets ì„¸íŒ…ì˜ ê²°ê³¼ 3) differently fused representation ìœ¼ë¡œ ì‹¤í—˜í•œ output</p> <h4 id="pretraining-domain-matters">Pretraining domain matters</h4> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/c7f0b5f7-2e30-4e16-80a9-bab0e9a0dbd0/image.png" alt=""></p> <p>in-domain ì—ì„œ ì‹¤í—˜í–ˆì„ ë•Œ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì•˜ê³ , cross-domain ì‹¤í—˜ ì„¸íŒ… ì¤‘ì—ì„  ImageNet ì˜ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì•˜ê³  GLC20 ì˜ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì§€ ì•Šì•˜ë‹¤. íŠ¹íˆ ImageNet ì˜ cross-domain ì„±ëŠ¥ì´ ì˜ ë‚˜ì˜¨ ê²ƒì„ ë³´ê³  ì´ëŠ” <strong>&quot;semantic similarity&quot;</strong> ë•Œë¬¸ì´ë¼ í•´ì„í•œë‹¤. ì´ì— ëŒ€í•œ ë‹¤ë¥¸ ê·¼ê±°ë¡œ 2ê°€ì§€ ì¶”ê°€ì‹¤í—˜ì„ ì œì‹œí•œë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/842d3c76-0418-42e5-8e63-2b91452a9d14/image.png" alt=""></p> <p>animal ê³¼ plant ì˜ ì‚¬ì§„ìœ¼ë¡œ ì´ë£¨ì–´ì§„ iNat21 dataset ì—ì„œ taxonomic class ë¥¼ ë‚˜ëˆ„ì–´ accuracy ë¥¼ ì¸¡ì •í–ˆì„ ë•Œ, animalê³¼ plant ì˜ ì‚¬ì§„ ë˜í•œ í¬í•¨ë˜ì–´ ìˆëŠ” ImageNet pretrained ëª¨ë¸ì˜ ì„±ëŠ¥ì´ íŠ¹ì • class ì—ì„  ë†’ì•˜ê³  ë‹¤ë¥¸ ì—¬ëŸ¬ class ì—ì„  iNat21 pretrained ëª¨ë¸ì˜ ê²°ê³¼ì™€ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤. ê·¸ì— ë¹„í•´ scene ì •ë³´ê°€ ë§ì€ Place365 ì˜ ê²°ê³¼ëŠ” ê·¸ë ‡ì§€ ëª»í–ˆë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/34df5c83-9042-425b-a8b6-a49756163fd9/image.png" alt=""><img src="https://velog.velcdn.com/images/jaeheon-lee/post/a75683bf-0c9d-4754-85a5-2a20f4951a6f/image.png" alt=""></p> <p>ë˜í•œ, Places365 ì™€ iNat21 ì˜ in-domain accuracy ë¥¼ class ë³„ë¡œ break down í•´ì„œ ë´¤ì„ ë•Œ (ë‹¹ì—°íˆ í‰ê· ì€ 0) iNat21ì˜ ê²½ìš° ì•½ 40%ì˜ class ëŠ” accuracy ì „ë°˜ì„ hurt í•˜ê³  60%ì˜ class ëŠ” accuracy í–¥ìƒì— ë„ì›€ì„ ì£¼ì—ˆë‹¤. ì´ ë•Œ 60% ì˜ ëŒ€ë¶€ë¶„ì€ plants ì˜€ë‹¤ëŠ” ì‚¬ì‹¤ì— ì£¼ëª©í•œë‹¤. label ì´ ì£¼ì–´ì§€ì§€ ì•Šì•˜ìŒì—ë„ ë¶ˆêµ¬í•˜ê³  high level ì˜ semantic information ì— ë”°ë¼ ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ë‚´ì—ˆë‹¤ëŠ” ê²ƒìœ¼ë¡œ í•´ì„í•˜ì—¬, SSL ì´ representation ì„ ë§Œë“¤ì–´ë‚´ëŠ” ê³¼ì •ì—ì„œë„ semantic similarity ê°€ ë“¤ì–´ê°„ë‹¤ ë¼ê³  ì„¤ëª…í•œë‹¤.</p> <h4 id="adding-cross-domain-pretraining-data-general-representation-ì—ëŠ”-ê·¸ë‹¥">Adding cross-domain pretraining data, general representation ì—ëŠ” ê·¸ë‹¥</h4> <p>dataset ì„ ì„ì—ˆì„ ë•Œ ì„±ëŠ¥ì´ ì–´ë–¤ì§€ ì‹¤í—˜í•œë‹¤. (pretraining on pooled dataset) <img src="https://velog.velcdn.com/images/jaeheon-lee/post/3c5be69a-8462-418d-8d16-a4b24a28a3ac/image.png" alt=""></p> <p>ëª¨ë“  ì‹¤í—˜ì—ì„œ, adding pretraining data from different domain ì€ ì„±ëŠ¥ì„ ì €í•˜í–ˆë‹¤. ì´ì— ëŒ€í•œ ì›ì¸ìœ¼ë¡œ <strong>&quot;diversity-difficulty trade-off&quot;</strong> ë¼ ì„¤ëª…í•˜ëŠ”ë°, diverse (different domain) image ê°€ ë“¤ì–´ì˜¤ë©´, contrastive learning ê³¼ì •ì—ì„œ ë„ˆë¬´ ì‰¬ìš´ ë¬¸ì œë¡œ ì¸ì‹í•˜ì—¬ ì„±ëŠ¥ì´ ë–¨ì–´ì§„ë‹¤ ì„¤ëª…í•œë‹¤. (SimSiam ì—ì„œë„ ë¹„ìŠ·í•œ ì„¤ëª… ë‚˜ì™”ìŒ)</p> <h4 id="self-supervised-representation-can-be-largely-redundant">Self-supervised &quot;representation&quot; can be largely redundant</h4> <p>ì–´ë–¤ dataset ì— pretrain ë˜ëŠëƒì— ë”°ë¼ ì„±ëŠ¥ì´ ë‹¤ë¥¸ ê²ƒì„ ë³´ê³ , representation ì˜ ì°¨ì´ê°€ ì–´ë–¤ì§€ ê¶ê¸ˆí•˜ì—¬ representation ë¼ë¦¬ fusion í•˜ì—¬ ì„±ëŠ¥ì„ ì¸¡ì •í•´ ë³´ì•˜ë‹¤. êµ¬ì²´ì ìœ¼ë¡œ ì €ìëŠ” concatenate features from different pretrained networks í•˜ê³  linear evaluation ì„ í†µí•´ ì„±ëŠ¥ì„ ì¸¡ì •í•œë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/65a76a0d-d288-4df0-a91e-982159cd9b29/image.png" alt=""></p> <p>1) two self-supervised representation ì„ ì„ì–´ë„ ì„±ëŠ¥ ë³€í™”ëŠ” ë¯¸ë¯¸í–ˆë‹¤. ImageNet SimCLR alone 0.647 --&gt; combined 0.641 / iNat21 SimCLR alone 0.506 --&gt; combined 0.520 ì´ë¥¼ í†µí•´ ì €ìëŠ” two self-supervised representation ì€ largely &quot;redundant&quot; í•¨ì„ ì•”ì‹œí•œë‹¤ê³  ì„¤ëª…í•œë‹¤.</p> <p>2) supervised and self-supervised representation ì„ ì„ì—ˆì„ ë•Œ ì°¨ì´ê°€ ê½¤ ìˆì—ˆë‹¤. ImageNet SimCLR alone 0.506 --&gt; ImageNet SimCLR + iNat21 Sup 0.553 / iNat SimCLR alone 0.647 --&gt; iNat21 SimCLR + ImageNet Sup 0.605 ì´ ë•Œ, iNat sup ì„ ì¶”ê°€í–ˆì„ ë•Œ ImageNet ë¶„ë¥˜ ì„±ëŠ¥ì´ ì €í•˜ë˜ì—ˆë˜ ê²ƒì— ë°˜í•˜ì—¬ ImageNet sup ì„ ì¶”ê°€í–ˆì„ ë•Œ iNat ë¶„ë¥˜ ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆë‹¤. ì´ ë˜í•œ dataset semantics ê°€ SSL ì—ì„œ ì¤‘ìš”í•˜ë‹¤ë¼ëŠ” ê°€ì •ê³¼ consistent í•˜ë‹¤ ì„¤ëª…í•œë‹¤. (ImageNetì˜ feature ëŠ” iNat ì—ê²Œ ë„ì›€, iNat ì˜ feature ëŠ” ImageNetì—ê²Œ ë„ì›€ ì•ˆë¨ -&gt; ì‰¬ìš´ ë¬¸ì œë¼ì„œ)</p> <h3 id="data-quality">Data Quality</h3> <p>ì—¬ëŸ¬ image corruption ë°©ì‹ì„ ì ìš©í•˜ì—¬ ì‹¤í—˜ì„ ì§„í–‰í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/e1e41b7f-be07-4556-b478-2ed24d0c3d3a/image.png" alt=""></p> <p>ì´ ë•Œ Resize &amp; Downsample ì€ downsample í›„ upsample ì„ ì ìš©í•˜ì—¬ size ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë˜ resolution ì„ ë§ê°€ëœ¨ë¦¬ëŠ” corruption ì´ë‹¤. salt &amp; pepper ë°©ì‹ì€ ì´ë¯¸ì§€ í”½ì…€ ë‹¨ìœ„ì—ì„œ ì¼ì • í™•ë¥ (0.01)ë¡œ black or white í•œ pixel ë¡œ ë°”ê¿”ë²„ë¦¬ëŠ” corruption ë°©ì‹ì´ë‹¤. JPEG ëŠ” ì†ì‹¤ ì••ì¶• ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ì—¬ ì‚¬ëŒì˜ ëˆˆì— ë¯¼ê°ë„ê°€ ì ì€ high frequency ì •ë³´ë¥¼ ì œí•˜ëŠ” ë°©ì‹ì˜ corruption ì´ë‹¤. Resize ëŠ” resolutionì„ ìœ ì§€í•˜ë˜ í¬ê¸°ë§Œ ì¤„ì´ëŠ” ë°©ì‹ì´ë‹¤. pretraining ì„ corrupted image ë¡œ ì§„í–‰í•œ ë’¤ ê¸°ì¡´ clean image ë¥¼ ì‚¬ìš©í•˜ì—¬ linear evaluation ì„ ì§„í–‰í•˜ì˜€ë‹¤. </p> <p>ì €ìëŠ” extreme cropping ì„ ì‚¬ìš©í•˜ëŠ” SSL ë°©ì‹ íŠ¹ì„± ìƒ resolution ì— robust í•  ê²ƒì´ë¼ ì˜ˆìƒí–ˆì§€ë§Œ, ì‹¤ì œ ê²°ê³¼ë¥¼ ë´¤ì„ ë•Œ SSL ë°©ì‹ì€ resolution ì„ ë§ê°€ëœ¨ë¦¬ëŠ” ë°©ì‹ì— í¬ê²Œ ë°˜ì‘í•˜ì—¬ ì„±ëŠ¥ ì €í•˜ê°€ ì¼ì–´ë‚¬ë‹¤. ì˜¤íˆë ¤ high-frequency noise ì— robust í•œ ê²°ê³¼ë¥¼ ë³´ì˜€ê³ , ì´ëŠ” texture informationì´ ì €í•˜ë˜ì–´ ì„¤ëª…ë ¥ì´ í¬ê²Œ ê°ì†Œí–ˆë‹¤ ë¼ê³  ì„¤ëª…í•œë‹¤. (ìì„¸í•œ ì›ì¸ì´ ë¶„ì„ë˜ì§€ëŠ” ì•ŠìŒ)</p> <h3 id="task-granularity">Task Granularity</h3> <p>SSL ì€ downstream task ì—ë„ ë§ì´ ì‚¬ìš©ëœë‹¤. ì—¬ëŸ¬ dataset ì˜ label ì˜ hierarchy ë¥¼ ì‚¬ìš©í•˜ì—¬ fine-grained classification ì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•œë‹¤. finest label ë¡œ training ì‹œí‚¤ê³ , (retrain ì—†ì´) label set ë§Œ ë°”ê¿” ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/59a9fe69-0395-4ee7-8cbc-f48f9313707d/image.png" alt=""></p> <p>iNat21 ê²°ê³¼ Supervised ëª¨ë¸ê³¼ ë‹¬ë¦¬ SimCLR ëª¨ë¸ì—ì„œ rapid degradation ì´ ê´€ì¸¡ë˜ì—ˆë‹¤. ë‹¤ë¥¸ dataset ì—ì„œë„ ì „ë°˜ì ìœ¼ë¡œ ë” ë¹ ë¥¸ degradation ì´ ì¼ì–´ë‚¬ë‹¤. ê·¸ëŸ¼ì—ë„ ë°ì´í„°ì–‘ (data quantity) ì„ ë‹¬ë¦¬í•˜ì—¬ ì§„í–‰í–ˆë˜ ì‹¤í—˜ ê²°ê³¼ì™€ ë¹„ìŠ·í•˜ê²Œ, iNat21 ì€ SSL ë°©ì‹ì´ ì˜ ì¡ì§€ ëª»í•˜ì˜€ë‹¤. ì´ì— ëŒ€í•œ ì›ì¸ìœ¼ë¡œ, SSL ì˜ augmentation ë“±ì˜ ë°©ì‹ì´ ImageNetì— fitting ë˜ì—ˆì„ ê°€ëŠ¥ì„±ì„ ì–¸ê¸‰í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ SSL ì—ì„œ ì‚¬ìš©ëœ color jitter augmentation ì´ ImageNet ì—ì„œëŠ” ì˜ ì‘ë™í•˜ì˜€ì§€ë§Œ iNat21ì˜ fine-grained classes ë¥¼ êµ¬ë¶„í•˜ëŠ” í•µì‹¬ feature ë¥¼ ì†ìƒì‹œì¼°ì„ ìˆ˜ ìˆëŠ” ê²ƒì´ë‹¤. </p> <h2 id="conclusion">Conclusion</h2> <ul> <li>500k ëŠ” ìˆì–´ì•¼.. 100k ëŠ” supervised learning ê³¼ ì°¨ì´ê°€ ë„ˆë¬´ í¼.</li> <li>ë‹¤ë¥¸ dataset ì‚¬ìš©í–ˆì„ ë•Œ ì„±ëŠ¥ ì°¨ì´ í¼. ë‹¨ìˆœíˆ SSL representation concat í–ˆì„ ë•Œ ì„±ëŠ¥ ë³€í™” ë¯¸ë¯¸í•¨.</li> <li>image resolution ì´ contrastive learning ì—ì„œ critical í•¨.</li> <li>SSL pretraining ì€ fine-grained classification ì„±ëŠ¥ ë©´ì—ì„œ ë²½ì„ ëŠë‚Œ.</li> </ul> <p>ìˆ˜í•™ì ì¸ ë‚´ìš©ì´ ë§ì„ ì¤„ ì•Œì•˜ëŠ”ë° ìƒê°ë³´ë‹¤ ì‹¤í—˜ ìœ„ì£¼ì—¬ì„œ ì¡°ê¸ˆ ì•„ì‰½.. í•˜ì§€ë§Œ representation fusion ì€ ì¨ë¨¹ì„ë§Œ í• ì§€ë„? (ë‹¨ìˆœ feature concat ì´ ë„ì›€ì´ ë§ì´ ë˜ëŠ”êµ¬ë§Œ)</p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; July 18, 2022 &nbsp; &middot; &nbsp; velog.io </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-VICReg-Variance-Invariance-Covariance-Regularization-for-Self-Supervised-Learning" target="_blank">[Paper Review] VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/58609359-7bdb-4ab1-b9aa-8779a77f26b6/image.png" alt=""></p> <p>Facebook AI Research (FAIR) ì—ì„œ ì‘ì„±í•œ ë…¼ë¬¸ìœ¼ë¡œ 2022ë…„ ICLR ì— ì±„íƒë˜ì—ˆë‹¤. Encoder ë‹¨ì—ì„œ ëŒ€ìƒì˜ feature ë¥¼ ë½‘ëŠ” ê³¼ì •ì—ì„œ, constantí•˜ê±°ë‚˜ non-informative vector ë¥¼ ë‚´ë†“ëŠ” collapse ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•œ ì—°êµ¬ê°€ ì§€ì†ì ìœ¼ë¡œ ì´ë£¨ì–´ì¡Œê³ , collapse ê°€ ì™œ ë°œìƒí•˜ëŠ”ì§€ì— ëŒ€í•œ ì—°êµ¬ê°€ í™œë°œíˆ ì´ë£¨ì–´ì§€ê³  ìˆë‹¤. ì´ë²ˆ ë…¼ë¬¸ì—ì„œëŠ” BN, memory bank, SG, output quantization ë“±ì˜ techniquesë¥¼ ì‚¬ìš©í•œ ê¸°ì¡´ì˜ SSL ë°©ì‹ê³¼ëŠ” ë‹¬ë¦¬ explicit í•˜ê²Œ collapse ë¥¼ í”¼í•˜ë„ë¡ ì„¤ê³„ëœ loss ì´ì™¸ì— 2ê°œì˜ regularization term ì„ ì„¤ì •í•˜ê³  ì‹¤í—˜í•˜ì—¬ collapse ë¬¸ì œì— ëŒ€í•´ ë‹¤ë£¨ì—ˆë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/712eaaab-796a-44bd-b706-5c140a94c9e4/image.png" alt=""> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/21f84e54-4768-446d-a3c6-1ed1b091538e/image.png" alt=""></p> <p>í•µì‹¬ figure ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. ê¸´ ë§‰ëŒ€ í•˜ë‚˜ë¥¼ í•˜ë‚˜ì˜ sampleë¡œë¶€í„° ë½‘íŒ feature vector ë¼ ìƒê°í–ˆì„ ë•Œ feature vector ë“¤ ê°„ì˜ variance ë¥¼ ìœ ì§€í•˜ëŠ” 1) variance term, í•˜ë‚˜ì˜ feature vector ë‚´ì—ì„œ feature ê°„ì˜ correlation ì„ 0 ìœ¼ë¡œ ë³´ë‚´ëŠ” 2) correlation term, ê¸°ì¡´ self-supervised learning ë°©ì‹ê³¼ ê°™ì´ ê°™ì€ image ë¡œë¶€í„° ë‹¤ë¥¸ augmentation (random transformation t, t&#39;) ì´ ì ìš©ëœ ë‘ feature vector ê°„ì˜ Euclidean distance ë¥¼ 0ìœ¼ë¡œ ë³´ë‚´ëŠ” 3) invariance term ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ì´ì œ ì‹ì„ ì¡°ê¸ˆ ë” ìì„¸íˆ ë³´ë„ë¡ í•˜ì.</p> <p>1) variance term <img src="https://velog.velcdn.com/images/jaeheon-lee/post/a21bd011-6e46-425b-a9d9-6ac3cac12f9c/image.png" alt=""></p> <p>ê° column ë§ˆë‹¤ ì „ì²´ feature vectorsì˜ stdë¥¼ ê³„ì‚°í•˜ê³ , hinge loss ë¥¼ í†µí•´ gamma ê°’ìœ¼ë¡œ ìœ ì§€í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆë‹¤. ì´ëŠ” ëª¨ë“  vector ê°€ í•˜ë‚˜ì˜ constant vectorë¡œ ëª¨ì´ëŠ” collapse ë¥¼ ë°©ì§€í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•œë‹¤.</p> <p>2) covariance term <img src="https://velog.velcdn.com/images/jaeheon-lee/post/ddc04015-91ad-4f94-95ba-7e140a7e4670/image.png" alt=""></p> <p>feature vector ì˜ covariance matrix ë¥¼ êµ¬í•˜ê³ , ì´ vector ì˜ diagonal part ë¥¼ ì œì™¸í•œ ë¶€ë¶„ë§Œ loss ì— í¬í•¨ì‹œì¼œ, í•˜ë‚˜ì˜ sample ì— ëŒ€í•´ì„œ ì„œë¡œ ë‹¤ë¥¸ dimension ë¼ë¦¬ì˜ correlationì„ 0ìœ¼ë¡œ ë³´ë‚´ì£¼ëŠ” ì—­í• ì„ ìˆ˜í–‰í•œë‹¤. ë§ˆì¹˜ Barlow Twinsì˜ decorrelation lossì™€ ë¹„ìŠ·í•˜ë‹¤.</p> <p>3) invariance term <img src="https://velog.velcdn.com/images/jaeheon-lee/post/6d134be2-d46f-4210-911b-d6032ff8422d/image.png" alt=""> Z (original), Z&#39; (random transformed) ì‚¬ì´ì˜ Euclidean distance ë¡œ í‘œí˜„ëœ loss ì´ë‹¤. representation space ìƒì—ì„œ positive sample ê°„ì˜ distanceë¥¼ ì¤„ì„ìœ¼ë¡œì¨ ì˜ë¯¸ìˆëŠ” representation ì´ ìˆ˜í–‰ë  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” termì´ë‹¤. ë§Œì•½ ìœ„ ë‘ê°œì˜ term ì—†ì´ ì´ invariance term ë§Œ ì¡´ì¬í–ˆë”ë¼ë©´, ê·¸ë¦¬ê³  memory bank ë° stop gradient ë“±ì˜ technique ì´ ì‚¬ìš©ë˜ì§€ ì•Šì•˜ë‹¤ë©´, representation vector ê°€ ì € square term ì˜ ìµœì†Œë¥¼ ë§Œì¡±í•˜ëŠ” í•˜ë‚˜ì˜ constant termìœ¼ë¡œ collapse í•  ê²ƒì´ë¼ëŠ” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‰½ê²Œ ìƒê°í•´ ë³¼ ìˆ˜ ìˆë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/01ab7901-0db8-4200-a857-0bb07042f2b9/image.png" alt=""></p> <p>ì‹¤ì œ ì‹¤í—˜ ê²°ê³¼ í…Œì´ë¸”ë¡œ ì´ ë…¼ë¬¸ì˜ ê°€ì¥ í•µì‹¬ì´ ë˜ëŠ” ì‹¤í—˜ ê²°ê³¼ ìë£Œì´ë‹¤. accuracy ì˜†ì— mark ê°€ ìˆëŠ” ì‹¤í—˜ setì€ original paper ì‹¤í—˜ set ì„ ì˜ë¯¸í•œë‹¤. BYOLì€ moving average, stop gradient, predictor (sgì™€ ë‹¤ë¥¸ ê³³), batch normalization ì´ ì‚¬ìš©ë˜ì—ˆê³ , SimSiam ì—ì„œëŠ” moving averageë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ ë„ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆë‹¤. 4ë²ˆì§¸ row ë¥¼ ë³´ë©´, SimSiamì—ì„œ predictor ì—†ì´ stop gradient ë§Œ ì‚¬ìš©ë˜ë©´ collapse ê°€ ë°œìƒí•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ì „ ë¸”ë¡œê·¸ì—ì„œ ë¦¬ë·°í–ˆë˜ How SimSiam works? ë…¼ë¬¸ì—ì„œ decorrelation ì„±ë¶„ê³¼ de-centering ì„±ë¶„ì´ ì¤‘ìš”í•˜ë‹¤ ì–¸ê¸‰ì´ ë˜ì—ˆì—ˆëŠ”ë°, ê·¸ ì—­í• ì„ í•´ì£¼ëŠ” variance termê³¼ correlation term ì„ ë„£ì–´ì£¼ì—ˆì„ ë•Œ collapse ë¬¸ì œê°€ í•´ê²°ë¨ê³¼ ë™ì‹œì— ì„±ëŠ¥í–¥ìƒì´ ìˆì—ˆë‹¤. ì´ëŠ” ì–¸ê¸‰í–ˆë˜ ë…¼ë¬¸ì˜ ê²°ê³¼ì™€ êµ‰ì¥íˆ consistent í•œ ê²°ê³¼ì´ë©° ì¬ë¯¸ìˆëŠ” ë¶€ë¶„ì´ë¼ ìƒê°í•´ ë³¼ ìˆ˜ ìˆë‹¤. ë˜ VICReg ì‹¤í—˜ ê²°ê³¼ì—ì„œë„, ë”±íˆ stop gradientì™€ predictor, moving averageì™€ ê°™ì€ techniqueì„ ì‚¬ìš©í•˜ì§€ ì•Šì•„ë„ explicit í•œ variance regularization termê³¼ covariance regularization termì„ ë„£ì–´ì£¼ì—ˆì„ ë•Œ collapseë¥¼ í”¼í•˜ë©´ì„œë„ ì„±ëŠ¥ì´ ê´œì°®ê²Œ ë‚˜ì˜¨ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ê²ƒë§Œìœ¼ë¡œ ì´ì „ SSL techniqueì˜ ì—­í• ê³¼ variance/covariance term ê°„ì˜ ì¸ê³¼ê´€ê³„ë¥¼ ì„¤ëª…í•  ìˆ˜ëŠ” ì—†ê² ì§€ë§Œ êµ‰ì¥íˆ ê°•ë ¥í•œ supporting ideaê°€ ë  ê²ƒì´ë‹¤.</p> <p>ì¬ë°Œêµ¬ë§Œ</p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; June 24, 2022 &nbsp; &middot; &nbsp; velog.io </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-How-Does-SimSiam-Avoid-Collapse-Without-Negative-Samples-A-Unified-Understanding-with-Self-supervised-Contrastive-Learning" target="_blank">[Paper Review] How Does SimSiam Avoid Collapse Without Negative Samples? A Unified Understanding with Self-supervised Contrastive Learning</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="how-does-simsiam-avoid-collapse-without-negative-samples-a-unified-understanding-with-self-supervised-contrastive-learning">How Does SimSiam Avoid Collapse Without Negative Samples? A Unified Understanding with Self-supervised Contrastive Learning</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/e931ea3c-b895-4e3c-b165-3febeee56fff/image.png" alt=""></p> <p>Self-supervised learning ì¤‘ contrastive learningê³¼ clustering ì„ ë„˜ì–´, BYOL (bootstrap your own latent) ë°©ì‹ì€ positive pair ê³¼ momentum encoder êµ¬ì¡°ë¥¼ ë„ë©° collapse ì—†ì´ í•™ìŠµì´ ì´ë£¨ì–´ì§„ë‹¤. ë˜í•œ SimSiam (simple Siamese networks) ì€ negative sample pairs, large batches, ê·¸ë¦¬ê³  momentum encoders ì—†ì´ meaningful representationsì„ í•™ìŠµí•œë‹¤. ê¸°ì¡´ SimSiam paper ì—ì„œ ì´ ë„¤íŠ¸ì›Œí¬ê°€ negative sample pairs ì—†ì´ collapseë¥¼ ì¼ìœ¼í‚¤ì§€ ì•Šê³  í•™ìŠµì´ ì˜ ì´ë£¨ì–´ì§€ëŠ”ì§€ì— ëŒ€í•œ ë©”ì»¤ë‹ˆì¦˜ì„ ì„¤ëª…í–ˆì§€ë§Œ, ì´ë²ˆ ë…¼ë¬¸ì—ì„  ê·¸ ë©”ì»¤ë‹ˆì¦˜ì„ ì—¬ëŸ¬ ì‹¤í—˜ ë””ìì¸ì„ í†µí•´ ë°˜ë°•í•˜ê³ , ìƒˆë¡œìš´ ë©”ì»¤ë‹ˆì¦˜ì„ ì œì‹œí•˜ì—¬ ì´ë¡ ì  / ì‹¤í—˜ì ìœ¼ë¡œ ì¦ëª…í•œë‹¤.</p> <h2 id="introduction">Introduction</h2> <p><strong>How does SimSiam avoid collapse without negative samples?</strong> ê¸°ì¡´ ì—°êµ¬ì— ë”°ë¥´ë©´ SimSiam network ì˜ &quot;stop gradient&quot;ì™€ &quot;predictor h&quot;ê°€ ì¤‘ìš”í•œ ì—­í• ì„ í–ˆë‹¤ ì„¤ëª…í•œë‹¤. êµ¬ì²´ì ìœ¼ë¡œ stop gradient ë¥¼ í†µí•´ alternative optimization ì´ ì´ë£¨ì–´ì§€ê³ , predictor ë¥¼ í†µí•´ expectation over augmentation ì˜ ê·¼ì‚¬ë¡œ ë°œìƒí–ˆë˜ gap ì˜ ì™„í™”ê°€ ì´ë£¨ì–´ì§€ê¸° ë•Œë¬¸ì´ë¼ ì„¤ëª…í•œë‹¤. </p> <p>ì €ìëŠ” ìœ„ ë‘ ë©”ì»¤ë‹ˆì¦˜ì„ ë°˜ë°•í•˜ê³ , representation vector ë¥¼ ë‘ ì„±ë¶„ (centor component ì™€ residual component) ìœ¼ë¡œ decompose í•˜ê³ , ê°ê° dimensional collapse ì— ì–´ë–¤ ì—­í• ì„ ìˆ˜í–‰í•˜ëŠ”ì§€ ê´€ì°°í•œë‹¤. ì´ ì‹¤í—˜ ë””ìì¸ ì†ì—ì„œ, &quot;extra gradient component&quot; ì—†ëŠ” basic Siamese architecture ì—ì„œëŠ” collapse ê°€ ì¼ì–´ë‚¨ì„ ë³´ì´ê³ , extra gradient component ì˜ center component ëŠ” &quot;de-cetering&quot;, residual component ëŠ” &quot;dimensional de-correlation&quot; ì„ í†µí•´ collapse ë¥¼ ì™„í™”ë¨ì„ ë³´ì¸ë‹¤.</p> <p>ë˜í•œ ìœ„ gradient decomposition ì„ í†µí•´, ê¸°ì¡´ contrastive learning ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” InfoNCE loss ë˜í•œ de-centering ê³¼ de-correlation effect ì˜ ì—­í• ì„ ìˆ˜í–‰í•¨ì„ ë³´ì—¬ self-supervised learning ì—ì„œ í†µìš©ë˜ëŠ” (unified) understanding ì— ëŒ€í•œ insight ë¥¼ ì œê³µí•œë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ SimSiam êµ¬ì¡°ì˜ ì¤‘ìš” ì—­í• ì„ ìˆ˜í–‰í•˜ëŠ” ì„±ë¶„ë§Œì„ ì´ìš©í•´ collapse ë¥¼ ë§‰ì„ ìˆ˜ ìˆìŒê¹Œì§€ ë³´ì¸ë‹¤.</p> <h2 id="revisiting-simsiam-and-its-explanatory-claims">Revisiting SimSiam and its Explanatory Claims</h2> <p><strong>l2-normalized vector and optimization goal</strong> f(x) = z ë¼ëŠ” representation ì´ ìˆì„ ë•Œ, augmentation-invariant í•œ representation ì„ ìœ„í•´ ë‘ positive sample ì˜ representation ê°„ì˜ distance, mean squared error (MSE), ë¥¼ loss ì‚¼ì•„ minimize í•œë‹¤. Scale ambiguity ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ vectorë“¤ì€ MSE ì— ë“¤ì–´ê°€ê¸° ì „ì— l2-normalized (Z = z/|z|) ëœë‹¤. ê·¸ë¦¬ê³  ì‚¬ì‹¤ ì´ëŠ” cosine loss ì™€ ë™ì¹˜ë‹¤. ì•„ë˜: <strong>Eq 1</strong></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/e29fcda2-9ded-448b-b2bf-474eca791b6d/image.png" alt=""></p> <p><strong>Collapse in SSL and solution of SimSiam</strong> Eq 1 ë§Œìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•˜ë©´, ëª¨ë“  outputì„ constantë¡œ ë‚´ë†“ì•„ë„ lossê°€ minimize ë˜ë¯€ë¡œ collapse ë¬¸ì œë¥¼ ì¼ìœ¼í‚¨ë‹¤. (ì € Eq 1 ë§Œì„ ì‚¬ìš©í•˜ëŠ” êµ¬ì¡°ë¥¼ &quot;Naive Siamese&quot; ë¼ê³  ë¶€ë¥¼ ê²ƒì„.) SimSiam êµ¬ì¡°ì—ì„œëŠ” &quot;stop gradient&quot; ì™€ &quot;predictor h&quot; ê°€ ë“¤ì–´ê°„ ë‹¤ìŒê³¼ ê°™ì€ loss ë¥¼ ì‚¬ìš©í•œë‹¤. ì•„ë˜: <strong>Eq 2</strong> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/5e327a8a-f059-4a7b-a0b3-46de41a136cb/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/6ce1bb48-2a13-442a-80e5-1bc6e82f93a5/image.png" alt=""></p> <h3 id="revisiting-explanatory-claims-in-simsiam">Revisiting explanatory claims in SimSiam</h3> <p>AO: Alternating between the Optimization of two sub-problems EOA: Expectation Over Augmentation</p> <p>ì•„ë˜ ì‹ë“¤ì€ ê¸°ì¡´ SimSiam ë…¼ë¬¸ì—ì„œì˜ í•´ì„ (stop gradient as AO, predictor as EOA) ì´ë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/55b9e068-390a-4bcb-928e-eecf62689f70/image.jpg" alt=""></p> <p>ì‰½ê²Œ ì„¤ëª…í•´, stop gradient ë¥¼ í†µí•´ alternative optimization ì´ ê°€ëŠ¥í•´ì¡Œê³ , augmentation ì„ epoch ë§ˆë‹¤ sampling í•˜ëŠ” ê²ƒ ë§Œìœ¼ë¡œë„ predictor ë¥¼ í†µí•´ augmentation distribution ì„ í•™ìŠµí•˜ì—¬ expectation over augmentation ê³¼ sampling ì‚¬ì´ì˜ gap ì„ ì™„í™”í•´ì£¼ì–´ collapse ë¥¼ ë°©ì§€í•´ ì¤€ë‹¤ëŠ” ë‚´ìš©ì´ë‹¤. ì´ ë•Œ, stop gradient ë¥¼ í†µí•œ íš¨ê³¼ì— ëŒ€í•œ ë°˜ë°•ì€ ì´ì „ ì—°êµ¬ì—ì„œ ì´ë£¨ì–´ì¡Œë‹¤ê³  í•œë‹¤.</p> <p>ë˜í•œ, ìœ„ ë…¼ë¦¬ì˜ ê°„ê·¹ (ì¶”ì¸¡) ì„ support í•˜ê¸° ìœ„í•´ &quot;predictor&quot;ë¡œ EOAë¥¼ í•˜ì§€ ì•Šê³ , &quot;$\eta_x$ ë¥¼ moving average ë°©ì‹ìœ¼ë¡œ update&quot; ë°©ì‹ìœ¼ë¡œ EOAë¥¼ ë©”ê¾¼ë‹¤ ì¹˜ê³  ì‹¤í—˜ì„ ì§„í–‰í•œë‹¤. Predictor ê°€ ì—†ì„ ë•Œ complete collapse ê°€ ì¼ì–´ë‚¬ê³ , moving average ê°€ ì—†ì„ ë•Œ complete collapse ê°€ ì¼ì–´ë‚¬ê¸°ì— (naive siamese) ë‘˜ì´ ë¹„ìŠ·í•œ ë°©ì‹ (EOA) ìœ¼ë¡œ collapse ë¥¼ ì™„í™”í•œë‹¤ ì„¤ëª…í•œë‹¤.</p> <h3 id="does-the-predictor-fill-the-gap-to-approximate-eoa">Does the predictor fill the gap to approximate EOA?</h3> <p><strong>ë­”ê°€ ì´ìƒí•œë°? by reverse of GP and SGP</strong> (c) ì˜ ìƒí™©ì€ ê°œë…ì ìœ¼ë¡œ ë´¤ì„ ë•Œ (a), (b) ì™€ ìœ ì‚¬í•˜ì§€ë§Œ SGP ê°€ ì ìš©ë˜ëŠ” êµ¬ê°„ì´ ë‹¬ë¼ì¡Œë‹¤. ì´ë¥¼ &quot;Mirror SimSiam&quot; ì´ë¼ ë¶€ë¦„. gradient path (GP) ì™€ stop gradient path (SGP) ë¥¼ ë°”ê¿”ì„œ ë°°ì¹˜í–ˆì„ ë•Œ problematic í•˜ë‹¤ ìƒê°í•œë‹¤. (ì´í•´ ì•ˆê°) ì›ë¬¸ì„ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜¤ë©´, It is worth mentioning that the Mirror SimSiam in Fig. 1 (c) is what stop gradient in the original SimSiam avoids. Therefore, it is problematic to perceive h as EOA. ë¼ê³  í•œë‹¤...</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/9df3077e-d695-4972-87f1-edc9ed11fc57/image.png" alt=""></p> <p><strong>Explicit EOA does not prevent collapse</strong> ì‹¬ìƒ´ ë…¼ë¬¸ì—ì„  ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•œë‹¤. In practice, it would be unrealistic to actually compute the expectation over augmentation. But it may be possible for a neural network (e.g., the preditor h) to learn to predict the expectation, while the sampling of T is implicitly distributed across multiple epochs. ì €ìëŠ” multiple epochì— ê±°ì³ augmentationì„ samplingí•˜ëŠ”ê²Œ beneficial í•˜ë©´, ì•„ì˜ˆ ë°°ì¹˜ í•˜ë‚˜ì—ì„œ augmentation ì„ explicití•˜ê²Œ ì—¬ëŸ¬ ë²ˆ sampling í•´ë²„ë¦¬ë©´ ë” ì´ë“ì¼ ê²ƒì´ë¼ í•˜ê³  predictor ì—†ì´ ì‹¤í—˜ì„ ìˆ˜í–‰í•œë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/295f3a57-620f-46e1-9899-bc8497e9957c/image.png" alt=""></p> <p>í•˜ì§€ë§Œ ì´ëŠ” collapse ë¥¼ ë§‰ì§€ ëª»í–ˆê³ , ì˜¤íˆë ¤ augmentationì€ ì ê²Œ ì‚¬ìš©í–ˆì§€ë§Œ moving average ë¥¼ ì‚¬ìš©í•œ ì‹¤í—˜ì—ì„  collapse ê°€ ì¼ì–´ë‚˜ì§€ ì•Šì•˜ë‹¤. EOA ê°€ collapse í‚¤í¼ë¡œì¨ì˜ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•˜ì§€ ëª»í•¨ì„ ì¦ëª…í•œë‹¤.</p> <h3 id="asymmetric-interpretation-of-predictor-with-stop-gradient-in-simsiam">Asymmetric interpretation of predictor with stop gradient in SimSiam</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/9df3077e-d695-4972-87f1-edc9ed11fc57/image.png" alt=""> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/393fbafb-8e7c-4708-8ece-58b92b5084d3/image.png" alt=""></p> <p>ê° figure ì•„ë˜ì˜ ì£¼ì„ìœ¼ë¡œ ì˜.. ë”°ë¼ê°€ ë´…ì‹œë‹¤.</p> <p><strong>Symmetric Predictor does not prevent collapse</strong> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/e9a34da6-a16d-4976-b16b-443f857131c9/image.png" alt=""></p> <p>ìœ„ table ê²°ê³¼ë¥¼ ë³´ë©´, Naive Siamese, Symmetric Predictor ì—ì„œ predictor ê°€ ìˆë˜ ì—†ë˜ symmetric architecture ë¥¼ ê°€ì§€ë©´ collapseê°€ ì¼ì–´ë‚¨ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. </p> <p><strong>Predictor with stop gradient is asymmetric</strong> SimSiamì˜ avoid collapse ëŠ” ë¹„ëŒ€ì¹­ êµ¬ì¡°ì— ìˆë‹¤ë¼ê³  í•  ìˆ˜ ìˆì–´ì¡Œë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, Mirror SimSiamì—ì„œë„ collapse ê°€ ì¼ì–´ë‚˜ëŠ” ê²ƒì„ ë³´ë©´, predictor ê°€ ì—†ëŠ” ìª½ì´ SGP ì—¬ì•¼ collapse ë¥¼ ë§‰ì„ ìˆ˜ ìˆë‹¤. ì´ë¥¼ ë‹¤ì‹œ í‘œí˜„í•˜ë©´, SimSiam avoids collapse by excluding Mirror SimSiam which has a loss as $L = -(P_a Z_b + P_bZ_a)$, where stop gradient is put on input of h, $p_a = h(sg[z_a])$.</p> <p><strong>Predictor vs. inverse predictor</strong> í¥ë¯¸ë¡œìš´ ì‹¤í—˜ì„ ë‹¤ì‹œ í•˜ë‚˜ í•œë‹¤. h ë¥¼ zì—ì„œ p ë¡œ mapping í•˜ëŠ” í•¨ìˆ˜ë¡œ ì¸ì§€í•˜ê³ , SimSiam with Symmetric Predictor ì‹¤í—˜ ë””ìì¸ì˜ SGPì— inverse predictor h-1ë¥¼ ë„£ì–´ì£¼ëŠ” ê²ƒì´ë‹¤. ì´ ë•Œ h-1ì„ optimization targetìœ¼ë¡œ ì¡ì•„ì¤Œìœ¼ë¡œì¨ collapse ê°€ ë°œìƒí•˜ì§€ ì•Šì•˜ë‹¤. (ë‚˜ì¤‘ì— ì´ê²Œ ì™œ ê·¸ëŸ¬ëƒë©´,, $h(Z_a)$ë‘ $Z_b$ ë¥¼ ë¹„ìŠ·í•˜ê²Œ ë§Œë“¤ì–´ ì¤Œìœ¼ë¡œì¨ Z ìì²´ì˜ correlationì„ ì¤„ì—¬ì¤˜ì„œ collapse ë§‰ëŠ”ê±´ë°, ì € $Z_b$ì—ë„ h ì”Œì›Œì§€ë©´ ê·¸ íš¨ê³¼ê°€ ì•ˆ ë‚˜íƒ€ë‚˜ì„œ ê·¸ë ‡ìŠµë‹ˆë‹¤.) <img src="https://velog.velcdn.com/images/jaeheon-lee/post/3e6096a2-a7dc-45c7-975a-78f400fe9522/image.png" alt=""> ì—¬ê¸°ì„œ, trainable hë¥¼ í†µí•´ collapse ê°€ ë§‰ì•„ì§€ê³ , ì„±ëŠ¥ì´ ì–´ëŠì •ë„ ë³´ì¥ëœë‹¤ëŠ” ê²ƒì„ í™•ì¸í•¨ìœ¼ë¡œì¨, h ìì²´ê°€ EOA ë¡œì¨ì˜ ê¸°ëŠ¥ì´ ì•„ë‹˜ì„ ì„¤ëª…í•œë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/1ac351bb-3a66-4c32-b0c7-5bba9783e308/image.png" alt=""></p> <h2 id="vector-decomposition-for-understanding-collapse">Vector Decomposition For Understanding Collapse</h2> <p><strong>Vector Decomposition</strong> Z ë¼ëŠ” representation vectorë¥¼ $Z = o+r$ë¡œ ë¶„í•´í•˜ê³ , ê°ê°ì„ center vector, residual vector ë¼ê³  ë¶€ë¥¸ë‹¤. íŠ¹íˆ o ëŠ” whole representation space Z ì˜ average ë¡œ ì„¤ëª…ëœë‹¤. (o_zëŠ” ì‹œê·¸ë§ˆ Z_m, Mì€ batch ì‚¬ì´ì¦ˆ) ê·¸ vectorë¥¼ ì œì™¸í•œ ë¶€ë¶„ì„ r ì´ë¼ í•œë‹¤.</p> <h3 id="collapse-from-the-vector-perspective">Collapse From the vector perspective</h3> <p>ëª¨ë“  solutionì´ collapseí•´ì„œ $o_z$ë¡œ ë–¨ì–´ì§€ëŠ” ê²ƒì€ ì•„ë‹ˆì§€ë§Œ, ì¼ë‹¨ cause of collapse ë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒì´ê¸°ì—, o ë¥¼ consequence of the collapse ë¼ ìƒê°í•˜ê³  ë¶„ì„ì„ ì§„í–‰í•œë‹¤.</p> <p><strong>Competition between o and r</strong> $Z = o+r$ ì—ì„œ oì™€ rì˜ ë¹„ìœ¨ì„ ê°ê° $m_o$, $m_r$ ì´ë¼ ì •ì˜í•œë‹¤. ì´ ë•Œ ì €ìëŠ” cause of collapse ëŠ” oì™€ rì˜ competition ì¤‘ oê°€ dominant í•´ë²„ë ¤ì„œ ë°œìƒí•œë‹¤ê³  í•´ì„í•œë‹¤. ì•„ê¹Œ Naive Siamese ì—ì„œ ì‚¬ìš©ëœ Eq 1 ì—ì„œ $Z_a$ì— ëŒ€í•œ negative gradient ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. (ì•„ë˜ê»€ Eq 3) <img src="https://velog.velcdn.com/images/jaeheon-lee/post/0fc33bfe-839d-4c61-9f61-713621e1d6de/image.png" alt=""></p> <p>($Z_a$ ê°€ dummy ë¼ í•˜ëŠ” ë¶€ë¶„ì´ ì˜ ì´í•´ê°€ ê°€ì§€ ì•Šì•˜ìŒ.) ì € gradient ì—ì„œ $Z_a$ ë¶€ë¶„ì„ ë´¤ì„ ë•Œ, $Z_a = o_z + r_a$ ì—ì„œ $o_z$ ë¶€ë¶„ì´ (gradient component) collapse ìª½ìœ¼ë¡œ boost í•  ê²ƒì´ë‹¤. ë¼ëŠ” <strong>Conjecture 1</strong> ì„ ì¡ëŠ”ë‹¤. ì´ë¥¼ ì¦ëª…í•˜ê¸° ìœ„í•´ì„œ, dummy gradient term $Z_a$ (?) ë¡œë¶€í„°, $-Z_a * sg(o_z)$ì™€ $-Z_a * sg(Z_a-o_z)$ ë¼ëŠ” loss ë¥¼ ë””ìì¸ í•œë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/6042cd31-022e-434c-b0b8-c17f1aa09a1d/image.png" alt=""></p> <p>ë§¨ ì•„ë˜ ê·¸ë˜í”„ì²˜ëŸ¼ loss ë¥¼ ì¤˜ë´¤ë”ë‹ˆ, gradient component $o_z$ ëŠ” $m_o$ë¥¼ increase í•˜ëŠ” effect ê°€ ìˆëŠ” ê²ƒì„ í™•ì¸í–ˆë‹¤.</p> <h3 id="extra-gradient-component-for-alleviating-collapse">Extra Gradient Component for Alleviating Collapse</h3> <p><strong>Revisit collapse in a &quot;symmetric&quot; architecture</strong> ì´ì „ ê²°ê³¼ë¥¼ ë¦¬ë§ˆì¸ë“œ í•´ë³´ë©´, predictor h ê°€ ìˆë˜ ì—†ë˜, symmetric êµ¬ì¡°ëŠ” ëª¨ë‘ collapse ê°€ ì¼ì–´ë‚¬ë‹¤. ê·¸ ì¤‘ Naive Siamese êµ¬ì¡°ì˜ gradientë¥¼ ëœ¯ì–´ë³´ë©´ $Z_b - Z_a = (o_z + r_b) - (o_z + r_a) = r_b - r_a$ ì´ê³ , ì´ ë•Œ $r_b$ê°€ $r_a$ ì²˜ëŸ¼ positive sample ë¡œë¶€í„° ë‚˜ì™”ê¸°ì— $m_r$ì„ increase í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ update í•˜ê² ì§€ë§Œ, $r_a$ ìì‹ ì˜ ì˜í–¥ ë³´ë‹¨ ì•½í•  ê²ƒì´ê¸° ë•Œë¬¸ì— ì˜¤íˆë ¤ $m_r$ì„ decrease í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ updateê°€ ì´ë£¨ì–´ì ¸ collapse í•œë‹¤ê³  ì„¤ëª…í•œë‹¤.</p> <p><strong>Basic gradient and Extra gradient components</strong> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/7e5454f2-5b89-47ff-bd77-7c32f1fdd10e/image.png" alt=""></p> <p>ì‰½ê²Œ ë§í•´, symmetricí•œ êµ¬ì¡°ì—ì„œì˜ gradient ë¥¼ basic gradient ë¼ ë¶€ë¥´ê³ , asymmetric í•œ êµ¬ì¡°ì—ì„œì˜ gradient ì—ì„œ basic gradient ë¥¼ ì œì™¸í•œ ê²ƒì„ Extra Gradient $G_e$ ë¼ê³  ë¶€ë¥´ìëŠ” ê²ƒì´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, SimSiam ì˜ negative gradient on $P_a$ (ì¦‰ $Z_b$) ë¥¼ $G_e$ $(Z_b-P_b)$ ì™€ $P_b$ ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆëŠ” ê²ƒì´ë‹¤. ($P_a$ ì˜ basic gradient ëŠ” $P_b$ ì´ê¸° ë•Œë¬¸!)</p> <h3 id="a-toy-example-experiment-with-negative-sample">A Toy Example Experiment with Negative Sample</h3> <p>ë‚˜ì´ë¸Œ ìƒ´ì´ ì‹¤íŒ¨í•˜ëŠ” ì›ì¸ìœ¼ë¡œ, repulsive part ê°€ ì—†ìŒì„ ê¼½ëŠ”ë‹¤. ê·¸ë˜ì„œ! contrastive loss ì—ì„œ ì–´ë–¤ repulsive component ê°€ collapse ë¥¼ ë°©ì§€í•˜ëŠ”ì§€ ì•Œì•„ë³´ê¸° ìœ„í•´, triplet loss ë¡œ ì‹¤í—˜ì„ ì§„í–‰í•œë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/c7a51372-0958-4290-80ea-dfc5b2977b10/image.png" alt=""></p> <p>ì´ ë•Œ, ì €ê±¸ $Z_a$ì— ëŒ€í•´ ë¯¸ë¶„í•˜ë©´ $Z_b - Z_n$ ì´ê³  Z_b ëŠ” basic gradient component ë‹ˆê¹Œ $-Z_n$ (negative sample ì˜ representation) ì´ ì•ì„œ ì–¸ê¸‰í–ˆë˜ $G_e$ ê°€ ëœë‹¤. ì´ë¥¼ o ì™€ r ë¡œ ë‚˜ëˆ„ì–´ì„œ ì‹¤í—˜ì„ ì§„í–‰í•œë‹¤. ì²˜ìŒ ê°€ì •ì€ ìœ„ ì‹¤í—˜ í† ëŒ€ë¡œ r component ê°€ avoid collapse ì— ì¤‘ìš”í•  ê²ƒ ê°™ë‹¤ê³  ìƒê°í–ˆëŠ”ë°, í˜„ì‹¤ì€ ì•„ë‹ˆì—ˆë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/6348ca5b-3e78-414b-a827-9a9fff35c481/image.png" alt=""></p> <p>ì˜¤íˆë ¤ removing r ì„ í–ˆì„ ë•Œ collapse ê°€ ì¼ì–´ë‚˜ì§€ ì•Šì•˜ê³ , removing o ë¥¼ í–ˆì„ ë•Œ collapse ê°€ ì¼ì–´ë‚¬ë‹¤. Conjecture 1 ê³¼ ê²¬ì£¼ì–´ ë´¤ì„ ë•Œ, ì´ ì‹¤í—˜ ê²°ê³¼ë¥¼ $o_e = -o_z$ ë¼ í•´ì„í•˜ì—¬, $o_e$ ê°€ ì˜¤íˆë ¤ ì„¼í„°ë¡œë¶€í„° ë²—ì–´ë‚˜ê²Œ í•´ì£¼ëŠ” <strong>de-centering role</strong> ì„ ìˆ˜í–‰í•  ê²ƒì´ë¼ ì„¤ëª…í•œë‹¤. (ì´í›„ ë¶„ì„ ë‚˜ì˜´.) rì€ ê·¸ëƒ¥ noise ë¡œ bahve í•œë‹¤ ìƒê°.</p> <h3 id="decomposed-gradient-analysis-in-simsiam">Decomposed Gradient Analysis in SimSiam</h3> <p>ì´ì œ naive simsiam ì´ ì•„ë‹ˆë¼ SimSiamìœ¼ë¡œ ëŒì•„ì™€ì„œ, eq 2 ë¥¼ ë¯¸ë¶„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì‹ì´ ë‚˜ì˜¨ë‹¤. Eq 4 <img src="https://velog.velcdn.com/images/jaeheon-lee/post/7e702862-053a-4041-877e-de6dbd2ff473/image.png" alt=""></p> <p>ìœ„ì™€ ê°™ì´, basic gradient ì¸ $P_b$ë¥¼ ìš°ê²¨ë„£ì–´ì„œ $G_e$ ì™€ ë¶„ë¦¬ì‹œí‚¨ë‹¤. ë‹¤ì‹œ ì´ extra gradient ë¥¼ center component ì™€ residual component ë¡œ ë‚˜ëˆ„ì–´ì„œ ì‹¤í—˜ì„ ì§„í–‰í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/d7a4b9c6-7952-4f1b-be48-397143c1dc33/image.png" alt=""></p> <p>ìœ„ triplet loss ë•Œì™€ëŠ” ë˜ ë‹¬ë¦¬, ë‘ component ì¤‘ í•˜ë‚˜ë§Œ ì¡´ì¬í•´ë„ collapse ë¥¼ ë§‰ì•„ë‚´ì—ˆë‹¤. ìš°ì„  $o_e$ ê°€ ì–´ë–»ê²Œ ë§‰ì•„ëƒˆëŠ”ì§€ë¥¼ ë¶„ì„í•œë‹¤.</p> <p><strong>How $o_e$ alleviates collapse in SimSiam</strong> ì € ì…‹ì—…ì—ì„œ $G_e = Z_b - P_b$ ì˜€ë‹¤. ì € ì‹ì„ ì˜ ì •ë¦¬í•´ë³´ë©´, center gradient component ëŠ” $o_e = o_z - o_p$ ì´ë‹¤. ì´ ë•Œ, <strong>conjecture 1</strong> ê³¼ í•¨ê»˜, ë¶„ì„ ëŒ€ìƒì€ $P_a$ì´ê¸° ë•Œë¬¸ì— ë§Œì•½ ì € $o_e$ ê°€ contains negative $o_p$ ë¥¼ ê°€ì§€ê³  ìˆë‹¤ë©´, ì„¤ëª…ì´ ëœë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/68ee0651-13bc-4f74-a00c-aa7d523f77e2/image.png" alt=""></p> <p>cosine similarity ë¥¼ í†µí•´, $o_e$ê°€ negative op ì„±ë¶„ì„ ê°€ì§€ê³  ìˆìŒì„ í™•ì¸í–ˆë‹¤. ê·¸ë ‡ê¸°ì— With Conjecture 1, this negative component explains why SimSiams avoids collapse from the perspective of <strong>de-centering</strong>.</p> <p>ë§ˆì°¬ê°€ì§€ë¡œ, Mirror SimSiam ì— ëŒ€í•´ ë™ì¼í•œ framework ë¡œ ì‹¤í—˜ì„ ìˆ˜í–‰í–ˆì„ ë•Œ, ì˜¤íˆë ¤ $o_e$ê°€ positive $o_p$ ì„±ë¶„ì„ ê°€ì§€ê³  ìˆì—ˆë‹¤. ì´ë¥¼ í† ëŒ€ë¡œ Mirror SimSiam ì—ì„œëŠ” predictor h ê°€ ë‘˜ ë‹¤ ë“¤ì–´ê°€ëŠ” ê²ƒì´ strengthen the collapse í•¨ì„ ë³´ì˜€ë‹¤.</p> <p><strong>Beyond de-centering for avoiding collapse</strong> ê·¸ë ‡ë‹¤ë©´,, ì•„ê¹Œ triplet loss ì—ì„œì˜ $r_e$ ì„±ë¶„ì€ collapse ë°©ì§€ì— ë„ì›€ì´ ì•ˆëëŠ”ë°, ì™œ ì´ë²ˆì—” $r_e$ ê°€ ë„ì›€ì´ ë˜ì—ˆì„ê¹Œ? ì´ë¥¼ ì´ì œ <strong>dimensional de-correlation</strong> ìœ¼ë¡œ ì„¤ëª…í•œë‹¤.</p> <h3 id="dimensional-de-correlation-helps-prevent-collapse">Dimensional De-Correlation Helps Prevent Collapse</h3> <p><strong>Conjecture 2</strong> : Dimensional de-correlation increases $m_r$ for preventing collapse. ì‹¤í—˜ ë””ìì¸ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.</p> <p>1) loss Eq 2 ë¡œ SimSiam ì„ í‰ë²”í•˜ê²Œ train 2) ëª‡ëª‡ epoch ì—ì„œ ì˜ë„ì ìœ¼ë¡œ $m_r$ ì„±ë¶„ì„ close to zero í•´ì„œ train 3) correlation regularization term ì„ ì´ìš©í•œ loss ë¡œ train</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/c985f8d4-f806-44c0-b6c1-1864a19abace/image.png" alt=""></p> <p>ìš”ê¸° ë³´ë©´, ì²˜ìŒì— 2) ë•Œë¬¸ì— ë–¨ì–´ì¡Œë‹¤ê°€, de-correlation regularization term ë„£ì—ˆì„ ë•Œ $m_r$ ì´ ë¹ ë¥´ê²Œ ìƒìŠ¹í•˜ëŠ” ê²ƒì„ í™•ì¸í•¨. (ìº¬)</p> <p><strong>Dimensional de-correlation in SimSiam</strong> predictor h ê°€ only has a single FC layer (??? to exclude the influence of $o_e$) ë¼ê³  ê°€ì •í•´ë³´ì. ì´ ë•Œ, ê¸°ì¡´ ì—°êµ¬ ê²°ê³¼ì— ë”°ë¥´ë©´, h weight ì˜ eigenspace ì™€ encoder output ì˜ correlation matrix ê°€ align í•œë‹¤ê³  í–ˆì—ˆìœ¼ë‹ˆ, FC layer ì˜ weight ê°€ encoder outputì˜ different dimension ê°„ì˜ correlation ì„ ì˜ í•™ìŠµí•  ê²ƒì´ë¼ ì˜ˆì¸¡í•˜ì˜€ë‹¤. ë³¸ì§ˆì ìœ¼ë¡œ, hëŠ” ë³¸ë˜ h(z_a) ì™€ I(z_b) ê°„ì˜ cosine similarity ë¥¼ ì¤„ì´ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµì´ ì´ë£¨ì–´ì§€ê¸° ë•Œë¬¸ì—, Z ìì²´ì˜ de-correlationì„ ì•¼ê¸°í•œë‹¤ê³  ì„¤ëª…í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/d7a4b9c6-7952-4f1b-be48-397143c1dc33/image.png" alt=""> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/e2b3d0d9-01fc-4abe-b7aa-ee22aa4be207/image.png" alt=""></p> <p>í‘œì—ì„œ ë³´ì•˜ë“¯ $r_e$ ê°€ collapse ë¥¼ í˜¼ìì„œë„ ë§‰ì•˜ë‹¤ëŠ” ê²°ê³¼ì™€ ì¶”í›„ ì§„í–‰ëœ ì‹¤í—˜ì—ì„œ r_e removal íŒŒíŠ¸ì—ì„œë§Œ covariance ê°€ ë†’ê³ , accuracy ê°€ ë‚®ê²Œ ë‚˜ì˜¨ ê²°ê³¼ê°€ ìœ„ ì„¤ëª…ì„ ë’·ë°›ì¹¨í•œë‹¤.</p> <h2 id="towards-a-unified-understanding-of-recent-progress-in-self-supervised-learning">Towards a Unified Understanding of Recent Progress in Self-Supervised Learning</h2> <p>SimSiam ì´ì™¸ì—ë„ contrastive learning ê³¼ ê°™ì€ self-supervised learning ë°©ì‹ë„, ë™ì¼í•œ framework ë¥¼ ì ìš©í•´ ì„¤ëª…í•˜ë ¤ í•œë‹¤.</p> <p><strong>Decentering and de-correlation in InfoNCE</strong></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/f493598e-78ce-4ec7-bd1f-30ff5f716c74/image.png" alt=""></p> <p>InfoNCE loss ë¥¼ $Z_a$ì— ëŒ€í•´ ë¯¸ë¶„í•œ negative gradient ë¥¼ ê³„ì‚°í•˜ë©´, ê²°êµ­ basic gradient ì™€ extra gradient ì„±ë¶„ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤. (ì—¬ê¸°ë¶€í„° ì§‘ì¤‘í•´ì•¼ ë¨.) extra gradientì˜ residual component ì— ë¶™ì–´ìˆëŠ” weight ëŠ” $Z_a$ì™€ $Z_i$ê°€ ê°€ê¹Œìš¸ ë•Œ (correlationì´ ë†’ì„ ë•Œ) ì»¤ì§„ë‹¤. ê·¸ëŸ¬ë¯€ë¡œ, weight ($\lambda$) ê°€ ì‘ì•„ì§€ëŠ”, decorrelation ì´ ë˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµëœë‹¤ ë¼ê³  ì„¤ëª…í•  ìˆ˜ ìˆëŠ” ê²ƒì´ë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/714f67de-f5b5-40c4-8f28-9874e6a4e735/image.jpg" alt=""></p> <p>ë˜í•œ, de-correlation effect in InfoNCE ëŠ” biased weights ($\lambda$) ë¡œë¶€í„° ë‚˜ì˜¨ë‹¤ ë¥¼ ë³´ê¸° ìœ„í•´, temperature ì— ë”°ë¥¸ lambda ë³€í™”ì— ë”°ë¥¸ ê° ì„±ë¶„ê³¼ &quot;correlation regularization loss&quot; ì™€ì˜ cosine similarity ë´¤ê³ , íŠ¹ì • temperature ì—ì„œ similarity ë†’ì•„ì§„ ê²ƒì„ í†µí•´ ê°€ì„¤ì„ ë³´ì¡° í•˜ì˜€ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/fecdea0f-0ec4-4155-8e7b-77e71492d64f/image.png" alt=""></p> <p>temperature ì— ë”°ë¼ì„œ entropy ê°€ ì¦ê°€í•˜ëŠ” ê²ƒ, temperature ì— ë”°ë¼ì„œ accuracy ë³€í™”ê°€ ìƒê¸°ëŠ” ê²ƒ, temperature ì— ë”°ë¼ì„œ covariance ë³€í™”ê°€ ìƒê¸°ëŠ” ê²ƒì„ í†µí•´ ìœ„ ê°€ì„¤ì„ ë‹¤ì‹œ corroborate í–ˆë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/51e10c29-6fbe-4903-a76e-1feeb4ff1b8e/image.png" alt=""></p> <h2 id="towards-simplifying-the-predictor-in-simsiam">Towards Simplifying the Predictor in SimSiam</h2> <p>SimSiam network ì—ì„œ í•µì‹¬ component ë§Œìœ¼ë¡œ simplify í•˜ì—¬ ì„±ëŠ¥ì„ ì¸¡ì •í•œë‹¤.</p> <ul> <li>to achieve dimensional de-correlation : a single FC layer might be sufficient because a single FC layer can realize the interaction among various dimensions.</li> <li>to achieve de-centering : a single bias layer might be sufficient because a bias vector can represent the center vector</li> </ul> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/a60f22aa-67ec-45e7-8596-9d159f2113b9/image.png" alt=""></p> <h2 id="conclusion">Conclusion</h2> <ul> <li>ê¸°ì¡´ SimSiam ë…¼ë¬¸ì—ì„œ ì„¤ëª…í•œ stop gradientì™€ predictor hì˜ ì—­í•  ê´€ë ¨ ë™ì‘ ì›ë¦¬ì˜ flaw ë¥¼ ì°¾ì•„ ë°˜ë°•í•¨.</li> <li>representation vector ë¥¼ central / residual component ë¡œ decompose í•˜ì—¬ ë¶„ì„í•¨.</li> <li>gradient ë¥¼ collapse ì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ” basic gradient ì™€ collapse ë¥¼ ë§‰ëŠ” extra gradient ë¥¼ ë‚˜ëˆ„ì–´ ë¶„ì„í•¨.</li> <li>InfoNCE ì—ì„œë„ de-correlation ê³¼ de-centering ë¥¼ ì°¾ì•„, ê¸°ì¡´ SSL ë°©ì‹ê³¼ SimSiam ë°©ì‹ ê°„ì˜ gap ì„ bridge í•¨.</li> <li>predictor êµ¬ì¡°ë¥¼ simplify í•¨ìœ¼ë¡œì¨ ìœ„ ê²°ê³¼ë¥¼ ë’·ë°›ì¹¨í•¨.</li> </ul> <p>ì²«.. ìµì¼ í‡´ê·¼ ê·¸ë ‡ì§€ë§Œ ì¬ë°‹ë‹¤</p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; May 26, 2022 &nbsp; &middot; &nbsp; velog.io </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p></li> <li><h3> <a class="post-title" href="/assets/pdf/example_pdf.pdf">a post with redirect</a> </h3> <p>you can also redirect to assets like pdf</p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; February 1, 2022 </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p></li> </ul> <nav aria-label="Blog page naviation"> <ul class="pagination pagination-lg justify-content-center"> <li class="page-item "> <a class="page-link" href="/blog/page/5/" tabindex="-1" aria-disabled="5">Newer</a> </li><li class="page-item "><a class="page-link" href="/blog/page/4/index.html" title="blog - page 4">4</a></li> <li class="page-item "><a class="page-link" href="/blog/page/5/index.html" title="blog - page 5">5</a></li> <li class="page-item active"><a class="page-link" href="/blog/page/6/index.html" title="blog - page 6">6</a></li> <li class="page-item "><a class="page-link" href="/blog/page/7/index.html" title="blog - page 7">7</a></li> <li class="page-item "><a class="page-link" href="/blog/page/8/index.html" title="blog - page 8">8</a></li> <li class="page-item "> <a class="page-link" href="/blog/page/7/">Older</a> </li> </ul> </nav> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> &copy; Copyright 2023 JaeHeon Lee. Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>