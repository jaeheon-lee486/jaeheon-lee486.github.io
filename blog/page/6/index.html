<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>blog - page 6 | JaeHeon Lee</title> <meta name="author" content="JaeHeon Lee"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🧠</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://jaeheon-lee486.github.io/blog/page/6/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">JaeHeon&nbsp;</span>Lee</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <div class="header-bar"> <h1>al-folio</h1> <h2>a simple whitespace theme for academics</h2> </div> <div class="tag-category-list"> <ul class="p-0 m-0"> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/formatting">formatting</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/images">images</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/links">links</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/math">math</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/code">code</a> </li> <p>&bull;</p> <li> <i class="fas fa-tag fa-sm"></i> <a href="/blog/category/blockquotes">blockquotes</a> </li> </ul> </div> <br> <div class="container featured-posts"> <div class="row row-cols-2"> <div class="card-item col"> <a href="/blog/2021/distill/"> <div class="card hoverable"> <div class="row g-0"> <div class="col-md-12"> <div class="card-body"> <div class="float-right"> <i class="fa-solid fa-thumbtack fa-xs"></i> </div> <h3 class="card-title text-lowercase">a distill-style blog post</h3> <p class="card-text">an example of a distill-style blog post and main elements</p> <p class="post-meta"> 8 min read &nbsp; &middot; &nbsp; <a href="/blog/2021"> <i class="fas fa-calendar fa-sm"></i> 2021 </a> </p> </div> </div> </div> </div> </a> </div> <div class="card-item col"> <a href="/blog/2015/code/"> <div class="card hoverable"> <div class="row g-0"> <div class="col-md-12"> <div class="card-body"> <div class="float-right"> <i class="fa-solid fa-thumbtack fa-xs"></i> </div> <h3 class="card-title text-lowercase">a post with code</h3> <p class="card-text">an example of a blog post with some code</p> <p class="post-meta"> 4 min read &nbsp; &middot; &nbsp; <a href="/blog/2015"> <i class="fas fa-calendar fa-sm"></i> 2015 </a> </p> </div> </div> </div> </div> </a> </div> </div> </div> <hr> <ul class="post-list"> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-Unsupervised-Learning-of-Visual-Features-by-Contrasting-Cluster-Assignments-SwAV" target="_blank">[Paper Review] Unsupervised Learning of Visual Features by Contrasting Cluster Assignments (SwAV)</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="unsupervised-learning-of-visual-features-by-contrasting-cluster-assignments">Unsupervised Learning of Visual Features by Contrasting Cluster Assignments</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/a21ca611-9ff8-4991-9cef-1d32addf68ca/image.png" alt=""></p> <p>SSL 분야에서 자주 인용되는 SwAV 모델의 페이퍼이다. 기존 contrastive learning 방식을 사용하되, pairwise comparison 을 계산할 필요 없어 online 으로도 사용한 알고리즘이다. Swapping Assignments between multiple Views of the same image (SwAV) 방식을 사용하여 같은 이미지로부터 생성된 representation vector 가 같은 prototype class 를 예측하도록 학습된다. memory bank 나 momentum network 대신 prototype (class) matrix 를 활용하기에 효율적이고, multi-crop 방식을 사용하여 생성된 resolution 이미지는 standard crop (full resolution crop) 과 달리 prototype 에 할당하지 않음으로써 메모리와 속도 면에서 향상이 있었다. 학습에 시간이 오래걸리기는 하나, 성능 면에서 supervised learning 에 가장 근접한 unsupervised learning 방식으로 소개된다. </p> <h2 id="introduction">Introduction</h2> <p>Self-supervised learning 방식에서는, same image 에서 다른 augmentation 을 적용된 image 를 생성 후 그들끼리는 가깝게, 다른 image로부터 생성된 augmentated image 와는 멀리 embedding 하는 것이 가장 기본이 된다. 하지만 모든 instance 끼리 비교하는 것은 사실상 불가능하기에, random subset (batch) 안의 instance 끼리 비교하거나, clustering 을 통해 이 instance discrimination problem을 relax 해준다. (후자 방식의) 예를 들어 DeepCluster 방식에서는 instance 끼리의 contrastive learning 이 아니라 group of instances 즉 clustering 끼리의 contrastive learning 이 이루어진다. 하지만, (이 방식은 tractable 함에도 불구하고) scalable 하지 않다. 학습을 통해 형성되는 clustering assignments 는 결국 모든 dataset image 를 사용해야 하기 때문이다. </p> <p>그렇기에 이 논문에서는 same image 로부터 다른 augmentation을 적용해 나온 code (clustering assignment)들끼리의 consistency는 유지해주면서, &quot;online&quot; 방식으로 code를 계산하는 새로운 패러다임을 제시한다. <em>deepcluster 방식을 아직 안 읽어봐서 모르지만, 이 논문에서는 code (prototype) matrix 를 encoder와 분리하여 만들고, error propagation 이 따로 이루어진다.</em> </p> <p>또한 기존 contrastive method 는 이미지 하나 당 한 쌍의 transformation 끼리 비교했던 것과 달리, SwAV 는 multi-crop 방식으로 생성된 small-sized 이미지들도 loss 계산 과정 안에 넣어 성능을 개선한다. </p> <p>그 결과 scalable online clustering loss 는 momentum encoder나 large memory bank 없이 ImageNet 에서 +2% 의 성능을 달성하였고, multi-crop 방식은 다른 SSL 방식들 보다 2%-4% 향상되었으며, self-supervised on ImageNet with a standard ResNet model 로 4.2% 향상, supervised ImageNet pretraining를 거진 여러 downstream task 에 성능 향상을 보였다.</p> <h2 id="related-work">Related Work</h2> <p>보통 이 파트는 건너 뛰는데 다른 contrastive learning 방식과 비교했을 때 SwAV 이 가지는 경쟁력, 차별점을 봐야할 필요가 있어보여 작성한다.</p> <h3 id="instance-and-contrastive-learning">Instance and contrastive learning</h3> <p>기존 unsupervised learning 에서는 각 이미지를 class 에 할당하고, 이 class 뒤에 linear classifier 를 붙여 학습을 진행했다. 하지만 이 과정은 빠르게 become intractable 했기에, 이전에 계산된 representation을 저장하는 memory bank 를 classifier 대신 사용하여 문제를 개선하였다. 보통 noise contrastive estimation, 다시 말해 InfoNCE 방식을 사용하였고, MoCo 에서는 reprsentation 을 momentum encoder 에 저장하였다. SimSiam 에서는 momentum encoder 없이 batch size 가 크다면 학습이 이루어짐도 밝혀졌다. 이렇게 모든 instance 끼리 pairwise하게 similarity 를 계산하던 기존 연구와는 달리, SwAV 에서는 image feature 를 학습 가능한 (trainable) prototype vector 에 mapping 하여 이를 학습에 활용하는 방식을 취한다.</p> <h3 id="clustering-for-deep-representation-learning">Clustering for deep representation learning</h3> <p>DeepCluster 에서 k-means assignments 를 pseudo-label 로 사용하여 학습했을 때 large uncurated dataset 에 대해서도 확장 가능하고 downstream task 에도 사용 가능함을 보였다. 하지만 이 방식은 formulation is not principled 되었었고 추후 연구 (Asano <em>et al.</em>) 에서 psuedo-label problem 과 optimal transport problem 연결 짓는 방법 (how to cast ~) 을 제시하였다. 이 연구에서도 비슷한 formulation 을 사용하였지만 Asano 의 연구처럼 Sinkhorn-Knopp algorithm output 을 hard label 에 approximating 하지 않고, soft label 로 사용하여 prototype vector 를 학습하였다. 또한 Asano 의 연구와는 달리 online assignment 방식을 사용하여 어떠한 큰 데이터셋에서도 사용할 수 있는 방식으로 발전시켰다.</p> <h2 id="method">Method</h2> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/33192de7-f71e-40e1-81fc-6bc000b4a1ff/image.png" alt=""></p> <p>가장 간단하게 (이해는 안되겠지만) 설명하자면 한 image 에 다른 augmentation 을 적용하여 encoder 를 통과시킨 representation 을 각각 z 와 z&#39; 이라고 해보자. z 를 trainable 한 prototype matrix C 를 통해 각각의 code q, q&#39; 를 생성한다. 이 때 다른 augmentation 을 적용했더라도 한 image 에서 나온 code 이기 때문에, z 로 q&#39; 을 예측할 수 있어야 하고 z&#39; 로 q 를 예측할 수 있어야 한다는 아이디어로부터, 다음과 같은 loss 를 사용하게 된다.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/b206ca5b-e089-462f-a5bb-2b3ef706d55b/image.png" alt=""></p> <p>이제 기본 theme 을 알았으니 그 내부를 까서 code 는 어떻게 생성되는 것인지, prototype matrix C 는 무엇인지, intro 에 소개된 multi-crop method 는 무엇인지 그리고 왜 사용하는지에 대해 소개하도록 하겠다.</p> <h3 id="online-clustering">Online clustering</h3> <p>각 image $x_n$ 는 transformation t sampled from the set $\tau$ 을 적용하여 $x_{nt}$ 를 생성한다. 이들은 non-linear mapping (encoder) 를 거쳐 $z_{nt}$ 로 표현되고, 각 feature 는 normalize 되어 unit sphere 상에 projection 된다. 이 뒤는 논문의 설명이다. </p> <p>We then compute a code $q_{nt}$ from this feature by mapping $z_{nt}$ to a set of K trainable prototypes vectors, {$c_1$ , ..., $c_k$}. We denote by C the matrix whose columns are the $c_1$ , ... , $c_K$. </p> <p>z 를 c (prototype vector) 를 활용해서 q로 만든다는 뜻이다. 부연설명을 하자면, q 는 z 와 c 를 이어주는 graph 형태이다. C 라는 k 개의 대표 prototype vector 를 가지고 있는 matrix 와, z 하나하나를 비교했을 때, (ex) ${q_1}$ 는 ${z_1}$ 이 K 개 중 몇 번째 prototype vector 와 제일 가까운지를 계산하여 어떤 prototype vector 에 &quot;할당&quot; 하면 될지를 &quot;안내&quot; 해주는 일종의 path 혹은 label 이라고 생각하면 편하다. 극단적으로 ${z_1}$ 이 (0.06 0.08 0) 이고, 2개의 class vector 각각 (0.06, 0.08, 0) (0.08, 0.06, 0) 을 가진 matrix C 가 있을 때 (<em>이렇게 되면 matrix C 는 [[0.06 0.08 0]; [0.08 0.06 0]]</em> ) ${q_1}$ 은 (1, 0) 이 되는 것이다.</p> <h3 id="swapped-prediction-problem">Swapped prediction problem</h3> <p>아직 명확히 납득가지는 않았겠지만, 다음 소개된 loss 를 함께 이해해보도록 하자. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/842f624a-bbf8-423a-8421-ace3b9c66c61/image.png" alt=""></p> <p>어디서 굉장히 많이 본 loss 이지 않는가? cross entropy 식 안에 들어간 q 와 p 의 첨자를 자세히 보면 각각 s 와 t 이다. 즉 다른 augmentation 이 적용된 loss 인 것이다. infoNCE loss 안을 들여다 보면, (우선 temperature가 쓰였고), z_t 와 다른 모든 prototype vector 들간의 거리에 비해, 상대적인 해당 prototype k vector c_k 사이의 거리를 뜻한다. 즉 q 는 실제로 z_s 가 어느 prototype vector 와 가장 가까운지를 특별한 알고리즘을 적용해서 &quot;답지 label&quot;를 만들어낸 것이고, p 는 z 와 c_k 사이의 상대적인 거리를 구해버린 것이다. 이렇게 해서 두 확률이 다르면 loss 가 커지게 되는 것이다. </p> <p>요약하자면, z_s 를 주어진 C prototype matrix 를 통해 어느 prototype vector 와 가까운지를 설명하는 답지 q_s 를 생성하고, z_t 와 C prototype vector 와의 상대적인 거리를 구한 p_t 를 생성하여, q_s 와 p_t 사이의 cross entropy loss 를 구하고, 그 반대인 p_s, q_t 사이에서도 CE loss 를 구하여 더해주면 우리가 원하는 최종 loss 를 구할 수 있는 것이다. 저 위의 식을 모든 N개의 image 에 대해 풀어 쓰면 다음과 같은 식으로 표현할 수 있다. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/a359a53a-db04-4df3-ad16-99994799bf1a/image.png" alt=""></p> <h3 id="computing-codes-online---sinkhorn-algorithm">Computing codes online - Sinkhorn Algorithm</h3> <p>그렇다면 답지라고 설명했던 code q 를 구하기 위해 z와 c 를 이용한다 설명했는데, 구체적으로 어떤 알고리즘을 사용하는지에 대해 설명하도록 하겠다. </p> <p>그 전에 문제 정의를 다시 해야 한다. 빵을 생산하는 베이커리 A, B가 있고, 이를 받아야 하는 학교 X, Y, Z 가 있다. A 는 300개, B 는 700개의 빵을 생산하고, 학교 X, Y, Z 는 각각 400개, 500개, 100개를 수급해야 한다. 이때, 베이커리와 학교 사이의 이동 거리를 cost value C graph 형태로 표현을 했을 때, 총 이동거리를 최소화 하면서도 학교에게 알맞은 빵을 공급하는 루트 P (transportation plan) 를 구하는 문제를 transportation polytope problem 이라 부른다.</p> <p>그 아래부터는 필기 설명으로 대체하겠다..</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/b8102164-c9dc-4d66-aa52-9280feb61e85/image.jpg" alt=""></p> <p>결국 요약하자면, 많이 생산하는 빵집은 (일단 cost matrix 를 빼고 생각했을 때) path 가 많이 뚫려 있어야 하고, 많이 소비하는 학교도 path 가 많이 뚫려 있어야 한다는 아이디어에 착안하여, rc^T 와 P 사이의 KL divergence 를 일정 parameter 이하로 보내자는 constraint 가 하나 추가되었다. 결국 이는 P 의 관점에서 봤을 때 P 의 entropy 를 maximize 하는 식이고, 이는 optimization 관점에서 봤을 때 non-convex problem 이기 때문에, convex problem 으로 바꿔주기 위해 duality 를 이용하여 새로운 convex problem 을 만든 식이 이제 3번 아래 있는 네모박스 식이다. 결국 이를 라그랑주 식을 이용해서 풀면, 어떤 두 상수 m, n 의 function 인 u 와 v vector 와 exp(-lambda c) 의 곱으로 P 가 결정되게 된다. 이 때, u 와 v 는 diagonal 에 P 는 doubly stochastic (다 normalized 되었다는 뜻) 이기 때문에 sinkhorn theorem 을 적용했을 때, normalize iteration을 수행하면 converge 한다. 그렇기에 맨 마지막에 설명되어 있는 알고리즘으로 귀결되는 것이다.. . . . .</p> <p><a href="https://amsword.medium.com/a-simple-introduction-on-sinkhorn-distances-d01a4ef4f085">https://amsword.medium.com/a-simple-introduction-on-sinkhorn-distances-d01a4ef4f085</a> 설명은 이 글을 참고하였다..</p> <p>이제 다시 우리의 문제로 돌아와서, 다음 식과 마주하게 된다.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/6ca2d368-5d28-4c41-a30c-8e09f04593fe/image.png" alt=""></p> <p>Q 는 z와 c를 이어주는 code matrix 이고, $C^TZ$ 는 두 matrix entry 사이의 거리를 표현해주는, 즉 위 문제에서의 cost matrix 가 되어준다. 위 optimization 식의 결과와 consistent 하게, 여기서도 optimal Q 를 다음과 같이 정리한다.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/77761d64-1e3b-433c-ac2a-bcd8188bd7b7/image.png" alt=""></p> <p>이 때 논문에서 본인들은 soft code 를 사용한다 표현하였다. 원래 Q matrix 자체는 discrete 하게 z_1 은 c_3 로 이어지고 z_2 는 c_4 로 이어지는 entry 가 0, 1 인 graph 형태로 표현하려 했으나, 실제로 결과를 내본 결과 z_1 은 c_3 에 0.5 c_2 에 0.2 ... 이런식으로 continuous solution Q 를 사용했을 때 성능이 더 잘 나왔다고 한다. 이는 discrete solution 으로 바꾸는 과정에서 rounding 이 사용되었고 이는 aggressive optimization 이기 때문이라 설명한다. </p> <p>또한 하나의 포인트가 더 있는데, Q 의 entropy 를 penalty term 으로 놓았기 때문에, Q matrix 가 하나의 prototype vector 로 쏠리게 할당을 하게 된다면 (어쩌면 이는 collapse) penalty 를 부여하게 된다. 즉 각 representation z 를 모든 prototype vector 에 골고루 할당하도록 하는 하나의 constraint 로 작동한다고 설명한다.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/c6cbc9fb-533c-4ccf-adb6-f28d22377bdf/image.png" alt=""></p> <h3 id="multi-crop-augmenting-views-with-smaller-images">Multi-crop: Augmenting views with smaller images</h3> <p>하나의 image 를 여러 view 로 보는 것이 성능 개선이 도움이 되는 것이 알려져 있지만, augmentation 을 늘릴수록 compute / memory requirement 가 quadratic 하게 늘어나게 된다. 이 문제를 타개하기 위해, two standard resolution crop 은 모든 다른 augmentation 과 계산을 수행하고, 다른 multi-crop sample V additional low resolution crop 들에 대해서는 서로서로 계산하지 않고 오직 two standard resolution crop 들과만 loss 계산을 수행한다. 다음과 같은 식으로 표현할 수 있다. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/94f6cc47-95ee-4ae0-93fe-8ccfdcb940e7/image.png" alt=""></p> <p>code 를 계산하는 부분은 오직 2 standard resolution 에 대해서만 수행된 것을 확인할 수 있다. 아래 섹션에서 성능차이를 보여주며, multi-crop 은 여러 self-supervised method 에서 성능 향상에 도움을 주었고 promising augmentation strategy 라 설명하고 있다.</p> <h2 id="main-results">Main Results</h2> <p>SwAV 를 통해 feature 를 학습하고, 이를 multiple dataset 에 transfer learning 하여 성능을 찍었다. SimCLR 에서 사용된 LARS, cosine learning rate, MLP projection head 를 구현하였고 성능 향상을 이뤄냈다. </p> <h3 id="evaluating-the-unsupervised-features-on-imagenet">Evaluating the unsupervised features on ImageNet</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/c3a54662-0600-4748-8bf4-97369632acbf/image.png" alt=""></p> <p>left: frozen feature 를 사용했을 때 기존 sota 를 +4.2% outperform 하고 supervised learning 과 1.2% 차이밖에 나지 않는 뛰어난 성능을 보였다. (800 epoch, 4096 large batch) right: 또한 ResNet-50 width 에 2, 4, 5 를 곱한 variants 에서도 supervised learning 과 비슷한 경향성을 보였고 그에 준하는 성능을 보여주었다. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/b9cc8201-33f0-4bda-90f2-9ce22b9fd003/image.png" alt=""></p> <p>semi-supervised learning 을 타겟하고 설계된 모델이 아님에도, sota semi-supervised learning 과 다른 self-supervised learning 을 outperform 하는 성능을 보여주었다. </p> <h3 id="transferring-unsupervised-features-to-downstream-tasks">Transferring unsupervised features to downstream tasks</h3> <p>ImageNet 을 label 없이 ResNet-50을 기반으로 학습한 SwAV 의 generalization 성능을 보기 위해, 몇몇 downstream vision task 에 transfer 하여 성능을 비교했다. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/5952e840-eba0-4994-b328-9bc1104bd487/image.png" alt=""></p> <p>왼쪽 supervised learning - linear classification 결과를 outperform 했다. 흠 왜지 appendix - places205 28 epoch, iNat18 84 epoch - 이미지 몇개 썼는지는 나와있지 않음. Our SwAV ResNet-50 model surpasses supervised ImageNet pretraining on all the considered transfer tasks and datasets.</p> <h3 id="training-with-small-batches">Training with small batches</h3> <p>SwAV 를 (이전엔 large batch 4096) small batch 256 images on 4 GPU setting 에서 실험하고, MoCov2 와 SimCLR 과 비교하였다. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/a2c6b81a-bf1c-42b3-b60f-9441597ea6fa/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/cd7979c5-4b2d-4e84-a6cd-4c29286aa90c/image.png" alt=""></p> <p>다른 방식과 비교했을 때 sota 성능을 보여주었다. SwAV 는 3840개의 feature 가 들어가는 queue 를 사용했고, MoCov2 는 momentum encoder network 를 돌리면서도 65536 개의 feature가 들어가는 queue 를 사용하였다. 또한 running time 을 기준으로 한 epoch 당 걸리는 시간은 MoCov2나 SimCLR 이 더 빨랐지만 good downstream performance 를 얻기까지의 epoch 수는 SwAV 이 더 적었다. (ex MoCov2 800 epoch 71.1, SwAV 200 epoch 72.0) 마지막으로, SwAV 는 large batch + momentum encoder 와도 사용할 수 있는데, 이는 future work 로 남겨두었다고 한다.</p> <h2 id="ablation-study">Ablation study</h2> <h3 id="clustering-based-self-supervised-learning">Clustering based self-supervised learning</h3> <h4 id="improving-prior-clustering-based-approaches">improving prior clustering-based approaches</h4> <p>과거 clustering-based model 을 재구현하고 현존 contrastive method SimCLR 과 비교하였다. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/5332d11f-3286-41e5-b288-30282ea477d9/image.png" alt=""> DeepCluster-v2 는 기존 deepcluster 의 two consecutive (ex epoch 1, 2 에서의) cluster assignments 끼리 correspondence 가 없어, epoch 이 새로 시작될 때마다 cluster assignment 와 final classification layer 이 irrelevant 하게 되어 다시 처음부터 학습되어야 한다는 큰 단점이 있었다. 이를 보완하고자, k-means clustering centroid의 explicit comparison 을 추가함으로써 stability 와 performance 를 향상하였다. </p> <h4 id="comparing-clustering-with-contrastive-instance-learning">comparing clustering with contrastive instance learning</h4> <p>SimCLR 과의 fair comparison 을 위해 SwAP 에서 사용했던 same data augmentation, epoch 수, batch size 등을 맞추어 실험을 진행하였고, 향상된 기존 clustering-based model 과 SwAV 이 SimCLR 을 성능 면에서 능가하였다. 이는 learning potential of clusteirng-based methods over instance classification 을 보여준다 설명한다.</p> <h4 id="advantage-of-swav-compared-to-deepcluster-v2">advantage of SwAV compared to DeepCluster-v2</h4> <p>성능 면에서 DeepCluster-v2 가 SwAV 을 능가하지만, 결정적으로 DeepCluster-v2 는 online algorithm 이 아니라서 large dataset 에 대해서는 작동할 수 없다. 또한 DeepCluster-v2 는 본 논문에서 제안한 swapping 방식의 special case 라 볼 수 있는데, swapping 이 batch 내에서 instance 끼리 이루어지는 것이 아니라 <strong>across epoch</strong> 에서 일어나는 것이라 해석할 수 있다. </p> <h3 id="applying-the-multi-crop-strategy-to-different-methods">Applying the multi-crop strategy to different methods</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/5332d11f-3286-41e5-b288-30282ea477d9/image.png" alt=""> figure 3 의 left 를 보면, multi-crop strategy 가 가진 성능개선 효과에 대해 알 수 있다. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/0c762192-3d62-418d-b3ac-979de4cfcb96/image.png" alt=""> 다음 loss function 은 SimCLR 에서 multi-crop strategy 를 어떻게 적용했는지를 보여준다. M 은 number of crops per instance 이고, 2x160+4x96 crops 이 있으면 M=6이 되는 것이다.</p> <h3 id="unsupervised-pretraining-on-a-large-uncurated-dataset">Unsupervised pretraining on a large uncurated dataset</h3> <p>online algorithm 을 사용함으로써 얻을 수 있는 scalability 를 증명하기 위해, instagram 으로부터 1 billion random public non-EU image (uncurated dataset) 으로 SwAV 를 pretrain 하고, ImageNet 에서 frozen feature linear classifier / finetuned feature linear classifier 성능을 비교하였다. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/b1a48d6e-332f-4b83-988b-57f09987ea4f/image.png" alt=""></p> <p>결과 SwAV에서 random initialized / SimCLR pretrained 보다 좋은 성능을 보였고, fined-tuned 에서도 역시 좋은 성능을 보여주었다. 또한 기존 ResNet-50 보다 capacity 를 늘린 ResNext 를 이용하여 동일 실험을 진행하였고 supervised models trained from scratch on ImageNet 과 비교했을 때 더 좋은 성능을 보여주었다. </p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; July 27, 2022 &nbsp; &middot; &nbsp; velog.io </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-When-Does-Contrastive-Visual-Representation-Learning-Work" target="_blank">[Paper Review] When Does Contrastive Visual Representation Learning Work?</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="when-does-contrastive-visual-representation-learning-work">When Does Contrastive Visual Representation Learning Work?</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/1804c970-4962-49cb-bf43-84d2970870f4/image.png" alt=""></p> <p>self-supervised representation learning 이 어떤 조건 하에 잘 작동하는지에 대한 insight 를 제공하는 논문이다. 크게 ImageNet, iNat21, Places365, GLC20 dataset 을 사용하여, 1) Dataset size, 2) Domain, 3) Quality, 4) Task granularity 를 달리한 실험을 진행하였다. 대부분의 실험이 SimCLR과 ResNet-50 으로 진행되었다. </p> <h2 id="introduction">Introduction</h2> <p>Under what conditions do self-supervised contrastive representation learning methods produce good visual representations?</p> <ul> <li>What is the impact of data quantity?</li> <li>What is the impact of the pretraining domain?</li> <li>What is the impact of data quality?</li> <li>What is the impact of task granularity?</li> </ul> <h2 id="methods">Methods</h2> <p>Datasets: ImageNet (1.3M images, 1k classes), iNat21 (2.7M images, 10k classes), Places365 (1.8M images, 365 classes), GLC20 (1M images, 16 classes) Fixed-size subsets: uniformly random 하게 선택하여 1M, 500k, 250k, 125k, 50k images 등을 구성함. Training details: ResNet-50 backbone 을 사용한 SimCLR 로 self-supervised learning 을 진행함.</p> <h2 id="experiments">Experiments</h2> <h3 id="data-quantity-datasize">Data Quantity (datasize)</h3> <p>SSL 에서 good representation 을 배우기 위해 필요한 데이터의 양은 얼마인가? </p> <p>다음 두가지 조건을 바꾸어 실험을 진행하였다.</p> <p>1) # of unlabeled images used for pretraining 2) # of labeled images used to subsequently train a classifier</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/c210cd4c-43f9-4eb1-bb78-47ace1e451bc/image.png" alt=""></p> <p>black line 은 supervised training 을 from scratch training 한 결과를 나타낸다. linear evaluation 는 fine tuning 과 달리 모든 parameter 를 freeze 해놓고 마지막에 linear layer 만 추가하여 이 parameter만 학습되도록 한 세팅이다. </p> <h4 id="there-is-little-benefit-beyond-500k-pretraining-images">There is little benefit beyond 500k pretraining images</h4> <p>저자는 500k (blue) 와 1M (orange) pretraining image curve 를 비교했을 때 1-2% 밖에 차이 나지 않음에 주목한다. 250k (green) 와 50k (pink) 를 비교했을 때 10% 이상의 차이를 보이는 구간도 존재하는 것으로 보아, pretraining 시에 image 개수를 500k 이상으로 늘려도 큰 효과를 보기 어렵다고 해석한다.</p> <h4 id="ssl-pretraining-can-be-a-good-initializer-when-there-is-limited-supervision">SSL pretraining can be a good initializer when there is limited supervision</h4> <p>bottom row 를 봤을 때, labeled image 가 10k, 50k인 경우 supervised learning 보다 SSL 로 pretraining 후 fine-tuning 하는 것이 significantly better 했다. 또한 labeled image 가 커짐에 따라 supervised learning 의 결과와 비슷해지는 양상을 보였다. 저자는 이를 보고 SSL 이 good initializer 라 해석하는데, 이전 연구 중 supervised learning 초기에 distort augmentation 이 들어간 image 를 사용하면 후반에 가도 일반 learning setting 의 결과를 따라잡지 못하는 결과와 함께 놓고 봤을 때 흥미롭다 해석한다.</p> <h4 id="ssl-representation-can-approach-fully-supervised-performance-for-some-dataset-but-only-by-using-lots-of-labeld-images">SSL representation can approach fully supervised performance for some dataset, but only by using lots of labeld images</h4> <p>ImageNet 과 Places365 의 결과 그래프를 봤을 때, labeled image 가 100k 일 때에도 pretraining을 1M image 로 진행한 실험 결과 성능 (orange) 는 supervised learning 의 성능 (black) 과 큰 차이가 나지 않는다 해석한다. </p> <h4 id="inat21-is-a-valuable-ssl-benchmark">iNat21 is a valuable SSL benchmark</h4> <p>iNat21 의 경우 SSL pretraining 결과들과 supervised learning 결과 (black) 사이에 large gap 이 존재한다. 이를 보고 SimCLR 이외에 MoCo, BYOL 로 실험을 진행하지만 여전히 큰 차이를 보였다. (species point 를 보면 됨) 저자는 이를 보고 iNat21 dataset 이 SSL의 challenge, 즉 아직 해결되지 않은 과제로써 향후 SSL 연구로 주목할만한 benchmark 라 언급한다.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/6fa926ff-c86f-4aa2-9da9-64f82970a112/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/13853058-0a19-4126-833f-32a3402c3d85/image.png" alt=""></p> <h3 id="data-domain">Data Domain</h3> <p>what kind of images should be use for pretraining? 어떤 데이터셋을 사용해야 하는가?</p> <p>다음과 같은 세가지 실험을 진행한다.</p> <p>1) in-domain and cross-domain linear evaluation results 2) pretraining on pooled datasets 세팅의 결과 3) differently fused representation 으로 실험한 output</p> <h4 id="pretraining-domain-matters">Pretraining domain matters</h4> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/c7f0b5f7-2e30-4e16-80a9-bab0e9a0dbd0/image.png" alt=""></p> <p>in-domain 에서 실험했을 때 성능이 가장 좋았고, cross-domain 실험 세팅 중에선 ImageNet 의 성능이 가장 좋았고 GLC20 의 성능이 가장 좋지 않았다. 특히 ImageNet 의 cross-domain 성능이 잘 나온 것을 보고 이는 <strong>&quot;semantic similarity&quot;</strong> 때문이라 해석한다. 이에 대한 다른 근거로 2가지 추가실험을 제시한다. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/842d3c76-0418-42e5-8e63-2b91452a9d14/image.png" alt=""></p> <p>animal 과 plant 의 사진으로 이루어진 iNat21 dataset 에서 taxonomic class 를 나누어 accuracy 를 측정했을 때, animal과 plant 의 사진 또한 포함되어 있는 ImageNet pretrained 모델의 성능이 특정 class 에선 높았고 다른 여러 class 에선 iNat21 pretrained 모델의 결과와 비슷한 성능을 보였다. 그에 비해 scene 정보가 많은 Place365 의 결과는 그렇지 못했다. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/34df5c83-9042-425b-a8b6-a49756163fd9/image.png" alt=""><img src="https://velog.velcdn.com/images/jaeheon-lee/post/a75683bf-0c9d-4754-85a5-2a20f4951a6f/image.png" alt=""></p> <p>또한, Places365 와 iNat21 의 in-domain accuracy 를 class 별로 break down 해서 봤을 때 (당연히 평균은 0) iNat21의 경우 약 40%의 class 는 accuracy 전반을 hurt 하고 60%의 class 는 accuracy 향상에 도움을 주었다. 이 때 60% 의 대부분은 plants 였다는 사실에 주목한다. label 이 주어지지 않았음에도 불구하고 high level 의 semantic information 에 따라 다른 결과를 내었다는 것으로 해석하여, SSL 이 representation 을 만들어내는 과정에서도 semantic similarity 가 들어간다 라고 설명한다.</p> <h4 id="adding-cross-domain-pretraining-data-general-representation-에는-그닥">Adding cross-domain pretraining data, general representation 에는 그닥</h4> <p>dataset 을 섞었을 때 성능이 어떤지 실험한다. (pretraining on pooled dataset) <img src="https://velog.velcdn.com/images/jaeheon-lee/post/3c5be69a-8462-418d-8d16-a4b24a28a3ac/image.png" alt=""></p> <p>모든 실험에서, adding pretraining data from different domain 은 성능을 저하했다. 이에 대한 원인으로 <strong>&quot;diversity-difficulty trade-off&quot;</strong> 라 설명하는데, diverse (different domain) image 가 들어오면, contrastive learning 과정에서 너무 쉬운 문제로 인식하여 성능이 떨어진다 설명한다. (SimSiam 에서도 비슷한 설명 나왔음)</p> <h4 id="self-supervised-representation-can-be-largely-redundant">Self-supervised &quot;representation&quot; can be largely redundant</h4> <p>어떤 dataset 에 pretrain 되느냐에 따라 성능이 다른 것을 보고, representation 의 차이가 어떤지 궁금하여 representation 끼리 fusion 하여 성능을 측정해 보았다. 구체적으로 저자는 concatenate features from different pretrained networks 하고 linear evaluation 을 통해 성능을 측정한다. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/65a76a0d-d288-4df0-a91e-982159cd9b29/image.png" alt=""></p> <p>1) two self-supervised representation 을 섞어도 성능 변화는 미미했다. ImageNet SimCLR alone 0.647 --&gt; combined 0.641 / iNat21 SimCLR alone 0.506 --&gt; combined 0.520 이를 통해 저자는 two self-supervised representation 은 largely &quot;redundant&quot; 함을 암시한다고 설명한다.</p> <p>2) supervised and self-supervised representation 을 섞었을 때 차이가 꽤 있었다. ImageNet SimCLR alone 0.506 --&gt; ImageNet SimCLR + iNat21 Sup 0.553 / iNat SimCLR alone 0.647 --&gt; iNat21 SimCLR + ImageNet Sup 0.605 이 때, iNat sup 을 추가했을 때 ImageNet 분류 성능이 저하되었던 것에 반하여 ImageNet sup 을 추가했을 때 iNat 분류 성능이 향상되었다. 이 또한 dataset semantics 가 SSL 에서 중요하다라는 가정과 consistent 하다 설명한다. (ImageNet의 feature 는 iNat 에게 도움, iNat 의 feature 는 ImageNet에게 도움 안됨 -&gt; 쉬운 문제라서)</p> <h3 id="data-quality">Data Quality</h3> <p>여러 image corruption 방식을 적용하여 실험을 진행한다.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/e1e41b7f-be07-4556-b478-2ed24d0c3d3a/image.png" alt=""></p> <p>이 때 Resize &amp; Downsample 은 downsample 후 upsample 을 적용하여 size 는 그대로 유지하되 resolution 을 망가뜨리는 corruption 이다. salt &amp; pepper 방식은 이미지 픽셀 단위에서 일정 확률(0.01)로 black or white 한 pixel 로 바꿔버리는 corruption 방식이다. JPEG 는 손실 압축 알고리즘을 적용하여 사람의 눈에 민감도가 적은 high frequency 정보를 제하는 방식의 corruption 이다. Resize 는 resolution을 유지하되 크기만 줄이는 방식이다. pretraining 을 corrupted image 로 진행한 뒤 기존 clean image 를 사용하여 linear evaluation 을 진행하였다. </p> <p>저자는 extreme cropping 을 사용하는 SSL 방식 특성 상 resolution 에 robust 할 것이라 예상했지만, 실제 결과를 봤을 때 SSL 방식은 resolution 을 망가뜨리는 방식에 크게 반응하여 성능 저하가 일어났다. 오히려 high-frequency noise 에 robust 한 결과를 보였고, 이는 texture information이 저하되어 설명력이 크게 감소했다 라고 설명한다. (자세한 원인이 분석되지는 않음)</p> <h3 id="task-granularity">Task Granularity</h3> <p>SSL 은 downstream task 에도 많이 사용된다. 여러 dataset 의 label 의 hierarchy 를 사용하여 fine-grained classification 의 성능을 측정한다. finest label 로 training 시키고, (retrain 없이) label set 만 바꿔 실험을 진행하였다. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/59a9fe69-0395-4ee7-8cbc-f48f9313707d/image.png" alt=""></p> <p>iNat21 결과 Supervised 모델과 달리 SimCLR 모델에서 rapid degradation 이 관측되었다. 다른 dataset 에서도 전반적으로 더 빠른 degradation 이 일어났다. 그럼에도 데이터양 (data quantity) 을 달리하여 진행했던 실험 결과와 비슷하게, iNat21 은 SSL 방식이 잘 잡지 못하였다. 이에 대한 원인으로, SSL 의 augmentation 등의 방식이 ImageNet에 fitting 되었을 가능성을 언급한다. 예를 들어 SSL 에서 사용된 color jitter augmentation 이 ImageNet 에서는 잘 작동하였지만 iNat21의 fine-grained classes 를 구분하는 핵심 feature 를 손상시켰을 수 있는 것이다. </p> <h2 id="conclusion">Conclusion</h2> <ul> <li>500k 는 있어야.. 100k 는 supervised learning 과 차이가 너무 큼.</li> <li>다른 dataset 사용했을 때 성능 차이 큼. 단순히 SSL representation concat 했을 때 성능 변화 미미함.</li> <li>image resolution 이 contrastive learning 에서 critical 함.</li> <li>SSL pretraining 은 fine-grained classification 성능 면에서 벽을 느낌.</li> </ul> <p>수학적인 내용이 많을 줄 알았는데 생각보다 실험 위주여서 조금 아쉽.. 하지만 representation fusion 은 써먹을만 할지도? (단순 feature concat 이 도움이 많이 되는구만)</p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; July 18, 2022 &nbsp; &middot; &nbsp; velog.io </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-VICReg-Variance-Invariance-Covariance-Regularization-for-Self-Supervised-Learning" target="_blank">[Paper Review] VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/58609359-7bdb-4ab1-b9aa-8779a77f26b6/image.png" alt=""></p> <p>Facebook AI Research (FAIR) 에서 작성한 논문으로 2022년 ICLR 에 채택되었다. Encoder 단에서 대상의 feature 를 뽑는 과정에서, constant하거나 non-informative vector 를 내놓는 collapse 문제를 피하기 위한 연구가 지속적으로 이루어졌고, collapse 가 왜 발생하는지에 대한 연구가 활발히 이루어지고 있다. 이번 논문에서는 BN, memory bank, SG, output quantization 등의 techniques를 사용한 기존의 SSL 방식과는 달리 explicit 하게 collapse 를 피하도록 설계된 loss 이외에 2개의 regularization term 을 설정하고 실험하여 collapse 문제에 대해 다루었다. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/712eaaab-796a-44bd-b706-5c140a94c9e4/image.png" alt=""> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/21f84e54-4768-446d-a3c6-1ed1b091538e/image.png" alt=""></p> <p>핵심 figure 는 다음과 같다. 긴 막대 하나를 하나의 sample로부터 뽑힌 feature vector 라 생각했을 때 feature vector 들 간의 variance 를 유지하는 1) variance term, 하나의 feature vector 내에서 feature 간의 correlation 을 0 으로 보내는 2) correlation term, 기존 self-supervised learning 방식과 같이 같은 image 로부터 다른 augmentation (random transformation t, t&#39;) 이 적용된 두 feature vector 간의 Euclidean distance 를 0으로 보내는 3) invariance term 으로 구성되어 있다. 이제 식을 조금 더 자세히 보도록 하자.</p> <p>1) variance term <img src="https://velog.velcdn.com/images/jaeheon-lee/post/a21bd011-6e46-425b-a9d9-6ac3cac12f9c/image.png" alt=""></p> <p>각 column 마다 전체 feature vectors의 std를 계산하고, hinge loss 를 통해 gamma 값으로 유지하도록 설계되었다. 이는 모든 vector 가 하나의 constant vector로 모이는 collapse 를 방지하는 역할을 수행한다.</p> <p>2) covariance term <img src="https://velog.velcdn.com/images/jaeheon-lee/post/ddc04015-91ad-4f94-95ba-7e140a7e4670/image.png" alt=""></p> <p>feature vector 의 covariance matrix 를 구하고, 이 vector 의 diagonal part 를 제외한 부분만 loss 에 포함시켜, 하나의 sample 에 대해서 서로 다른 dimension 끼리의 correlation을 0으로 보내주는 역할을 수행한다. 마치 Barlow Twins의 decorrelation loss와 비슷하다.</p> <p>3) invariance term <img src="https://velog.velcdn.com/images/jaeheon-lee/post/6d134be2-d46f-4210-911b-d6032ff8422d/image.png" alt=""> Z (original), Z&#39; (random transformed) 사이의 Euclidean distance 로 표현된 loss 이다. representation space 상에서 positive sample 간의 distance를 줄임으로써 의미있는 representation 이 수행될 수 있도록 하는 term이다. 만약 위 두개의 term 없이 이 invariance term 만 존재했더라면, 그리고 memory bank 및 stop gradient 등의 technique 이 사용되지 않았다면, representation vector 가 저 square term 의 최소를 만족하는 하나의 constant term으로 collapse 할 것이라는 시나리오를 쉽게 생각해 볼 수 있다.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/01ab7901-0db8-4200-a857-0bb07042f2b9/image.png" alt=""></p> <p>실제 실험 결과 테이블로 이 논문의 가장 핵심이 되는 실험 결과 자료이다. accuracy 옆에 mark 가 있는 실험 set은 original paper 실험 set 을 의미한다. BYOL은 moving average, stop gradient, predictor (sg와 다른 곳), batch normalization 이 사용되었고, SimSiam 에서는 moving average를 사용하지 않고도 좋은 성능을 보여주었다. 4번째 row 를 보면, SimSiam에서 predictor 없이 stop gradient 만 사용되면 collapse 가 발생한 것을 확인할 수 있다. 이전 블로그에서 리뷰했던 How SimSiam works? 논문에서 decorrelation 성분과 de-centering 성분이 중요하다 언급이 되었었는데, 그 역할을 해주는 variance term과 correlation term 을 넣어주었을 때 collapse 문제가 해결됨과 동시에 성능향상이 있었다. 이는 언급했던 논문의 결과와 굉장히 consistent 한 결과이며 재미있는 부분이라 생각해 볼 수 있다. 또 VICReg 실험 결과에서도, 딱히 stop gradient와 predictor, moving average와 같은 technique을 사용하지 않아도 explicit 한 variance regularization term과 covariance regularization term을 넣어주었을 때 collapse를 피하면서도 성능이 괜찮게 나온 것을 확인할 수 있다. 이것만으로 이전 SSL technique의 역할과 variance/covariance term 간의 인과관계를 설명할 수는 없겠지만 굉장히 강력한 supporting idea가 될 것이다.</p> <p>재밌구만</p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; June 24, 2022 &nbsp; &middot; &nbsp; velog.io </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-How-Does-SimSiam-Avoid-Collapse-Without-Negative-Samples-A-Unified-Understanding-with-Self-supervised-Contrastive-Learning" target="_blank">[Paper Review] How Does SimSiam Avoid Collapse Without Negative Samples? A Unified Understanding with Self-supervised Contrastive Learning</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="how-does-simsiam-avoid-collapse-without-negative-samples-a-unified-understanding-with-self-supervised-contrastive-learning">How Does SimSiam Avoid Collapse Without Negative Samples? A Unified Understanding with Self-supervised Contrastive Learning</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/e931ea3c-b895-4e3c-b165-3febeee56fff/image.png" alt=""></p> <p>Self-supervised learning 중 contrastive learning과 clustering 을 넘어, BYOL (bootstrap your own latent) 방식은 positive pair 과 momentum encoder 구조를 띄며 collapse 없이 학습이 이루어진다. 또한 SimSiam (simple Siamese networks) 은 negative sample pairs, large batches, 그리고 momentum encoders 없이 meaningful representations을 학습한다. 기존 SimSiam paper 에서 이 네트워크가 negative sample pairs 없이 collapse를 일으키지 않고 학습이 잘 이루어지는지에 대한 메커니즘을 설명했지만, 이번 논문에선 그 메커니즘을 여러 실험 디자인을 통해 반박하고, 새로운 메커니즘을 제시하여 이론적 / 실험적으로 증명한다.</p> <h2 id="introduction">Introduction</h2> <p><strong>How does SimSiam avoid collapse without negative samples?</strong> 기존 연구에 따르면 SimSiam network 의 &quot;stop gradient&quot;와 &quot;predictor h&quot;가 중요한 역할을 했다 설명한다. 구체적으로 stop gradient 를 통해 alternative optimization 이 이루어지고, predictor 를 통해 expectation over augmentation 의 근사로 발생했던 gap 의 완화가 이루어지기 때문이라 설명한다. </p> <p>저자는 위 두 메커니즘을 반박하고, representation vector 를 두 성분 (centor component 와 residual component) 으로 decompose 하고, 각각 dimensional collapse 에 어떤 역할을 수행하는지 관찰한다. 이 실험 디자인 속에서, &quot;extra gradient component&quot; 없는 basic Siamese architecture 에서는 collapse 가 일어남을 보이고, extra gradient component 의 center component 는 &quot;de-cetering&quot;, residual component 는 &quot;dimensional de-correlation&quot; 을 통해 collapse 를 완화됨을 보인다.</p> <p>또한 위 gradient decomposition 을 통해, 기존 contrastive learning 에서 자주 사용되는 InfoNCE loss 또한 de-centering 과 de-correlation effect 의 역할을 수행함을 보여 self-supervised learning 에서 통용되는 (unified) understanding 에 대한 insight 를 제공한다. 마지막으로 SimSiam 구조의 중요 역할을 수행하는 성분만을 이용해 collapse 를 막을 수 있음까지 보인다.</p> <h2 id="revisiting-simsiam-and-its-explanatory-claims">Revisiting SimSiam and its Explanatory Claims</h2> <p><strong>l2-normalized vector and optimization goal</strong> f(x) = z 라는 representation 이 있을 때, augmentation-invariant 한 representation 을 위해 두 positive sample 의 representation 간의 distance, mean squared error (MSE), 를 loss 삼아 minimize 한다. Scale ambiguity 를 방지하기 위해 vector들은 MSE 에 들어가기 전에 l2-normalized (Z = z/|z|) 된다. 그리고 사실 이는 cosine loss 와 동치다. 아래: <strong>Eq 1</strong></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/e29fcda2-9ded-448b-b2bf-474eca791b6d/image.png" alt=""></p> <p><strong>Collapse in SSL and solution of SimSiam</strong> Eq 1 만으로 학습을 진행하면, 모든 output을 constant로 내놓아도 loss가 minimize 되므로 collapse 문제를 일으킨다. (저 Eq 1 만을 사용하는 구조를 &quot;Naive Siamese&quot; 라고 부를 것임.) SimSiam 구조에서는 &quot;stop gradient&quot; 와 &quot;predictor h&quot; 가 들어간 다음과 같은 loss 를 사용한다. 아래: <strong>Eq 2</strong> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/5e327a8a-f059-4a7b-a0b3-46de41a136cb/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/6ce1bb48-2a13-442a-80e5-1bc6e82f93a5/image.png" alt=""></p> <h3 id="revisiting-explanatory-claims-in-simsiam">Revisiting explanatory claims in SimSiam</h3> <p>AO: Alternating between the Optimization of two sub-problems EOA: Expectation Over Augmentation</p> <p>아래 식들은 기존 SimSiam 논문에서의 해석 (stop gradient as AO, predictor as EOA) 이다. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/55b9e068-390a-4bcb-928e-eecf62689f70/image.jpg" alt=""></p> <p>쉽게 설명해, stop gradient 를 통해 alternative optimization 이 가능해졌고, augmentation 을 epoch 마다 sampling 하는 것 만으로도 predictor 를 통해 augmentation distribution 을 학습하여 expectation over augmentation 과 sampling 사이의 gap 을 완화해주어 collapse 를 방지해 준다는 내용이다. 이 때, stop gradient 를 통한 효과에 대한 반박은 이전 연구에서 이루어졌다고 한다.</p> <p>또한, 위 논리의 간극 (추측) 을 support 하기 위해 &quot;predictor&quot;로 EOA를 하지 않고, &quot;$\eta_x$ 를 moving average 방식으로 update&quot; 방식으로 EOA를 메꾼다 치고 실험을 진행한다. Predictor 가 없을 때 complete collapse 가 일어났고, moving average 가 없을 때 complete collapse 가 일어났기에 (naive siamese) 둘이 비슷한 방식 (EOA) 으로 collapse 를 완화한다 설명한다.</p> <h3 id="does-the-predictor-fill-the-gap-to-approximate-eoa">Does the predictor fill the gap to approximate EOA?</h3> <p><strong>뭔가 이상한데? by reverse of GP and SGP</strong> (c) 의 상황은 개념적으로 봤을 때 (a), (b) 와 유사하지만 SGP 가 적용되는 구간이 달라졌다. 이를 &quot;Mirror SimSiam&quot; 이라 부름. gradient path (GP) 와 stop gradient path (SGP) 를 바꿔서 배치했을 때 problematic 하다 생각한다. (이해 안감) 원문을 그대로 가져오면, It is worth mentioning that the Mirror SimSiam in Fig. 1 (c) is what stop gradient in the original SimSiam avoids. Therefore, it is problematic to perceive h as EOA. 라고 한다...</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/9df3077e-d695-4972-87f1-edc9ed11fc57/image.png" alt=""></p> <p><strong>Explicit EOA does not prevent collapse</strong> 심샴 논문에선 다음과 같이 표현한다. In practice, it would be unrealistic to actually compute the expectation over augmentation. But it may be possible for a neural network (e.g., the preditor h) to learn to predict the expectation, while the sampling of T is implicitly distributed across multiple epochs. 저자는 multiple epoch에 거쳐 augmentation을 sampling하는게 beneficial 하면, 아예 배치 하나에서 augmentation 을 explicit하게 여러 번 sampling 해버리면 더 이득일 것이라 하고 predictor 없이 실험을 수행한다. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/295f3a57-620f-46e1-9899-bc8497e9957c/image.png" alt=""></p> <p>하지만 이는 collapse 를 막지 못했고, 오히려 augmentation은 적게 사용했지만 moving average 를 사용한 실험에선 collapse 가 일어나지 않았다. EOA 가 collapse 키퍼로써의 기능을 수행하지 못함을 증명한다.</p> <h3 id="asymmetric-interpretation-of-predictor-with-stop-gradient-in-simsiam">Asymmetric interpretation of predictor with stop gradient in SimSiam</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/9df3077e-d695-4972-87f1-edc9ed11fc57/image.png" alt=""> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/393fbafb-8e7c-4708-8ece-58b92b5084d3/image.png" alt=""></p> <p>각 figure 아래의 주석으로 잘.. 따라가 봅시다.</p> <p><strong>Symmetric Predictor does not prevent collapse</strong> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/e9a34da6-a16d-4976-b16b-443f857131c9/image.png" alt=""></p> <p>위 table 결과를 보면, Naive Siamese, Symmetric Predictor 에서 predictor 가 있던 없던 symmetric architecture 를 가지면 collapse가 일어남을 확인할 수 있다. </p> <p><strong>Predictor with stop gradient is asymmetric</strong> SimSiam의 avoid collapse 는 비대칭 구조에 있다라고 할 수 있어졌다. 구체적으로, Mirror SimSiam에서도 collapse 가 일어나는 것을 보면, predictor 가 없는 쪽이 SGP 여야 collapse 를 막을 수 있다. 이를 다시 표현하면, SimSiam avoids collapse by excluding Mirror SimSiam which has a loss as $L = -(P_a Z_b + P_bZ_a)$, where stop gradient is put on input of h, $p_a = h(sg[z_a])$.</p> <p><strong>Predictor vs. inverse predictor</strong> 흥미로운 실험을 다시 하나 한다. h 를 z에서 p 로 mapping 하는 함수로 인지하고, SimSiam with Symmetric Predictor 실험 디자인의 SGP에 inverse predictor h-1를 넣어주는 것이다. 이 때 h-1을 optimization target으로 잡아줌으로써 collapse 가 발생하지 않았다. (나중에 이게 왜 그러냐면,, $h(Z_a)$랑 $Z_b$ 를 비슷하게 만들어 줌으로써 Z 자체의 correlation을 줄여줘서 collapse 막는건데, 저 $Z_b$에도 h 씌워지면 그 효과가 안 나타나서 그렇습니다.) <img src="https://velog.velcdn.com/images/jaeheon-lee/post/3e6096a2-a7dc-45c7-975a-78f400fe9522/image.png" alt=""> 여기서, trainable h를 통해 collapse 가 막아지고, 성능이 어느정도 보장된다는 것을 확인함으로써, h 자체가 EOA 로써의 기능이 아님을 설명한다. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/1ac351bb-3a66-4c32-b0c7-5bba9783e308/image.png" alt=""></p> <h2 id="vector-decomposition-for-understanding-collapse">Vector Decomposition For Understanding Collapse</h2> <p><strong>Vector Decomposition</strong> Z 라는 representation vector를 $Z = o+r$로 분해하고, 각각을 center vector, residual vector 라고 부른다. 특히 o 는 whole representation space Z 의 average 로 설명된다. (o_z는 시그마 Z_m, M은 batch 사이즈) 그 vector를 제외한 부분을 r 이라 한다.</p> <h3 id="collapse-from-the-vector-perspective">Collapse From the vector perspective</h3> <p>모든 solution이 collapse해서 $o_z$로 떨어지는 것은 아니지만, 일단 cause of collapse 를 분석하는 것이기에, o 를 consequence of the collapse 라 생각하고 분석을 진행한다.</p> <p><strong>Competition between o and r</strong> $Z = o+r$ 에서 o와 r의 비율을 각각 $m_o$, $m_r$ 이라 정의한다. 이 때 저자는 cause of collapse 는 o와 r의 competition 중 o가 dominant 해버려서 발생한다고 해석한다. 아까 Naive Siamese 에서 사용된 Eq 1 에서 $Z_a$에 대한 negative gradient 는 다음과 같다. (아래껀 Eq 3) <img src="https://velog.velcdn.com/images/jaeheon-lee/post/0fc33bfe-839d-4c61-9f61-713621e1d6de/image.png" alt=""></p> <p>($Z_a$ 가 dummy 라 하는 부분이 잘 이해가 가지 않았음.) 저 gradient 에서 $Z_a$ 부분을 봤을 때, $Z_a = o_z + r_a$ 에서 $o_z$ 부분이 (gradient component) collapse 쪽으로 boost 할 것이다. 라는 <strong>Conjecture 1</strong> 을 잡는다. 이를 증명하기 위해서, dummy gradient term $Z_a$ (?) 로부터, $-Z_a * sg(o_z)$와 $-Z_a * sg(Z_a-o_z)$ 라는 loss 를 디자인 한다. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/6042cd31-022e-434c-b0b8-c17f1aa09a1d/image.png" alt=""></p> <p>맨 아래 그래프처럼 loss 를 줘봤더니, gradient component $o_z$ 는 $m_o$를 increase 하는 effect 가 있는 것을 확인했다.</p> <h3 id="extra-gradient-component-for-alleviating-collapse">Extra Gradient Component for Alleviating Collapse</h3> <p><strong>Revisit collapse in a &quot;symmetric&quot; architecture</strong> 이전 결과를 리마인드 해보면, predictor h 가 있던 없던, symmetric 구조는 모두 collapse 가 일어났다. 그 중 Naive Siamese 구조의 gradient를 뜯어보면 $Z_b - Z_a = (o_z + r_b) - (o_z + r_a) = r_b - r_a$ 이고, 이 때 $r_b$가 $r_a$ 처럼 positive sample 로부터 나왔기에 $m_r$을 increase 하는 방향으로 update 하겠지만, $r_a$ 자신의 영향 보단 약할 것이기 때문에 오히려 $m_r$을 decrease 하는 방향으로 update가 이루어져 collapse 한다고 설명한다.</p> <p><strong>Basic gradient and Extra gradient components</strong> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/7e5454f2-5b89-47ff-bd77-7c32f1fdd10e/image.png" alt=""></p> <p>쉽게 말해, symmetric한 구조에서의 gradient 를 basic gradient 라 부르고, asymmetric 한 구조에서의 gradient 에서 basic gradient 를 제외한 것을 Extra Gradient $G_e$ 라고 부르자는 것이다. 예를 들어, SimSiam 의 negative gradient on $P_a$ (즉 $Z_b$) 를 $G_e$ $(Z_b-P_b)$ 와 $P_b$ 로 나눌 수 있는 것이다. ($P_a$ 의 basic gradient 는 $P_b$ 이기 때문!)</p> <h3 id="a-toy-example-experiment-with-negative-sample">A Toy Example Experiment with Negative Sample</h3> <p>나이브 샴이 실패하는 원인으로, repulsive part 가 없음을 꼽는다. 그래서! contrastive loss 에서 어떤 repulsive component 가 collapse 를 방지하는지 알아보기 위해, triplet loss 로 실험을 진행한다. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/c7a51372-0958-4290-80ea-dfc5b2977b10/image.png" alt=""></p> <p>이 때, 저걸 $Z_a$에 대해 미분하면 $Z_b - Z_n$ 이고 Z_b 는 basic gradient component 니까 $-Z_n$ (negative sample 의 representation) 이 앞서 언급했던 $G_e$ 가 된다. 이를 o 와 r 로 나누어서 실험을 진행한다. 처음 가정은 위 실험 토대로 r component 가 avoid collapse 에 중요할 것 같다고 생각했는데, 현실은 아니었다. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/6348ca5b-3e78-414b-a827-9a9fff35c481/image.png" alt=""></p> <p>오히려 removing r 을 했을 때 collapse 가 일어나지 않았고, removing o 를 했을 때 collapse 가 일어났다. Conjecture 1 과 견주어 봤을 때, 이 실험 결과를 $o_e = -o_z$ 라 해석하여, $o_e$ 가 오히려 센터로부터 벗어나게 해주는 <strong>de-centering role</strong> 을 수행할 것이라 설명한다. (이후 분석 나옴.) r은 그냥 noise 로 bahve 한다 생각.</p> <h3 id="decomposed-gradient-analysis-in-simsiam">Decomposed Gradient Analysis in SimSiam</h3> <p>이제 naive simsiam 이 아니라 SimSiam으로 돌아와서, eq 2 를 미분하면 다음과 같은 식이 나온다. Eq 4 <img src="https://velog.velcdn.com/images/jaeheon-lee/post/7e702862-053a-4041-877e-de6dbd2ff473/image.png" alt=""></p> <p>위와 같이, basic gradient 인 $P_b$를 우겨넣어서 $G_e$ 와 분리시킨다. 다시 이 extra gradient 를 center component 와 residual component 로 나누어서 실험을 진행한다.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/d7a4b9c6-7952-4f1b-be48-397143c1dc33/image.png" alt=""></p> <p>위 triplet loss 때와는 또 달리, 두 component 중 하나만 존재해도 collapse 를 막아내었다. 우선 $o_e$ 가 어떻게 막아냈는지를 분석한다.</p> <p><strong>How $o_e$ alleviates collapse in SimSiam</strong> 저 셋업에서 $G_e = Z_b - P_b$ 였다. 저 식을 잘 정리해보면, center gradient component 는 $o_e = o_z - o_p$ 이다. 이 때, <strong>conjecture 1</strong> 과 함께, 분석 대상은 $P_a$이기 때문에 만약 저 $o_e$ 가 contains negative $o_p$ 를 가지고 있다면, 설명이 된다. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/68ee0651-13bc-4f74-a00c-aa7d523f77e2/image.png" alt=""></p> <p>cosine similarity 를 통해, $o_e$가 negative op 성분을 가지고 있음을 확인했다. 그렇기에 With Conjecture 1, this negative component explains why SimSiams avoids collapse from the perspective of <strong>de-centering</strong>.</p> <p>마찬가지로, Mirror SimSiam 에 대해 동일한 framework 로 실험을 수행했을 때, 오히려 $o_e$가 positive $o_p$ 성분을 가지고 있었다. 이를 토대로 Mirror SimSiam 에서는 predictor h 가 둘 다 들어가는 것이 strengthen the collapse 함을 보였다.</p> <p><strong>Beyond de-centering for avoiding collapse</strong> 그렇다면,, 아까 triplet loss 에서의 $r_e$ 성분은 collapse 방지에 도움이 안됐는데, 왜 이번엔 $r_e$ 가 도움이 되었을까? 이를 이제 <strong>dimensional de-correlation</strong> 으로 설명한다.</p> <h3 id="dimensional-de-correlation-helps-prevent-collapse">Dimensional De-Correlation Helps Prevent Collapse</h3> <p><strong>Conjecture 2</strong> : Dimensional de-correlation increases $m_r$ for preventing collapse. 실험 디자인은 다음과 같다.</p> <p>1) loss Eq 2 로 SimSiam 을 평범하게 train 2) 몇몇 epoch 에서 의도적으로 $m_r$ 성분을 close to zero 해서 train 3) correlation regularization term 을 이용한 loss 로 train</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/c985f8d4-f806-44c0-b6c1-1864a19abace/image.png" alt=""></p> <p>요기 보면, 처음에 2) 때문에 떨어졌다가, de-correlation regularization term 넣었을 때 $m_r$ 이 빠르게 상승하는 것을 확인함. (캬)</p> <p><strong>Dimensional de-correlation in SimSiam</strong> predictor h 가 only has a single FC layer (??? to exclude the influence of $o_e$) 라고 가정해보자. 이 때, 기존 연구 결과에 따르면, h weight 의 eigenspace 와 encoder output 의 correlation matrix 가 align 한다고 했었으니, FC layer 의 weight 가 encoder output의 different dimension 간의 correlation 을 잘 학습할 것이라 예측하였다. 본질적으로, h는 본래 h(z_a) 와 I(z_b) 간의 cosine similarity 를 줄이는 방향으로 학습이 이루어지기 때문에, Z 자체의 de-correlation을 야기한다고 설명한다.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/d7a4b9c6-7952-4f1b-be48-397143c1dc33/image.png" alt=""> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/e2b3d0d9-01fc-4abe-b7aa-ee22aa4be207/image.png" alt=""></p> <p>표에서 보았듯 $r_e$ 가 collapse 를 혼자서도 막았다는 결과와 추후 진행된 실험에서 r_e removal 파트에서만 covariance 가 높고, accuracy 가 낮게 나온 결과가 위 설명을 뒷받침한다.</p> <h2 id="towards-a-unified-understanding-of-recent-progress-in-self-supervised-learning">Towards a Unified Understanding of Recent Progress in Self-Supervised Learning</h2> <p>SimSiam 이외에도 contrastive learning 과 같은 self-supervised learning 방식도, 동일한 framework 를 적용해 설명하려 한다.</p> <p><strong>Decentering and de-correlation in InfoNCE</strong></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/f493598e-78ce-4ec7-bd1f-30ff5f716c74/image.png" alt=""></p> <p>InfoNCE loss 를 $Z_a$에 대해 미분한 negative gradient 를 계산하면, 결국 basic gradient 와 extra gradient 성분으로 나눌 수 있다. (여기부터 집중해야 됨.) extra gradient의 residual component 에 붙어있는 weight 는 $Z_a$와 $Z_i$가 가까울 때 (correlation이 높을 때) 커진다. 그러므로, weight ($\lambda$) 가 작아지는, decorrelation 이 되는 방향으로 학습된다 라고 설명할 수 있는 것이다. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/714f67de-f5b5-40c4-8f28-9874e6a4e735/image.jpg" alt=""></p> <p>또한, de-correlation effect in InfoNCE 는 biased weights ($\lambda$) 로부터 나온다 를 보기 위해, temperature 에 따른 lambda 변화에 따른 각 성분과 &quot;correlation regularization loss&quot; 와의 cosine similarity 봤고, 특정 temperature 에서 similarity 높아진 것을 통해 가설을 보조 하였다.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/fecdea0f-0ec4-4155-8e7b-77e71492d64f/image.png" alt=""></p> <p>temperature 에 따라서 entropy 가 증가하는 것, temperature 에 따라서 accuracy 변화가 생기는 것, temperature 에 따라서 covariance 변화가 생기는 것을 통해 위 가설을 다시 corroborate 했다.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/51e10c29-6fbe-4903-a76e-1feeb4ff1b8e/image.png" alt=""></p> <h2 id="towards-simplifying-the-predictor-in-simsiam">Towards Simplifying the Predictor in SimSiam</h2> <p>SimSiam network 에서 핵심 component 만으로 simplify 하여 성능을 측정한다.</p> <ul> <li>to achieve dimensional de-correlation : a single FC layer might be sufficient because a single FC layer can realize the interaction among various dimensions.</li> <li>to achieve de-centering : a single bias layer might be sufficient because a bias vector can represent the center vector</li> </ul> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/a60f22aa-67ec-45e7-8596-9d159f2113b9/image.png" alt=""></p> <h2 id="conclusion">Conclusion</h2> <ul> <li>기존 SimSiam 논문에서 설명한 stop gradient와 predictor h의 역할 관련 동작 원리의 flaw 를 찾아 반박함.</li> <li>representation vector 를 central / residual component 로 decompose 하여 분석함.</li> <li>gradient 를 collapse 에 영향을 주지 않는 basic gradient 와 collapse 를 막는 extra gradient 를 나누어 분석함.</li> <li>InfoNCE 에서도 de-correlation 과 de-centering 를 찾아, 기존 SSL 방식과 SimSiam 방식 간의 gap 을 bridge 함.</li> <li>predictor 구조를 simplify 함으로써 위 결과를 뒷받침함.</li> </ul> <p>첫.. 익일 퇴근 그렇지만 재밋다</p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; May 26, 2022 &nbsp; &middot; &nbsp; velog.io </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p></li> <li><h3> <a class="post-title" href="/assets/pdf/example_pdf.pdf">a post with redirect</a> </h3> <p>you can also redirect to assets like pdf</p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; February 1, 2022 </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p></li> </ul> <nav aria-label="Blog page naviation"> <ul class="pagination pagination-lg justify-content-center"> <li class="page-item "> <a class="page-link" href="/blog/page/5/" tabindex="-1" aria-disabled="5">Newer</a> </li><li class="page-item "><a class="page-link" href="/blog/page/4/index.html" title="blog - page 4">4</a></li> <li class="page-item "><a class="page-link" href="/blog/page/5/index.html" title="blog - page 5">5</a></li> <li class="page-item active"><a class="page-link" href="/blog/page/6/index.html" title="blog - page 6">6</a></li> <li class="page-item "><a class="page-link" href="/blog/page/7/index.html" title="blog - page 7">7</a></li> <li class="page-item "><a class="page-link" href="/blog/page/8/index.html" title="blog - page 8">8</a></li> <li class="page-item "> <a class="page-link" href="/blog/page/7/">Older</a> </li> </ul> </nav> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> &copy; Copyright 2023 JaeHeon Lee. Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>