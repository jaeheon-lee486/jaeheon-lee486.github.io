<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>blog - page 5 | JaeHeon Lee</title> <meta name="author" content="JaeHeon Lee"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ğŸ§ </text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://jaeheon-lee486.github.io/blog/page/5/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">JaeHeon&nbsp;</span>Lee</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <div class="header-bar"> <h1>al-folio</h1> <h2>a simple whitespace theme for academics</h2> </div> <div class="tag-category-list"> <ul class="p-0 m-0"> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/formatting">formatting</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/images">images</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/links">links</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/math">math</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/code">code</a> </li> <p>&bull;</p> <li> <i class="fas fa-tag fa-sm"></i> <a href="/blog/category/blockquotes">blockquotes</a> </li> </ul> </div> <br> <div class="container featured-posts"> <div class="row row-cols-2"> <div class="card-item col"> <a href="/blog/2021/distill/"> <div class="card hoverable"> <div class="row g-0"> <div class="col-md-12"> <div class="card-body"> <div class="float-right"> <i class="fa-solid fa-thumbtack fa-xs"></i> </div> <h3 class="card-title text-lowercase">a distill-style blog post</h3> <p class="card-text">an example of a distill-style blog post and main elements</p> <p class="post-meta"> 8 min read &nbsp; &middot; &nbsp; <a href="/blog/2021"> <i class="fas fa-calendar fa-sm"></i> 2021 </a> </p> </div> </div> </div> </div> </a> </div> <div class="card-item col"> <a href="/blog/2015/code/"> <div class="card hoverable"> <div class="row g-0"> <div class="col-md-12"> <div class="card-body"> <div class="float-right"> <i class="fa-solid fa-thumbtack fa-xs"></i> </div> <h3 class="card-title text-lowercase">a post with code</h3> <p class="card-text">an example of a blog post with some code</p> <p class="post-meta"> 4 min read &nbsp; &middot; &nbsp; <a href="/blog/2015"> <i class="fas fa-calendar fa-sm"></i> 2015 </a> </p> </div> </div> </div> </div> </a> </div> </div> </div> <hr> <ul class="post-list"> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-Handcrafted-Histological-Transformer-H2T-Unsupervised-Representation-of-Whole-Slide-Images" target="_blank">[Paper Review] Handcrafted Histological Transformer (H2T): Unsupervised Representation of Whole Slide Images</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="handcrafted-histological-transformer-h2t-unsupervised-representation-of-whole-slide-images">Handcrafted Histological Transformer (H2T): Unsupervised Representation of Whole Slide Images</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/8a714f41-32f3-48db-b220-8200058b12c9/image.png" alt=""></p> <h2 id="introduction">Introduction</h2> <p>HoverNetì˜ ì €ìì¸ Quoc Dang Vuê°€ ì‘ì„±í•œ ë…¼ë¬¸ìœ¼ë¡œ, SwAV ì´ë¼ëŠ” self-supervised learning ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ WSI ì˜ ê° patch ì˜ prototype vector ë¥¼ ìƒì„±í•˜ê³ , ì´ prototype vector ë¡œ ì´ë£¨ì–´ì§„ representation space ì— ê° WSI ì˜ patch ë¥¼ embedding í•˜ì—¬ feature ë¥¼ ìƒì„±í•˜ì˜€ë‹¤. WSI ë‚´ patch ê°„ì˜ ìœ„ì¹˜ ì •ë³´ë„ í™œìš©í•  ìˆ˜ ìˆë„ë¡ pattern assignment map ì„ í™œìš©í•˜ì—¬ patch ì •ë³´ë¥¼ WSI ë‹¨ìœ„ë¡œ aggregate í•˜ì˜€ê³ , ì´ë¥¼ downstream analysis ì— í™œìš©í•˜ì˜€ë‹¤. patch ì •ë³´ë¥¼ WSI ë‹¨ìœ„ ì •ë³´ë¡œ aggregate í•˜ëŠ” ê³¼ì •ì—ì„œ transformer ì˜ attention mechanism ê³¼ ìœ ì‚¬í•œ ë°©ë²•ì´ ì‚¬ìš©ë˜ì–´, handcrafted histological transformer (H2T) ë¼ ì£¼ì¥í•œë‹¤. ë˜í•œ interpretability ì™€ improvement in predictive power ì‚¬ì´ì˜ trade-off ë¥¼ ì ì ˆíˆ ê·¹ë³µí•œ ë°©ë²•ì´ë¼ ì£¼ì¥í•œë‹¤.</p> <h2 id="method">Method</h2> <h3 id="handcrafted-histological-transformer-h2t">Handcrafted histological transformer (H2T)</h3> <p>Transformer ì™€ ê·¸ ë™ì‘ ì›ë¦¬ë¥¼ ë°íŒ ì—°êµ¬ì— ì˜ê°ì„ ë°›ì•„, H2T ë¥¼ ì„¤ê³„í•˜ì˜€ë‹¤. H2T ëŠ” two stage ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/f485564d-cbde-41be-b3de-780f8dbd2e73/image.png" alt=""></p> <p>a. Construction of the prototypical patterns b. Projection against these patterns</p> <p>first stage ì—ì„œ ì—¬ëŸ¬ source ë¡œë¶€í„° ì–»ì€ ì¶©ë¶„í•œ ì–‘ì˜ reference WSI ë¥¼ patch í™” í•˜ì—¬ prototypical pattern ì„ ì¶”ì¶œí•œë‹¤. íŠ¹íˆ ì „ì— ë¦¬ë·°í–ˆë˜ SwAV ë¼ëŠ” Self-supervised learning ë°©ì‹, scalable online clustering, ì„ í™œìš©í•˜ì—¬ prototypical pattern (centroids) ë¥¼ ê³„ì‚°í•œë‹¤. second stage ì—ì„œ ìƒˆë¡œìš´ WSI ë¥¼ patch í™” í•˜ì—¬ prototypical pattern ì— ëŒ€í•´ projection í•˜ê³ , constituent instance ì™€ instance ê°€ assignëœ pattern ê°„ì˜ relationship ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ, WSI ë‹¨ìœ„ì˜ summarized information ì„ ìƒì„±í•œë‹¤. </p> <h3 id="multi-head-self-attention">Multi head self-attention</h3> <p>transformer ì˜ multi head self-attention ì— ëŒ€í•´ ì„¤ëª…í•˜ê³ , ì €ìê°€ ì œì•ˆí•œ ë©”ì»¤ë‹ˆì¦˜ê³¼ synonuymous ì„ì„ ì£¼ì¥í•œë‹¤. ì´ë²ˆ ì„¹ì…˜ì˜ ê²½ìš°, ì´í•´ê°€ ì˜ ë˜ì§€ëŠ” ì•Šì•˜ë‹¤.. ë‹¤ìŒì€ K Q V relationship ì„ ë‚˜íƒ€ë‚´ëŠ” formulation ì´ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/728dfc00-0043-44fc-8b0a-6444080bb708/image.png" alt=""></p> <p>Hopfield is all you need ë…¼ë¬¸ì„ ì°¸ì¡°í–ˆì„ ë•Œ, MHAì™€ Hopfield neural network ëŠ” í° ê´€ë ¨ì´ ìˆê³ , K ì™€ V ì— ëŒ€í•´ same input Y ì™€ Q ë¥¼ rename í•œ R ì„ ì ìš©í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì‹ì„ ì–»ì„ ìˆ˜ ìˆê³ , ì´ëŠ” ëª‡ê°€ì§€ í¥ë¯¸ë¡œìš´ properties ë¥¼ ë³´ì¸ë‹¤ ì£¼ì¥í•œë‹¤. (ìŒ.. 1x1 convolution ìœ¼ë¡œ channel ìˆ˜ë¥¼ ëŠ˜ë¦¬ê³  ì´ë¥¼ Q, K, V ë¡œ í™œìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆì—ˆë‚˜? Qì™€ Kì˜ attentionë¥¼ Vì— ê³±í•´ì£¼ëŠ”ê²Œ.. ì•„ Y(instance)ë‘ R(prototypical vector)ì™€ì˜ ìœ ì‚¬ë„ë¥¼ ë³´ëŠ”ê±´ê°€? í ..)</p> <p> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/6900d663-7861-4677-988e-774392178e8d/image.png" alt=""></p> <p>First, ìœ„ ì‹ì€ (Rì„ reference ì‚¼ì•„) inputs Rê³¼ Y ì‚¬ì´ì˜ association ì„ ì°¾ëŠ” ê²ƒê³¼ ë™ì¹˜ì´ë‹¤. Second, scaling factor betaëŠ” ëª¨ë¸ì˜ memorization ê³¼ association capacity ë¥¼ ê²°ì • ì§“ê¸°ì— ì¤‘ìš”í•œ ìš”ì†Œì´ë‹¤. Finally, Rì´ trainable ì´ë¼ í–ˆì„ ë•Œ, traing setìœ¼ë¡œ ë¶€í„° prototypical patterns P ì˜ ì§‘í•©ì„ ë°°ìš°ëŠ” ì•„í‚¤í…ì³ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì–»ì„ ìˆ˜ ìˆë‹¤. (...) </p> <h3 id="positional-encoding">Positional encoding</h3> <p>ìœ„ì—ì„œ ì–¸ê¸‰í•œ ì‹ì„ ë³´ë©´, instance ê°„ì˜ ê´€ê³„ëŠ” permutation invariant í•˜ë‹¤. í•˜ì§€ë§Œ instance ì˜ ordering ì¦‰ position ì€ ì¤‘ìš”í•œ ì •ë³´ì´ê¸°ì—, MHA ì—ì„œ í‘¸ë¦¬ì— ì¸ì½”ë”©ì´ë‚˜ sine-encoding ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ positional encodingì„ í•´ì¤€ë‹¤. (ì´í›„ sine, cosine ì„ ì´ìš©í•œ positional encoding ì„¤ëª…)</p> <h3 id="handcrafted-prototypical-patterns">Handcrafted prototypical patterns</h3> <p>ìœ„ handcrafted histological transformer (H2T) ì˜ second stage ë¥¼ ë‹¤ì‹œ ë‘ ê°€ì§€ë¡œ ë‚˜ëˆ„ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.</p> <p>1) WSI ë¥¼ patch í˜¸ í•˜ì—¬ prototypical pattern ì— projection í•œë‹¤. 2) constituent instance ì™€ instance ê°€ assign ëœ pattern ê°„ì˜ relationship ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ WSI ë‹¨ìœ„ì˜ summarized info ë¥¼ ìƒì„±í•œë‹¤.</p> <h4 id="1-representation-from-histological-patterns">1) representation from histological patterns</h4> <p>Prototypical patterns ë¥¼ SwAV ë°©ì‹ìœ¼ë¡œ ë½‘ì•„ë‚´ê³ , WSI ë¥¼ ì–´ë–»ê²Œ projection í•˜ëŠëƒì— ëŒ€í•œ ì„¤ëª…ì´ ë‹´ê²¨ìˆë‹¤. (ì²˜ìŒì— ì´í•´í•˜ëŠë¼ í˜ë“¤ì—ˆë‹¤) <img src="https://velog.velcdn.com/images/jaeheon-lee/post/1257545a-cbe3-4d98-86d5-12d163aba67d/image.png" alt=""></p> <p>WSI ë¥¼ patch í™” í•˜ì—¬ (ì ì ˆí•œ backbone ì„ ê±°ì¹œ) feature vector $\psi$ ì™€ ëª¨ë“  prototypical vector ê°„ì˜ distance ë¥¼ ê³„ì‚°í•˜ì—¬, minimum distance ë¥¼ ê°€ì§„ pattern ì— assign ëœë‹¤. ìš°ì„  $\Phi_i$ ëŠ” ê° pattern ì— assign ëœ instance ì˜ ê°œìˆ˜ë¥¼ ì˜ë¯¸í•œë‹¤. $f(p_i, \psi_i)$ ëŠ” pì™€ psi ì‚¬ì´ì˜ similarity ë¥¼ measure í•´ì£¼ëŠ” attribution function ì´ë‹¤. ë”°ë¼ì„œ $H_i$ ëŠ” i ë²ˆì§¸ pattern ì— ì†í•œ vector ë“¤ì´ ì–¼ë§ˆë‚˜ centroid ì™€ ê°€ê¹Œìš´ì§€ë¥¼ ë³´ì—¬ì£¼ëŠ” ë‹¨í•©ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ instance ë¼ë¦¬ì˜ ì •ë³´ë¥¼ í•©í•œ pattern ì˜ weight, importance ë¼ ìƒê°í•  ìˆ˜ ìˆë‹¤. ì´ë¥¼ ê° pattern ë³„ë¡œ concat í•˜ì—¬ WSI ë‹¨ìœ„ì˜ H ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ë‹¤. </p> <p>ì´ ë•Œ, $f(p_i, \psi_i)$, attribution function ì„ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë‹¤ì–‘í•˜ê²Œ êµ¬ì„±í•˜ì—¬ ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/06de8b48-6915-4b5b-ac5d-aae1a32d4ad7/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/de3d134e-9668-442c-af0a-b36b0e5a5dff/image.png" alt=""></p> <h4 id="2-representation-from-co-localization-of-patterns">2) representation from co-localization of patterns</h4> <p>ì´ì œ patch instance ê°„ì˜ spatial relation ì„ ê¸°ë°˜ìœ¼ë¡œ ë˜ ë‹¤ë¥¸ WSI ë‹¨ìœ„ì˜ ì •ë³´ë¥¼ ë½‘ì•„ë‚¸ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/7f2b6fb5-3cd1-4576-a178-03ef58b242b8/image.png" alt=""></p> <p>pattern co-localization matrix (PCM) ìœ¼ë¡œ ì •ì˜ëœ ë‹¤ìŒ matrix ëŠ” $\gamma$ ê°’ (radius) ì— ë”°ë¼ ê° pattern ë¼ë¦¬ ì–¼ë§ˆë‚˜ ê°€ê¹Œì´ì— ë¶„í¬í•´ ìˆëŠ”ì§€ì— ëŒ€í•œ ì •ë³´ë¥¼ ë‹´ëŠ”ë‹¤. ë‹¤ìŒ ì‚¬ì§„ì„ ë³´ë©´ ë” ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/1231c8ed-976f-43d5-a6cc-d5da9c2e7eb0/image.png" alt=""></p> <p>8ê°œì˜ immediate neighbors ì„ ê¸°ì¤€ìœ¼ë¡œ ì–´ë–¤ pattern ì´ ëª‡ê°œê°€ ì¸ì ‘í•´ ìˆëŠ”ì§€ë¥¼ PCM ìœ¼ë¡œ ë‚˜íƒ€ë‚¸ ê²ƒì´ë‹¤. ì €ìëŠ” ì´ ë°©ë²•ì„ ì‚¬ìš©í–ˆì„ ë•Œì˜ ë¬¸ì œì ë„ ì§€ì í•˜ê³  ìˆë‹¤. gamma ê°’ì„ ì–´ëŠ ìˆ˜ì¤€ê¹Œì§€ë§Œ ë†’ì¼ ìˆ˜ ìˆë‹¤ëŠ” unscalable í•œ íŠ¹ì„±ì„ ì§€ì í•˜ë©°, CNN ì„ ì‚¬ìš©í•  ê²ƒë„ ì œì•ˆí•œë‹¤. ê° patch instance ì˜ prototypical pattern ì„ assign í–ˆê³  patch ì˜ ìœ„ì¹˜ë„ ì•Œê³  ìˆìœ¼ë¯€ë¡œ, ê·¸ spatial relation ì„ 2D CNN ìœ¼ë¡œ ë³´ê³  í•˜ë‚˜ì˜ map, pattern assignment map (PAM) ì„ ì–»ì„ ìˆ˜ ìˆë‹¤ê³  ì£¼ì¥í•œë‹¤. ë˜í•œ, PAM ì€ raw pixel intensity ë¥¼ ê°€ì§€ì§€ ì•Šê³  discrete value ë¥¼ ê°€ì§€ê¸° ë•Œë¬¸ì—, PAM ì„ directly learn í•˜ë„ë¡ ì„¤ê³„í•˜ëŠ” ê²ƒë³´ë‹¤ CNN ì„ í•™ìŠµí•¨ìœ¼ë¡œì¨ Deep PAM feature ë¥¼ ì–»ê³ , ì´ë¥¼ WSI ë³„ë¡œ C ë¼ëŠ” feature ë¡œ ì¶”ì¶œí•  ê²ƒì„ ì œì•ˆí•˜ê³  ìˆë‹¤. </p> <h2 id="experimental-results">Experimental Results</h2> <h3 id="datasets">Datasets</h3> <p>TCGA ì™€ CPTAC ì˜ 2ê°œì˜ ì•”ì¢… (LUAD, LUSC, Normal) ì˜ FFPE, Frozen slide ë¥¼ ì‚¬ìš©í•˜ì—¬, ì´ 1245ëª…ì˜ í™˜ììë¡œë¶€í„° 5306 ì¥ì˜ WSI ë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/dd3309c0-45d0-402b-baa3-776c557de511/image.png" alt=""></p> <h3 id="evaluation">Evaluation</h3> <p>ì—¬ëŸ¬ attribution function ì„ ì‚¬ìš©í•´ WSI ë¡œë¶€í„° ì¶”ì¶œí•œ H2T feature ëŠ” linear probing ë°©ì‹ìœ¼ë¡œ downstream task ì— ì ìš©ë˜ì–´ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ì˜€ë‹¤. CPTAC ì™€ TCGA ë‘˜ ì¤‘ í•˜ë‚˜ë¥¼ training set ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ , ë‚˜ë¨¸ì§€ë¥¼ validation set ìœ¼ë¡œ í™œìš©í•˜ì˜€ë‹¤. êµ¬ì²´ì ìœ¼ë¡œ LUAD, LUSC, normal ì‚¬ì´ë¥¼ classify í•˜ëŠ” task ë¥¼ 5-fold crss validation í•˜ì—¬ ìˆ˜ì¹˜ë¥¼ ê¸°ë¡í•˜ì˜€ë‹¤. </p> <h3 id="implementation-details">Implementation details</h3> <p>size 512x512 with 256x256 overlapping ë°©ì‹ìœ¼ë¡œ patchë¥¼ ì¶”ì¶œí•˜ì˜€ê³ , pretrained ResNet50 ìœ¼ë¡œ ê¸°ë³¸ representation ì„ ë½‘ì•„ë‚´ì—ˆë‹¤. 40xì™€ 20x magnification ì„ ê°€ì§„ WSI ë¥¼ ì‚¬ìš©í•˜ì˜€ê³ , SwAV ìœ¼ë¡œ í•˜ì—¬ê¸ˆ 16 x 2048 vector (16ê°œì˜ cluster, 2048-dimensional) ë¥¼ í•™ìŠµí•˜ë„ë¡ ì„¤ê³„í•˜ì˜€ë‹¤. </p> <h3 id="prototypical-patterns">Prototypical patterns</h3> <p>further assessment ì´ì „ì— SwAV prototypical pattern ì˜ sanity check ë¥¼ ìˆ˜í–‰í•˜ì˜€ë‹¤. 4ê°œì˜ set (normal, LUAD, LUSC, all) ì˜ TCGA WSI ì™€ SwAV-ResNet50 ì„ ì´ìš©í•˜ì—¬ 16 prototypical pattern ì„ ë½‘ì•„ë‚´ì—ˆë‹¤. ì´í›„ pattern assignment ë¥¼ ìˆ˜í–‰í•˜ê³ , pathologist annotation ê³¼ ë¹„êµí•˜ì˜€ë‹¤. train ì€ TCGA ë¡œ í–ˆì§€ë§Œ PAM ì€ ACDC dataset ì„ ì´ìš©í•˜ì—¬ map ì„ ê·¸ë ¤ë³´ì•˜ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/6e82d7ab-f6f8-4c9e-a9ae-2fab495fce76/image.png" alt=""></p> <p>6ë²ˆê³¼ 16ë²ˆ pattern ì´ normal ê³¼ ê´€ë ¨ì„ ë³´ì˜€ê³ , 1ë²ˆ, 13ë²ˆ ì€ LUAD tumor, 15ë²ˆì€ LUSC tumor pattern ê³¼ ì—°ê´€ì„±ì„ ë³´ì˜€ë‹¤. LUAD, LUSC ì™€ pathologist ì˜ annotation ê³¼ ê°ê° 0.6879, 0.8407 ì˜ Pearson Correlation Coefficient ë¥¼ ê¸°ë¡í•˜ì˜€ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/b259692c-56c0-47e5-9321-ea05d2b2c485/image.png" alt=""></p> <p>ê°™ì€ prototypical pattern ìœ¼ë¡œ reference cohort TCGA, unseen cohort CPTAC setting ì—ì„œ 3 dataset LUAD, LUSC, normal ì„ visualization í•˜ì˜€ë‹¤. ê²°ê³¼ tumorous, stromal region ê°„ì˜ pattern consistency ë¥¼ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤. </p> <h3 id="comparative-evaluation">Comparative evaluation</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/00f73a60-0cbf-4fb5-8cce-6f69de5ac62f/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/4547a013-8cce-451d-8d1f-a18b8f24ec69/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/b78c3512-b5f2-4bc2-9d17-cda1e1d08f18/image.png" alt=""></p> <p>normal vs tumor, LUAD vs LUSC, Normal vs LUAD vs LUSC WSI classification task ê²°ê³¼ 5 fold AUROC (or mAP) ì„ ë‚˜íƒ€ë‚¸ ê²°ê³¼ì´ë‹¤. </p> <h3 id="abltaion-study">Abltaion study</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/58514402-6f32-4e1f-8d60-2d63b2439fda/image.png" alt=""></p> <p>CNN ì„ í™œìš©í•˜ê¸° ì „ C ë¥¼ í™œìš©í•˜ëŠ” ë°©ë²•ì— ë”°ë¥¸ ì„±ëŠ¥ ìˆ˜ì¹˜ì´ë‹¤. Normal vs Tumor classification task ì´ë‹¤. CëŠ” co-localization matrix of patterns within PAM, C-raw ëŠ” PAM ì„ CNN ìœ¼ë¡œ í•™ìŠµ, C-one-hot ì€ pattern ì„ one-hot encoding í•œ í›„ CNN ì— ë„£ì–´ í•™ìŠµí•œ ê²°ê³¼ ì´ë‹¤. </p> <h3 id="discovery-experiments">Discovery experiments</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/145371d7-9014-4182-8c58-5a713157620e/image.png" alt=""></p> <p>discovering anomalous WSI task ë¥¼ ì˜ ìˆ˜í–‰í•˜ëŠ” ê°€ë„ ì¶”ê°€ downstream task ë¡œ ì§„í–‰í•˜ì˜€ë‹¤. 16 x 2048 feature, ì¦‰ high-dimensional vector ë¥¼ visualization í•˜ê¸° ìœ„í•´ UMAP ë¡œ 2D planeì— ê° WSI ë¥¼ ë‚˜íƒ€ë‚´ì—ˆë‹¤. ê²°ê³¼ LUAD, LUSC ëŠ” around 0.8 (orange) ì— ë¨¸ë¬¼ë €ì§€ë§Œ, normal WSI ëŠ” distinctly high anomaly score ë¥¼ ê°€ì¡Œë‹¤. ë˜í•œ unsupervised clustering of WSI ì¸¡ë©´ì—ì„œë„ LUAD, LUSC, normal ê°„ separation ì„ ê´€ì¸¡í•  ìˆ˜ ìˆì—ˆë‹¤. </p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; September 25, 2022 &nbsp; &middot; &nbsp; jaeheon-lee </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Book-Review-How-AI-and-the-Brain-work" target="_blank">[ë„ì„œ ë¦¬ë·°] ì¸ê³µì§€ëŠ¥ê³¼ ë‡ŒëŠ” ì–´ë–»ê²Œ ìƒê°í•˜ëŠ”ê°€</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="ì¸ê³µì§€ëŠ¥ê³¼-ë‡ŒëŠ”-ì–´ë–»ê²Œ-ìƒê°í•˜ëŠ”ê°€">ì¸ê³µì§€ëŠ¥ê³¼ ë‡ŒëŠ” ì–´ë–»ê²Œ ìƒê°í•˜ëŠ”ê°€</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/b9db6c65-704a-460a-bbf1-b0839a5eb35e/image.png" alt=""></p> <h2 id="--">--</h2> <p>ë…¼ë¬¸ ë¦¬ë·°ë§Œ ì˜¬ë¦¬ë˜ ì´ ê³µê°„ì—ë„ ë“œë””ì–´ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì˜ ê¸€ì„ ì“°ê²Œ ë˜ì—ˆë‹¤. ã…ã… TensorflowKR (í˜ì´ìŠ¤ë¶ ê·¸ë£¹) ì—ì„œ ì‘ë…„ 1ë…„ê°„ ì—°êµ¬ë¥¼ ì§€ë„í•´ì£¼ì…¨ë˜ ì´ìƒì™„ êµìˆ˜ë‹˜ (ê°“) ì´ ì±…ì„ ë‚´ì…¨ë‹¤ëŠ” ì†Œì‹ì„ ì ‘í–ˆê³ , ë§ˆì¹¨ í™œë™í•˜ê¸° ì‹œì‘í•œ brain and cognitive science community (BCSC) ì—ì„œ ì±…ì„ ì§€ì›í•´ì¤€ë‹¤ëŠ” ê¸°ìœ ì†Œì‹ì„ ë“£ê³  ë°”ë¡œ ì‹ ì²­í•˜ì˜€ë‹¤. ë¦¬ë·°ë¥¼ ì‹œì‘í•˜ê¸° ì „, í•„ìëŠ” AIì™€ computational neuroscienceì— ê´€ì‹¬ì´ ë§ê³ , ì´ë¯¸ ì±…ì˜ ë‚´ìš©ê³¼ ê´€ë ¨ëœ ì „ê³µ ìˆ˜ì—…ê³¼ í”„ë¡œì íŠ¸ë¥¼ ê±°ì¹œ í•™ìƒì„ì„ ë°íŒë‹¤.</p> <h2 id="---1">--</h2> <p>í”„ë¡¤ë¡œê·¸ì™€ 7ì¥ì— ê±°ì¹œ ë³¸ë¬¸, ì—í•„ë¡œê·¸, ì°¸ê³ ë¬¸í—Œìœ¼ë¡œ ë‚´ìš©ì´ êµ¬ì„±ë˜ì–´ ìˆê³ , ë‚œì´ë„ëŠ” AIë¥¼ ì¡°ê¸ˆì´ë¼ë„ ì ‘í•´ë³¸ ì‚¬ëŒì´ë©´ ì‰½ê²Œ ì½ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤. ì¢…ì´ì ‘ê¸° ë¡œë¶€í„° ì‹œì‘ë˜ëŠ” ë¹„ìœ ë“¤ì„ ë³´ë©´ì„œ êµìˆ˜ë‹˜ì´ ì´ ë‚´ìš©ë“¤ì„ <strong>ì‰½ê²Œ</strong> ì „ë‹¬í•˜ê³ ì í•˜ëŠ” ê°•í•œ ì˜ì§€ (?) ë¥¼ ëŠë‚„ ìˆ˜ ìˆì—ˆê³ , ë¹„ìœ ë“¤ì´ ëª¨ë‘ ì‹¤ì œ <strong>ê°œë…ì„ ì™œê³¡ ì—†ì´ ì„¤ëª…</strong> í•˜ê³  ìˆë‹¤ëŠ” ëŠë‚Œì„ ë°›ì•˜ë‹¤. (ì‹¤ì œë¡œ ì´ìƒì™„ êµìˆ˜ë‹˜ì˜ ìˆ˜ì—…ì„ í•œ í•™ê¸° ë“¤ì—ˆì—ˆëŠ”ë° ìˆ˜ì—… ë„ì¤‘ ì´í•´ë„ë¥¼ ë§¤ë²ˆ ì„¤ë¬¸ì¡°ì‚¬ë¡œ í™•ì¸í•˜ê³  ìˆ˜ì—… í›„ ì§ˆë¬¸ì´ ëª‡ê°œë“  ì ì‹¬ì‹œê°„ì´ ì´ˆê³¼ë˜ë“  ìƒê´€ì—†ì´ ëª¨ë‘ ë“¤ì–´ì£¼ì…¨ë‹¤.) </p> <p>ì•„ë§ˆ ì²˜ìŒ ì ‘í•´ë³¸ ì‹ ê²½ê³¼í•™ í•™ë„ì—ê² êµ‰ì¥íˆ ì–´ë µì§€ ì•Šì•˜ì„ê¹Œ .. í•˜ëŠ” ìƒê°ì´ ë“ ë‹¤. ë³¸ë¬¸ì˜ 6ì¥ì„ ì œì™¸í•˜ê³ ëŠ” ëª¨ë‘ AI theory ì— ê´€ë ¨ëœ ë‚´ìš©ì´ ì£¼ë¥¼ ì´ë£¬ë‹¤. 1ì¥ê³¼ 2ì¥ì—ì„œëŠ” XOR problem ì„ ë¹„ë¡¯í•œ shallow network ì™€ estimator, regularization, overfitting ì— ëŒ€í•´ ì†Œê°œí•˜ê³  ìˆë‹¤. ì¢…ì´ì ‘ê¸°ë¼ëŠ” ë¹„ìœ ë¥¼ í†µí•´ networkì˜ layer ë¶€í„° ì­‰ì­‰ ì„¤ëª…í•´ì£¼ì—ˆê³ , SVM, kernel-SVM, dual problem ì— ëŒ€í•´ ê°„ë‹¨íˆ ì†Œê°œí•˜ê³  ìˆìœ¼ë©°, êµ¬ì¡°ì˜ ë‹¨ìˆœí•¨ê³¼ bias-variance tradeoff ë¥¼ ì–¸ê¸‰í•˜ì˜€ë‹¤. </p> <p>3ì¥ì—ì„  ë³¸ê²©ì ìœ¼ë¡œ deep learning model ì— ëŒ€í•´ ì„¤ëª…í•œë‹¤. ì¸ê³µì§€ëŠ¥ ëª¨ë¸ ê°œë…ì˜ ì¶”ìƒí™” ê³¼ì •ì—ì„œ í•„ì—°ì ìœ¼ë¡œ ë°œìƒí•˜ëŠ” specificity-invariance ë”œë ˆë§ˆì— ëŒ€í•´ ì†Œê°œí•˜ê³ , ì´ ë‘ë§ˆë¦¬ í† ë¼ë¥¼ ì•ˆì •ì ìœ¼ë¡œ block í™” í•˜ì—¬ ê¹Šê²Œ ìŒ“ì•„ì˜¬ë¦¬ëŠ” CNN ë°©ì‹ì— ëŒ€í•´ ì†Œê°œí•˜ê³  ìˆë‹¤. ë˜í•œ visual system ì—°êµ¬ê°€ AI architecture ì— ì˜í–¥ì„ ì¤€ ì—°êµ¬ì™€ AI ê°€ visual / auditory cortex í•´ì„ì— ì˜í–¥ì„ ì¤€ ì—°êµ¬ ì‚¬ë¡€ë„ ì†Œê°œë˜ê³  ìˆë‹¤. (í¥ë¯¸ë¡œì›€)</p> <p>4ì¥ì—ì„  ì±… í‘œì§€ì˜ <strong>&quot;ì§€ê·¹íˆ ì£¼ê´€ì ì¸ ê·¸ë˜ì„œ ë”ìš± ê°ê´€ì ì¸&quot;</strong> ë¬¸êµ¬ê°€ ë“±ì¥í•œë‹¤. ê°œì¸ì ìœ¼ë¡œ ì´ ì±…ì—ì„œ ê°€ì¥ ì–´ë µê³  ì¬ë°ŒëŠ” ë¶€ë¶„ì´ë¼ ìƒê°í•œë‹¤. ë°”ë¡œ generative model (ê°œë…ì˜ êµ¬ì²´í™”) ì¸ë°, hopfield model ê³¼ Boltzmann machine, restricted boltzmann machine, autoencoder, VAE, GAN ì— ëŒ€í•´ ì•„ì£¼ ìŠ¤ë¬´ìŠ¤í•˜ê²Œ ì¬ë°Œê²Œ ì„¤ëª…í•´ì£¼ê³  ìˆë‹¤. ì‚¬ì‹¤ ì´ ë¶€ë¶„ì€ ìˆ˜ì‹ì„ ë³´ë©´ ì³ë‹¤ë„ ë³´ê¸° ì‹«ì€ êµ¬ê°„ì¸ë°, êµ‰ì¥íˆ ì§ê´€ì ìœ¼ë¡œ ì²´ê³„ì ìœ¼ë¡œ ì„¤ëª…ì´ ë˜ì–´ìˆë‹¤ê³  ìƒê°í•œë‹¤. (í•„ìëŠ” Restricted boltzmann machine ì— ëŒ€í•´ ì—¬íƒœ ì˜ëª» ì•Œê³  ìˆì—ˆìŒì„,, ì±…ì„ ì½ìœ¼ë©° ê¹¨ë‹¬ì•˜ë‹¤.) </p> <p>3ì¥ê³¼ 4ì¥ì—ì„œ ê°œë…ì˜ ì¶”ìƒí™”ì™€ êµ¬ì²´í™”ì— ëŒ€í•´ ì„¤ëª…í•˜ì˜€ê³ , ë“œë””ì–´ 5ì¥ì—ì„œ ì‹œê°„ì¶•ì´ ë“±ì¥í•œë‹¤. ë”± ë“¤ì–´ë§ëŠ” ë¹„ìœ ì™€ í•¨ê»˜ ì‹œê°„ì¶•ì´ í•„ìš”í•œ ì´ìœ , ëª¨ë¸ì˜ êµ¬ì¡°ì— ëŒ€í•´ ì„¤ëª…í•˜ê³  ìˆë‹¤. LSTM ê´€ë ¨ ë‚´ìš©ë„ ë‚˜ì˜¤ëŠ”ë° ì±… ì½ë‹¤ê°€ ê´€ì‹¬ìˆëŠ” ì‚¬ëŒì€ êµ¬ì¡°ë¥¼ ì‹¤ì œë¡œ ê²€ìƒ‰í•´ ë³´ë©´ì„œ ì±…ì„ ë‹¤ì‹œ ì½ì–´ë³´ê¸¸ ë°”ë€ë‹¤! ë˜ transformerê³¼ self-attention ê°œë…ì— ëŒ€í•´ì„œë„ ê°„ëµíˆ ì†Œê°œí•˜ê³  ìˆë‹¤. </p> <p>í”„ë¡¤ë¡œê·¸ì—ì„œ êµìˆ˜ë‹˜ì€ <strong>&quot;ë‡Œì™€ ì¸ê³µì§€ëŠ¥ì˜ ì‘ë™ì›ë¦¬ëŠ” ê°™ì§€ ì•Šë‹¤.&quot;</strong> ë¼ê³  ì–˜ê¸°í•˜ë©° ì‹œì‘í•˜ëŠ”ë°, ê·¸ì™€ ê´€ë ¨ëœ ë‚´ìš©ì´ 6ì¥ì—ì„œ ì„¤ëª…ëœë‹¤. ì¸ê³µì§€ëŠ¥ì˜ í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” error backpropagation ì´ ë‡Œì—ì„œëŠ” ì‰½ì§€ì•Šì€ ë©”ì»¤ë‹ˆì¦˜ì„ì„ ì–¸ê¸‰í•˜ê³ , biological plausible model ì¦‰ ìƒë¬¼í•™ì ìœ¼ë¡œ ê°€ëŠ¥í•œ ëª¨ë¸ê³¼ ê´€ë ¨ëœ ì—°êµ¬ë¥¼ ì†Œê°œí•œë‹¤. êµ¬ì²´ì ìœ¼ë¡œ ê°€ì¥ ê¸°ì´ˆì ì¸ synaptic plasticity ë¶€í„° temporal error model ê³¼ predictive coding ì„ ê³ ìš” ì†ì˜ ì™¸ì¹¨ì´ë¼ëŠ” ê²Œì„ì— ë¹„ìœ í•´ì„œ ì„¤ëª…í•œë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ìµœê·¼ í™œë°œíˆ ì´ë£¨ì–´ì§€ê³  ìˆëŠ” global connectivity ì™€ ê´€ë ¨ëœ apical dendrite ê´€ë ¨ ì—°êµ¬ë¥¼ ì†Œê°œí•˜ë©° ì¥ì„ ë§ˆë¬´ë¦¬ í•œë‹¤. (ì´ ìª½ì´ ì¢€ ë” ìì„¸íˆ ì†Œê°œë˜ê¸¸ ë°”ëëŠ”ë° .. í•œ ì¥ìœ¼ë¡œë§Œ ì†Œê°œë˜ì–´ì„œ ì•„ì‰¬ì› ë‹¤ í‘)</p> <p>ë§ˆì§€ë§‰ìœ¼ë¡œ 7ì¥ì—ì„œëŠ” god ì´ìƒì™„ êµìˆ˜ë‹˜ì˜ ì—°êµ¬ì‹¤ì—ì„œ ìˆ˜í–‰ë˜ê³  ìˆëŠ” ì—°êµ¬ì™€ ê´€ë ¨ëœ ë‚´ìš©ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤. Reinforcement learning ê·¸ ì¤‘ì—ì„œë„ model-free, model-based RL ì— ëŒ€í•´ ê°„ë‹¨íˆ ì†Œê°œí•˜ê³ , ì‹¤ì œë¡œ ë‡Œì˜ íŠ¹ì • ì˜ì—­ì˜ í™œì„±ë„ê°€, RL setting ì—ì„œ reward, ë‘ module ì‚¬ì´ì˜ weight ë“±ì˜ componentì™€ correlation ì„ ë³´ì¸ë‹¤ëŠ” ì—°êµ¬ì— ëŒ€í•´ ì†Œê°œí•˜ê³  ìˆë‹¤! ê·¸ë¦¬ê³  ì±…ì€ ì—í•„ë¡œê·¸ì™€ í•¨ê»˜ ë§ˆë¬´ë¦¬ ëœë‹¤.</p> <h2 id="---2">--</h2> <p>ì‚¬ì‹¤ ì±…ì˜ ë‚´ìš©ì€ KAIST ì˜ Brain-Inspired Machine Intelligence ìˆ˜ì—…ì—ì„œ ìì„¸í•˜ê²Œ ë‹¤ë£¨ì–´ì§„ë‹¤. í•„ìëŠ” 2021ë…„ë„ ë´„í•™ê¸°ì— ì´ ê³¼ëª©ì„ ìˆ˜ê°•í–ˆê¸°ì— êµ‰ì¥íˆ ìµìˆ™í•˜ë©´ì„œë„ ë°˜ê°€ì› ë‹¤. (ì‘ë…„ì— í•„ê¸°í–ˆë˜ lecture note ë¥¼ íŒ¨ë“œë¡œ ë„ì›Œë†“ê³  ì±…ì„ ì½ì—ˆë‹¤.) ë‚˜ë§Œ ì•Œê³  ì‹¶ì—ˆë˜ ëª…ê°•ì˜ ì˜€ëŠ”ë° ì„¸ìƒì— ë‚˜ì™€ì„œ ì„œìš´ ë°˜ ê¸°ì¨ ë°˜ ì´ë„ê¹Œ... <img src="https://velog.velcdn.com/images/jaeheon-lee/post/b62abb5f-3f55-4118-bf64-58e2445de1a6/image.png" alt=""></p> <p>ì´ìƒì™„ êµìˆ˜ë‹˜ ë©ì—ì„œ ê°œë³„ì—°êµ¬ í•  ë•Œ ê¸°ì–µë„ ìƒˆë¡ìƒˆë¡ ë‚˜ê³ , êµìˆ˜ë‹˜ì„ ë¹„ë¡¯í•´ì„œ ì—°êµ¬ì‹¤ ì„ ë°°ë‹˜ë“¤ê»˜ ì—¬ëŸ¬ê°€ì§€ë¡œ ì¢‹ì€ ì˜í–¥ê³¼ ë„ì›€ì„ ë°›ì•„ì„œ ì§€ê¸ˆì€ ì–´ë–»ê²Œ ì§€ë‚´ì‹œë‚˜.. ì—°ë½ì„ ë¨¼ì € í•´ë³¼ê¹Œ í•˜ëŠ” ê·¸ëŸ° ìƒê°ë„ ë“ ë‹¤. ì•„! ì´ìƒì™„ êµìˆ˜ë‹˜ ë© í™ˆí˜ì´ì§€ëŠ” aibrain.kaist.ac.kr ì´ë‹¤. (ë§ê´€ë¶€) </p> <p>ì•„ë¬´ìª¼ë¡ ì¹´í˜ ë§ˆê°ì‹œê°„ì´ ë‹¤ ë˜ì–´ì„œ ê¸€ì€ ì—¬ê¸°ê¹Œì§€ ë§ˆë¬´ë¦¬ í•˜ë ¤ í•œë‹¤. ì±…ì„ ì§€ì›í•´ì£¼ì‹  ì†”ì¶œíŒì‚¬ ì™€ BCSC, ê·¸ë¦¬ê³  í•­ìƒ ì¡´ê²½í•˜ëŠ” ì´ìƒì™„ êµìˆ˜ë‹˜ê»˜ ê°ì‚¬ì¸ì‚¬ë¥¼ ì „í•©ë‹ˆë‹¤! </p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; September 24, 2022 &nbsp; &middot; &nbsp; jaeheon-lee </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-Self-supervised-contrastive-learning-for-digital-histopathology" target="_blank">[Paper Review] Self supervised contrastive learning for digital histopathology</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="self-supervised-contrastive-learning-for-digital-histopathology">Self supervised contrastive learning for digital histopathology</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/3cf4dabc-cf49-4e48-b398-11df9e7309e0/image.png" alt=""></p> <h2 id="introduction">Introduction</h2> <p>SSL methodì˜ ë‹¤ì–‘í•œ hyperparameterë¥¼ ë°”ê¾¸ê³  histopathologyì— ì ìš©í•˜ì—¬ ì‹¤í—˜ì„ ì§„í–‰í•œ ë…¼ë¬¸ì´ë‹¤. SimCLR ì„ ì‚¬ìš©í–ˆìœ¼ë©° downstream task - classification, segmetnation, regression - ì„ í†µí•´ pretrain domain, pretrain image ê°œìˆ˜, downstream ì‹œ labeled image ë¹„ìœ¨, optimizer, resolution, augmentation (íŠ¹íˆ color jittering ë° random resize crop), pretrain backbone architecture ë“± ë‹¤ì–‘í•œ ì‹¤í—˜ ì¡°ê±´ì„ ì ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ ë¦¬í¬íŠ¸ í•˜ì˜€ë‹¤. </p> <h2 id="method">Method</h2> <p>SimCLR ì—ì„œ NT-Xent loss ë¥¼ ì–¸ê¸‰í•˜ê³  ìˆë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/e2ab0e7c-ba60-411c-9672-7256bd5b1e6a/image.png" alt=""></p> <p>ë˜í•œ, contrastive method ëŠ” image patch ê°„ì˜ slient feature ë¥¼ í•™ìŠµí•˜ê¸°ì—, pretraining ì‹œ samples ì´ ê°™ì€ datasetìœ¼ë¡œë¶€í„° construct ë˜ëŠ” ê²ƒ ë³´ë‹¤ ë‹¤ì–‘í•œ dataset ìœ¼ë¡œë¶€í„° ì¶”ì¶œë˜ëŠ” ê²ƒì´ ë” ì¢‹ì€ representation ì„ í•™ìŠµí•  ìˆ˜ ìˆì„ ê²ƒì´ë¼ ì„¤ëª…í•œë‹¤. (ê·¸ë¦¬ê³  ì´ë¥¼ ì¦ëª…í•œë‹¤.)</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/ffa4f669-741e-4b19-ba37-6d19b5fd589c/image.png" alt=""></p> <h2 id="experiments">Experiments</h2> <h3 id="pretraining-datasets">Pretraining datasets</h3> <p>ê¸¸ê²Œ ì„¤ëª…ë˜ì–´ ìˆì§€ë§Œ, supplement ì˜ table í•˜ë‚˜ë¡œ ì„¤ëª…ëœë‹¤. ì´ 57ê°œì˜ dataset ì¤‘ 22ê°œëŠ” image patch ë¡œë§Œ ì´ë£¨ì–´ì§„ dataset ì´ê³ , ë‚˜ë¨¸ì§€ëŠ” TCGA, CPTACì™€ ì—¬ëŸ¬ challenge ì—ì„œ ì‚¬ìš©ëœ WSI ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. 20x ë¶€í„° 100x ê¹Œì§€ 23ê°œ ì¥ê¸°ì— ëŒ€í•œ ë‹¤ì–‘í•œ patch ì™€ slide ê°€ ì¡´ì¬í•œë‹¤. (ì´ ê°œìˆ˜ëŠ” ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ìŒ. í•˜ì§€ë§Œ ì„¸ì–´ë³´ë©´ ëŒ€ëµ patch 4ë§Œì¥ + WSI 1ë§Œì¥ ì •ë„)</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/ef4813fc-e3f2-494b-8a17-06150faba7b4/image.png" alt=""></p> <h3 id="validation-datasets">Validation datasets</h3> <p>pretrain í›„ ë‹¤ì„¯ ê°œì˜ dataset ìœ¼ë¡œ classification, ë‘ ê°œì˜ dataset ìœ¼ë¡œ segmentation, í•˜ë‚˜ë¡œ regression task ë¥¼ ì§„í–‰í•˜ì˜€ë‹¤. classification - BACH (4, breast), Lymph (3, lymph), BreakHisv1 (2, breast), NCT-CRC-HE-100K (9, colorectal), Gleason2019 (5, prostate) segmentation - BACH (4, breast), DigestPath2019 (2, colon) regression - BreastPathQ (percentage cancer cellularity score to a given image patch, breast)</p> <h3 id="validation-tasks--setup">Validation tasks &amp; setup</h3> <p>COMPARE with 1) randomly initialized 2) ImageNet pretrained / in Resnet 18, 34, 50, 101 training settings: 1) fine-tuning, 2) last layer ì œì™¸ freeze(seg ì œì™¸) supervised learning ++ pretrained feature ë¥¼ ì´ìš©í•œ clustering, feature selection ,,,</p> <p>100 epochs per experiment, Adam optimizer, batch size 128 training 50%, validation 25%, test 25%</p> <h2 id="results">Results</h2> <p>ë”°ë¡œ ëª¨ë¸ ì•„í‚¤í…ì³ê°€ ì“°ì—¬ìˆì§€ ì•Šìœ¼ë©´ Resnet18ë¡œ í•™ìŠµëœ ê²°ê³¼ì´ë‹¤. 50ë§Œì¥ì˜ 224 x 224 pixel image patch ë¥¼ 1000 epoch í•™ìŠµ ì‹œí‚¤ëŠ”ë° 24ì‹œê°„ ê±¸ë¦°ë‹¤.</p> <h3 id="fine-tuning">fine-tuning</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/66ff35e5-3999-44cc-8b70-cb6c50d382bd/image.png" alt=""></p> <p>ì „ë°˜ì ìœ¼ë¡œ Self sup. setting ì—ì„œ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ë‹¤. ë‹¤ë§Œ Resnet 50, 101 segmentation ìƒí™©ì—ì„œëŠ” Imagenet pretrain ì„±ëŠ¥ì´ ë†’ì•˜ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/36e464f0-5513-4efd-8907-dba22519a692/image.png" alt=""></p> <p>ë˜í•œ supervised learning setting ì—ì„œ labeled data ê°€ &quot;ì ì„ ë•Œ&quot; SSL ì„±ëŠ¥ì´ ë‹¤ë¥¸ ë°©ë²• (random=from scratch, Imagenet pretrained) ì— ë¹„í•´ í¬ê²Œ ë†’ì•˜ë‹¤. ì €ìëŠ” NCT ë¥¼ ì˜ˆë¡œ ë“¤ë©° ì„¤ëª…í•˜ì˜€ë‹¤.</p> <h3 id="freeze">freeze</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/efb720cf-d015-4dc6-b3ea-63bf775b9f26/image.png" alt=""></p> <p>ìœ„ í…Œì´ë¸”ì˜ ëª¨ë“  task, condition ì—ì„œ SSL ë°©ì‹ì„ ì‚¬ìš©í–ˆì„ ë•Œ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì•˜ë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/89b9cb32-76ac-4b42-b145-b110e2ddc31c/image.png" alt=""></p> <p>segmentation ì˜ ê²½ìš° ë”°ë¡œ freeze experiment ê²°ê³¼ë¥¼ ë¦¬í¬íŠ¸ í•˜ì§€ëŠ” ì•Šì•˜ë‹¤. (since a decoder can contain millions of parameters that can be trained to achieve satisfactory performance regardless of the encoder weights.)</p> <h3 id="unsupervised-clustering-using-the-learned-representations">unsupervised clustering using the learned representations</h3> <p>learned representation can also be used for querying an image to its nearest neighbors without clustering the dataset, which is useful in applications such as active learning for sample selection and various data retrieval systems. </p> <p>randomly sampling patch ë°©ì‹ì€ class imbalance ë¬¸ì œë¥¼ ì•¼ê¸°í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— representative patches ë¥¼ ë½‘ê¸° ìœ„í•´ clustering ì¢‹ë‹¤. íŠ¹íˆ ì €ìëŠ” 69 WSI ë¡œë¶€í„° 1.4 million image patch ë¥¼ ë½‘ê³ , 3000ê°œì˜ clusterë¡œ ë°ì´í„°ë¥¼ ë‚˜ëˆ„ì—ˆë‹¤. (Elbow heuristic ë°©ì‹ì„ ì´ìš©í•´ 1000, 1500,,, 10000 ì¤‘ 3000 ì„ íƒ) ê·¸ ë°©ì‹ìœ¼ë¡œ mini-batch K-means algorithm ì„ ì‚¬ìš©í•˜ì˜€ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/680810fb-80ea-4dce-b07f-d6e9bffe1c44/image.png" alt=""></p> <p>figure 6 ì—ì„œ, ì•½ê°„ì˜ cluster ë¥¼ ë½‘ì•„ highlight í–ˆë”ë‹ˆ any supervision ì—†ì´ segmentation ë„ ì–´ëŠì •ë„ ë˜ì—ˆë‹¤ê³  ì£¼ì¥í•œë‹¤.</p> <h3 id="pretrain-ì‹œ-image-patch-ê°œìˆ˜ì™€-resolution-ë°”ê¿”ì„œ-ì‹¤í—˜">pretrain ì‹œ image patch ê°œìˆ˜ì™€ resolution ë°”ê¿”ì„œ ì‹¤í—˜</h3> <p>1) 0.01, 0.1, 1, 10% ì˜ image ë§Œì„ ì‚¬ìš©í•´ pretrain 2) IDCGrade (breast, 10x, 20x, 40x, 922 patches ??) ë¡œ pretrain <img src="https://velog.velcdn.com/images/jaeheon-lee/post/abacabe5-5699-4a94-a226-af36ae7a4f2a/image.png" alt=""></p> <p>ë” ë§ì€ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ pretrain í•  ìˆ˜ë¡ ì„±ëŠ¥ì´ ì¢‹ì•˜ê³ , ë” ë†’ì€ resolution dataë¡œ í•™ìŠµí–ˆì„ ë•Œ ì„±ëŠ¥ì´ ë” ì¢‹ì•˜ë‹¤. ë¬¼ë¡  ë‹¤ì–‘í•œ resolutionì„ ì´ìš©í•´ í•™ìŠµí–ˆì„ ë•Œê°€ ì„±ëŠ¥ì´ ì œì¼ ì¢‹ì•˜ë‹¤.</p> <h3 id="transferability-of-features-between-tissue-types-and-staining">transferability of features between tissue types and staining</h3> <p>breast, lymph node, prostate ëª¨ë‘ 4000ê°œ ì •ë„ì”© ì‚¬ìš©. breast: TCGA-PRAD, TUPAC16, TNBC, ICPR,,, / lymph nodes: Camelyon 16, 17 / prostate: Prostate-MRI</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/135888d1-0701-4ad7-8f98-0a51c91423e0/image.png" alt=""></p> <p>site-specific pretraining ì—ë„ ë¶ˆêµ¬í•˜ê³ , pretrained model ê³¼ validation performance ì‚¬ì´ì˜ strong correlation ì€ ê´€ì°°ë˜ì§€ ì•Šì•˜ë‹¤. ë˜í•œ, ê°€ì¥ ì²«ë²ˆì§¸ table ì˜ ê²°ê³¼ (77, 6.6, 74) ì™€ ë¹„êµí–ˆì„ ë•Œ, íŠ¹ì • domain ì— ëŒ€í•´ ì‹¤í—˜í•œ ê²°ê³¼ë³´ë‹¤ ì„±ëŠ¥ì´ ë–¨ì–´ì¡Œë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/5048daa8-83c0-4a47-b575-1ac01ca8c1b3/image.png" alt=""></p> <h2 id="hyperparameter-and-suitable-augmentation-selection">hyperparameter and suitable augmentation selection</h2> <p>(ì—¬ê¸°ë¶€í„´ supplment ì— ë‚˜ì™€ìˆëŠ” ë‚´ìš©ìœ¼ë¡œ, ìœ„ result ì— ê³µí†µì ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” setting ì´ë‹¤.)</p> <h3 id="optimizer-and-temperature">optimizer and temperature</h3> <p>pretraining ê³¼ì •ì—ì„œ Adam + batch size&gt;256 ì„¸íŒ…ìœ¼ë¡œ í–ˆì„ ë•Œ converge í•˜ì§€ ì•Šì•˜ê³ , Lars ê°€ Lamb ë³´ë‹¤ ì„±ëŠ¥ì´ ì¡°ê¸ˆ ë” ë†’ê²Œ ë‚˜ì™”ìœ¼ë©°, smaller temperature ì—ì„œ í•™ìŠµì´ ì „ë°˜ì ìœ¼ë¡œ ë” ì˜ ë‚˜ì˜¤ëŠ” ê²ƒì„ í™•ì¸í•˜ì˜€ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/d11cc487-a703-47d1-b9ca-abf8b32751d2/image.png" alt=""></p> <h3 id="augmentation">augmentation</h3> <p>ì‚¬ìš©í•œ augmentation ê¸°ë²•ì€, randomly resized crops, 90 rotation, flips, color jittering, Gaussian blurring ì„ ì‚¬ìš©í•˜ì…¨ê³ , ê·¸ ì¤‘ íŠ¹íˆ color jittering ê³¼ random resize crop ì¡°ê±´ì„ ë‹¬ë¦¬í•˜ì—¬ ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ë‹¤. color jittering ì¡°ê±´ light, medium, heavy ëŠ” ê°ê° (brightness, contrast, saturation, hue) ê¸°ì¤€ (0.4 0.4 0.4 0.2) (0.8 0.8 0.8 0.2) (0.8 0.8 0.8 0.4) ì„ ì˜ë¯¸í•œë‹¤. randomly resize crop ì˜ í¼ì„¼íŠ¸ëŠ” ê·¸ë§Œí¼ì˜ patch sizeë¡œ crop í–ˆë‹¤ëŠ” ëœ»ì´ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/3898d657-dcca-4518-8931-640932356253/image.png" alt=""></p> <p>ê²°ê³¼ ë” ê°•í•œ augmentation ì´ ì ìš©ë  ìˆ˜ë¡ ì„±ëŠ¥ë„ ë†’ì•„ì¡Œë‹¤. ì‹¬ì§€ì–´ 1% random resize crop ì€ 224 x 224 pixel ê¸°ì¤€ 20 x 20 pixel ë§Œ ê°€ì ¸ì˜¨ ê²ƒì„ì—ë„ ë¶ˆêµ¬í•˜ê³ , ë‹¤ë¥¸ random resize crop ë¹„ìœ¨ ì‹¤í—˜ë³´ë‹¤ ì„±ëŠ¥ì´ ë” ë†’ì•˜ë‹¤...</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/0e98cda9-a171-4ff4-a703-1b70487a52de/image.png" alt=""></p> <h2 id="conclusion">Conclusion</h2> <p>ë°©ëŒ€í•œ ì–‘ì˜ ë°ì´í„°ì…‹ê³¼ ì—¬ëŸ¬ ì¡°ê±´ì„ ë°”ê¿” SSL ë¡œ ì‹¤í—˜í•œ ë…¸ë ¥ì´ ëŒ€ë‹¨í•œ .. ë…¼ë¬¸ì´ì—ˆë‹¤. ë…¼ë¬¸ì—ì„  no prior research on histopathological image analysis with a ... consistently reaches or surpasses supervised training. ì´ë¼ê³  í•˜ëŠ” ê±¸ ë³´ë©´.. ì •ë§ ë°©ëŒ€í•œ ì–‘ì„ ì¼ê¸´ í–ˆë‚˜ë³´ë‹¤. ëŠ” ìƒê°ì´ ë“ ë‹¤. SSL ë°©ì‹ì„ ì‚¬ìš©í•  ë•Œ ì–´ë–¤ setting ì„ ì‚¬ìš©í• ì§€ ê³ ë¯¼í•˜ë‹¤ê°€ ì°¾ì€ ë…¼ë¬¸ì¸ë° ëŒ€ì‹  ì—¬ëŸ¬ ì‹¤í—˜ì„ ì§„í–‰í•´ì¤˜ì„œ ì°¸ê³ í•  ë•Œ ì¢‹ì„ ê²ƒ ê°™ì•„ ê³ ë§ˆìš´ ìƒê°ë„ ë“¤ì—ˆë‹¤. ì•”íŠ¼ êµ¿. </p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; September 13, 2022 &nbsp; &middot; &nbsp; jaeheon-lee </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-Pan-cancer-integrative-histology-genomic-analysis-via-multimodal-deep-learning" target="_blank">[Paper Review] Pan-cancer integrative histology-genomic analysis via multimodal deep learning</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="pan-cancer-integrative-histology-genomic-analysis-via-multimodal-deep-learning">Pan-cancer integrative histology-genomic analysis via multimodal deep learning</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/6d4be227-bbe9-404f-8232-628ec7089a26/image.png" alt=""></p> <p>CLAM ìœ¼ë¡œ ìµìˆ™í•œ í•˜ë²„ë“œì˜ mahmood lab ì˜ ì—°êµ¬ê°€ ì–¼ë§ˆ ì „ì— ê³µê°œë˜ì—ˆë‹¤. TCGA dataì˜ 14ê°œ ì•”ì¢…ì— ëŒ€í•´, diagnostic tissue image ì™€ molecular profile data ë¥¼ ìœµí•©í•˜ì—¬ feature ë¥¼ ë§Œë“¤ì–´ë‚´ì—ˆê³  ì´ë¥¼ survival analysis ì— í™œìš©í•˜ì˜€ë‹¤. c-index ë“±ì˜ ranking performance ë¿ë§Œ ì•„ë‹ˆë¼ interpretability ë©´ì—ì„œë„ í›Œë¥­í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆë‹¤. </p> <h2 id="introduction">Introduction</h2> <ul> <li>recent DL-based approachesëŠ” survival label ê³¼ ê°™ì€ outcome-based label ì„ í™œìš©í•˜ì—¬ objective and prognostic molecular feature ë¥¼ ì°¾ê³ ì í•¨.</li> <li>joint image-omic biomarker ex) oligodendroglioma and astrocytoma histolgoies with IDH1 mutation and 1p/19q-co-deletion status ëŠ” ì •êµí•œ patient stratification ê°€ëŠ¥ì¼€ í•¨.</li> <li>multimodal fusion ì€ improve precision &amp; assist discover biomarker</li> </ul> <h2 id="method">Method</h2> <ul> <li>joint image-omic biomarker ë¥¼ ë°œêµ´í•˜ê¸° ìœ„í•´, MMF (multimodal fusion) algorithm ì„ ì œì•ˆí•¨.</li> <li>MMF: H&amp;E WSI, molecular profile feature (mutation status, copy-number variation, RNA seq)</li> <li>survival outcome prediction ì„ ìˆ˜í–‰í•¨ê³¼ ë™ì‹œì—, how histopathology/molecular features + their interaction ì´ low-, high-risk patient ì™€ correlation ì„ ì´ë£¨ëŠ”ì§€ ë¶„ì„ ìˆ˜í–‰.</li> <li>1) attention-based 2) attribution-based method ë¥¼ í†µí•´ explainability í™•ë³´.</li> </ul> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/1573d8a9-89c2-48bd-9527-484062096662/image.png" alt=""></p> <p>1) attention-based Multiple Instance Learning for processing WSI 2) Self-Normalizing Networks (SNN) for processing molecular profile data 3) multimodal fusion layer for tegrating WSIs and molecular profile data</p> <h3 id="dataset-description--wsi-preprocessing">dataset description &amp; WSI preprocessing</h3> <p>TCGA project ì˜ 14ê°œ ì•”ì¢…, 5720ëª… í™˜ìì˜ ë°ì´í„° public CLAM ì˜ repository ë¥¼ í™œìš©í•˜ì—¬ automated tissue segmentation ì§„í–‰ image patch size 256 x 256, ResNet50 pretrained by ImageNet -&gt; 1024 dimensional feature vector</p> <h3 id="amil">AMIL</h3> <p>ë”°ë¡œ clustering ê¸°ë²• ë“±ì„ ì‚¬ìš©í•˜ì§€ ì•Šì€, AMILë¥¼ ì²˜ìŒ ì œì•ˆí•œ ë…¼ë¬¸ì˜ ë°©ë²•ì„ ì¸ìš©í•˜ê³  ì‚¬ìš©í•¨. WSI processing í›„ WSI bag ì€ $M_i \times C$ , (patch ê°œìˆ˜ X 1024) ë¡œ í‘œí˜„ë¨. í™˜ì ìˆ˜ë¥¼ N ì´ë¼ í–ˆì„ ë•Œ attention pooling ì˜ ëŒ€ìƒì´ ë˜ëŠ” matrix ëŠ” $M_i \times C \times N$ ì´ê³ , ì´ë¥¼ ë‹¤ìŒ ì‹ì„ í†µí•´ $512 \times N$ ë¡œ ë³€í™˜. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/d544d939-37fb-4a97-aca3-2221fb32c190/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/daa362fd-3f67-4f7d-8b1a-2807820d4a76/image.png" alt=""></p> <p>ìì„¸í•œ ì„¤ëª…ì€ ìƒëµí•˜ì§€ë§Œ, ì§ê´€ì ìœ¼ë¡œ ì„¤ëª…í•˜ë©´, WSI ì˜ patch ì—¬ëŸ¬ ê°œì˜ feature vector ë“¤ì„, feature vector ì˜ ê´€ê³„ì™€ ì¤‘ìš”ë„ë¥¼ íŒë‹¨í•˜ëŠ” í•™ìŠµ ê°€ëŠ¥í•œ network ë¥¼ í†µí•´, í•˜ë‚˜ì˜ feature vector ë¡œ aggregate í•´ì£¼ëŠ” ê³„ì‚°ì„. ì´ë ‡ê²Œ ìƒì„±ëœ vector ëŠ” $W_{pred} \in R^{4 \times 512}$ ì™€ sigmoid activation ì„ ê±°ì³, negative-log-likelihood function for discrete time survival modling ì— í™œìš©ëœë‹¤. ë˜í•œ last fully-connected layer ëŠ” WSI representation $h_{WSI} \in h^{32 \times 1}$ ì„ ìœ„í•´ ì‚¬ìš©ë˜ê³  ì´ëŠ” multimodal fusion layer ì— í™œìš©ëœë‹¤.</p> <h3 id="snn">SNN</h3> <p>FCN ì˜ variation ì¤‘ í•˜ë‚˜ë¡œ, high-dimensional low-sample size (HDLSS) sscenenarios ë¥¼ ë°°ìš°ê¸° ìœ„í•œ architecture ì¤‘ í•˜ë‚˜ì´ë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ëª¨ë¥´ì§€ë§Œ HDLSS property ë¥¼ ë„ëŠ” molecular data ë¥¼ $h_{molecular} \in h^{32 \times 1}$ ë¡œ encoding í•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœë‹¤. ì´ëŠ” multimodal fusion layer ì— í™œìš©ëœë‹¤.</p> <h3 id="multimodal-fusion-layer">Multimodal fusion layer</h3> <p>ë‘ representation $h_{WSI}$, $h_{molecular}$ ì˜ ëª¨ë“  bimodal interaction ì„ ì¡ì•„ë‚´ê¸° ìœ„í•´, Kronecker Product ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ differentiable fusion tensor $h_{fusion} \in h^{33 \times 33}$ ì„ ê³„ì‚°í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/98012ffb-492d-495c-9435-83af729e9bf2/image.png" alt=""></p> <p>ì´ ë•Œ, unimodal feature ë„ ì¡ì•„ë‚´ê³  ì„œë¡œ ë‹¤ë¥¸ modalityì˜ feature collinearty ë¥¼ ì¤„ì´ê¸° ìœ„í•´ bias ì²˜ëŸ¼ 1 ì„ concat í•´ì¤€ ë’¤ Kronecker Product ë¥¼ ê³„ì‚°í•˜ì˜€ë‹¤. ë˜í•œ ì´ì™€ ë”ë¶ˆì–´, gating-based attentnion mechanism ì„ ì¶”ê°€ì ìœ¼ë¡œ ì ìš©í•˜ì—¬, ê° modality ì˜ expressiveness ë¥¼ control í•˜ê³ ì í•˜ì˜€ë‹¤. (iëŠ” ê° modality)</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/fa5249b1-413b-4e09-881a-9b5111a5322a/image.png" alt=""></p> <p>ê° modality representation vector ì— ëŒ€í•´ gated mechanism ì„ ë¨¼ì € ì ìš©í•œ í›„ fusion matrix ë¥¼ ê³„ì‚°í•˜ì˜€ë‹¤. ì´í›„ size 256ì˜ ë‘ ê°œì˜ hidden layer ë¥¼ ê±°ì³¤ê³ , survival analysis ë¥¼ ìœ„í•œ cross entropy ì²˜ëŸ¼ ìƒê¸´ loss function ì„ ê³„ì‚°í•˜ì—¬ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸ í•˜ì˜€ë‹¤. </p> <h2 id="results">Results</h2> <h3 id="model-performances-of-porpoise-and-understanding-impact-of-multimodal-training">model performances of PORPOISE and understanding impact of multimodal training</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/2a3a675c-c8ce-43f8-bd92-340c7b1e6032/image.png" alt=""></p> <p>ë¶„ì„ ëŒ€ìƒì´ì—ˆë˜ ëª¨ë“  ì•”ì¢…ì— ëŒ€í•œ ì„±ëŠ¥ ì •ë³´ë¥¼ í•œ ëˆˆì— ë³¼ ìˆ˜ ìˆëŠ” figure ì´ë‹¤. KM curve ë¥¼ ë´¤ì„ ë•Œ, 14ê°œ ì¤‘ 4ê°œ (HNSC, LIHC, LUSC, STAD) ë¥¼ ì œì™¸í•˜ê³  11ê°œì— ëŒ€í•´ significance ë¥¼ ì–»ì—ˆë‹¤. c-index ì˜ ê²½ìš° 14ê°œ ì¤‘ 2ê°œ (LIHC, UCEC) ë¥¼ ì œì™¸í•˜ê³  12ê°œì— ëŒ€í•´ SNN, AMIL ì¦‰ unimodality ì •ë³´ë§Œ ì‚¬ìš©í•œ ê²ƒ ë³´ë‹¤ MMF ì˜ c-index ê°€ ë” ë›°ì–´ë‚¬ë‹¤. fusion layer ì— ë“¤ì–´ê°€ê¸° ì „ ê° modality feature ì— ëŒ€í•´ gate layer ë¥¼ í†µí•´ ê° modality ì˜ attribution ì„ ê³„ì‚°í•˜ì—¬ ë‚˜íƒ€ë‚¸ ê²°ê³¼, ëŒ€ë¶€ë¶„ì˜ ì•”ì¢…ì— ëŒ€í•´ molecular feature ì˜ ì§€ë¶„ì´ ì••ë„ì ìœ¼ë¡œ ì»¸ì§€ë§Œ, ê·¸ ì¤‘ LIHC, STAD, UCEC ëŠ” WSI attribution ì´ ë†’ê²Œ ë‚˜íƒ€ë‚¬ë‹¤. </p> <h3 id="quantitative-performance-local-model-explanation-and-global-interpretability-analyses-of-porpoise-on--cancer">Quantitative performance, local model explanation, and global interpretability analyses of PORPOISE on ... cancer</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/a5b07c9e-5f71-4eda-9d05-0c9f29335035/image.png" alt=""></p> <p>ìœ„ì™€ ê°™ì€ ë¶„ì„ ìë£Œê°€ supplementary data ë¥¼ í¬í•¨í•˜ì—¬ 14ê°œ ì•”ì¢… ëª¨ë‘ì— ëŒ€í•´ ì£¼ì–´ì¡Œë‹¤. Whole Slide Image ë¥¼ patch í™” í•˜ê³  AMIL ì˜ attention score ë¥¼ ì´ìš©í•˜ì—¬ global í•œ heatmap ê³¼ ROI heatmap ë¥¼ A ì— ë‚˜íƒ€ë‚´ì—ˆë‹¤. B, D ëŠ” SHAP ì„ ì´ìš©í•œ feature attribution visualization ê²°ê³¼ì´ë‹¤. ê° ëª¨ë¸ì—ì„œ ì–´ë–¤ feature ê°€ ì˜ì‚¬ ê²°ì •ì— ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ë¯¸ì³¤ëŠ”ì§€ë¥¼ ì•Œë ¤ì¤€ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ B ëŠ” local interpretability, ì¦‰ individual sample ì˜ ê° feature ê°€ ì–¼ë§ˆë‚˜, ì–´ë–»ê²Œ model risk prediction ì— ì˜í–¥ì„ ë¯¸ì³¤ëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ëŠ”ë°, x axis ëŠ” attribution value ë¡œ ì–¼ë§ˆë‚˜ ì— í•´ë‹¹í•˜ê³  y axis ëŠ” attribution ì„ sorting í•œ ê²ƒì´ë‹¤. continuous colormap ì€ í•´ë‹¹ gene ì´ mutation (1) ì¼ ë•Œ ì˜í–¥ì„ ì£¼ëŠ”ì§€ wildtype (0) ì¼ ë•Œ ì˜í–¥ì„ ì£¼ëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œì´ë‹¤. D ëŠ” global interpretability, ì¦‰ í•´ë‹¹ cancer cohort ì „ë°˜ì— ëŒ€í•´ ì–´ë–¤ feature ê°€ ì˜ì‚¬ê²°ì •ì— ì–¼ë§ˆë‚˜ ì–´ë–»ê²Œ ì˜í–¥ì„ ë¯¸ì³¤ëŠ”ì§€ë¥¼ ë³´ì—¬ì¤€ë‹¤. ìì„¸í•œ ë‚´ìš©ì€ SNN ìª½ì´ë¼ ì¼ë‹¨ì€ ë‚¨ê²¨ë‘ë„ë¡ í•˜ì. CëŠ” unimodality ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œì™€ fusionì„ ì‚¬ìš©í–ˆì„ ë•Œ ê°ê° score ë¥¼ êµ¬í•œ ë’¤ KM curve ë¥¼ ë‚˜íƒ€ë‚¸ ê²°ê³¼ì´ë‹¤. ì „ë°˜ì ìœ¼ë¡œ unimodality ë§Œì„ ì‚¬ìš©í–ˆì„ ë•Œ ë³´ë‹¤ multimodality ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ ë‘ group ì´ ë” ì˜ ë‚˜ë‰˜ê³  logrank test ê²°ê³¼ p valueë„ ë” signifcant í•˜ê²Œ ê³„ì‚°ë˜ì—ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ E ëŠ” attention score ê°€ ë†’ì€ ìƒìœ„ 1% patch (ì•½ 135ê°œ ì •ë„) ë§Œì„ ì¶”ì¶œí•˜ì—¬, HoverNet ì„ ì´ìš©í•´ cell segmentation ì„ ìˆ˜í–‰í•œ ê²°ê³¼ì´ë‹¤. ì´ ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ì—¬ cell quantification ê¹Œì§€ ìˆ˜í–‰í•˜ì˜€ê³ , íŠ¹íˆ ëŒ€ë¶€ë¶„ì˜ ì•”ì¢…ì— ëŒ€í•´ TIL (tumor infiltrating lymphocyte) ê´€ë ¨í•œ ìœ ì˜ë¯¸í•œ ê²°ê³¼ë¥¼ ì–»ì—ˆë‹¤. </p> <p>ë‹¤ìŒë¶€í„°ëŠ” ë…¼ë¬¸ì—ì„œ ì–¸ê¸‰í•œ ì¤‘ìš” ê²°ê³¼ì˜ ìš”ì•½ì´ë‹¤.</p> <ul> <li>12/14 cancer type ì—ì„œ MMF ëŠ” highest c-index ë‹¬ì„±</li> <li>7/14 cancer type ì—ì„œ MMF ëŠ” AMIL ë³´ë‹¤ stratification significance ë¥¼ ë” í™•ë³´í•¨.</li> <li>Kronecker product ë¥¼ ì´ìš©í•œ fusion ì„ ì‚¬ìš©í–ˆì„ ë•Œ c-index ê°€ ì œì¼ ì˜ ë‚˜ì˜´.</li> </ul> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/05f92928-6d4e-45e0-b257-ecac66cb9a64/image.png" alt=""></p> <ul> <li>8/14 cancer type ì—ì„œ low/high risk group ê°„ lymphocyte cell fraction ì˜ significant difference ë¥¼ ë³´ì„.</li> <li>6/14 cancer type ì—ì„œ low/high risk group ê°„ tumor cell fraction ì˜ significant difference ë¥¼ ë³´ì„.</li> <li>LGG cohort ì—ì„œ IHD1 mutation ì´ ì•„ì£¼ ì¤‘ìš”í•œ prognostic factor ë¡œ ê³„ì‚°ë˜ì—ˆê³ , ì´ëŠ” ê¸°ì¡´ ì—°êµ¬ë“¤ê³¼ consistent í•¨.</li> <li>PAAD cohort ì—ì„œ ì „ë°˜ì ìœ¼ë¡œ innate immunity ì™€ inflammatory cell signaling ì— ê´€ì—¬í•˜ëŠ” gene ì´ ì¤‘ìš”í•˜ë‹¤ ê³„ì‚°ë¨. </li> <li>tumor-infiltrating lymphocyte (TIL) presence ê°€ 9/14 cancer type ì—ì„œ significant difference ë¥¼ ë³´ì„.</li> </ul> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/367e5fb8-e6e7-4460-9cf7-ba6706b1013c/image.png" alt=""></p> <p>ì´ë•Œ, TIL presence ëŠ” highest-attended patch ì—ì„œ high tumor-immune cell co-localization ì—¬ë¶€ (ì €ìì˜ heuristic) ë¥¼ ì´ìš©í•´ íŒë‹¨í•˜ì˜€ë‹¤. 20ê°œì˜ cell ì´ ìˆê³ , 10ê°œ ì´ìƒì˜ lymphocyte ê°€ ì¡´ì¬í•˜ê³ , 5ê°œ ì´ìƒì˜ tumor cell ì´ ì¡´ì¬í•  ë•Œ TIL ì´ ì¡´ì¬í•œë‹¤ ë¼ê³  ì •ì˜í•˜ì˜€ë‹¤. ì €ìëŠ” í•œê³„ì ì— TIL presence ì™€ statistical significance ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ post hoc analyses ê°€ í•„ìš”í•˜ë‹¤ ë¼ê³  ë§ë¶™ì˜€ë‹¤. </p> <h2 id="discussion">Discussion</h2> <p>PAAD ì˜ ê²½ìš°, AMIL ì´ prognostic í•˜ì§€ ì•Šë‹¤ ê³„ì‚°ë˜ì—ˆê³  SNN ë³´ë‹¤ë„ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šì•˜ì§€ë§Œ, multimodal integration ì„ í†µí•´ ì„±ëŠ¥ì´ í–¥ìƒë¨ê³¼ ë™ì‹œì—, WSIì˜ attribution score ë¹„êµì  ë†’ì•˜ë‹¤. ê·¸ ë°˜ëŒ€ë¡œ BRCA, COADREAD, LUAD ì˜ ê²½ìš°, uni-modality ì¼ ë•Œë³´ë‹¤ multimodal integration ì„ í†µí•´ ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆê³  WSI ëŒ€ì‹  molecular feature ì˜ attribution score ê°€ ë†’ì•˜ë‹¤. ì•ì„  ê²°ê³¼ë“¤ì„ í¬í•¨í•œ ë…¼ë¬¸ì˜ ì „ë°˜ì˜ ì„¤ëª…ì„ ì¦ê±°ë¡œ, computational support system for therapeutic decision-making ì„ í†µí•´ í–¥í›„ genotype-phenotype correlation-based analyses ëŠ” shared + modality-specific í•œ prognostic information ì„ ì°¾ê³  single/joint biomarker ë¥¼ ë°œêµ´í•˜ëŠ”ë°ì— í° ë„ì›€ì´ ë  ê²ƒì´ë¼ ì£¼ì¥í•œë‹¤.</p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; August 22, 2022 &nbsp; &middot; &nbsp; jaeheon-lee </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-Bias-in-Cross-Entropy-Based-Training-of-Deep-Survival-Networks" target="_blank">[Paper Review] Bias in Cross-Entropy-Based Training of Deep Survival Networks</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="bias-in-cross-entropy-based-training-of-deep-survival-networks">Bias in Cross-Entropy-Based Training of Deep Survival Networks</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/de674758-6443-4193-a779-2b134e71d8fb/image.png" alt=""></p> <p>Deep survival networks ì—ì„œëŠ” í¬ê²Œ ë‘ ë¶„ë¥˜ì˜ loss function ì„ ì‚¬ìš©í•˜ì—¬ íƒ€ê²Ÿ ë„¤íŠ¸ì›Œí¬ë¥¼ optimize í•œë‹¤. ì²«ë²ˆì§¸ë¡œëŠ” proportional hazard model ë¡œë¶€í„° ìœ ë„ëœ DeepSurv ì—ì„œ ìµœì´ˆë¡œ ì‚¬ìš©í•œ negative log likelihood ê³„ì—´ loss ê°€ ìˆê³ , ë‘ë²ˆì§¸ëŠ” event time ì„ discretize í•˜ì—¬ fixed boundary ë¥¼ ì´ìš©í•œ classification ê³„ì—´ loss ê°€ ìˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” survival analysis ì—ì„œ ê¸°ì¡´ ì‚¬ìš©ë˜ë˜ cross-entropy loss ì— íŠ¹ì • bias ê°€ ë¼ì—¬ìˆìŒì„ ì´ë¡ , ì‹¤í—˜ì ìœ¼ë¡œ ì¦ëª…í•˜ê³  ì´ë¥¼ ì™„í™”í•œ ìƒˆë¡œìš´ loss ë¥¼ ì œì•ˆí•˜ê³  ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•œë‹¤. </p> <h2 id="introduction">Introduction</h2> <p>Discrete hazard function ê³¼ discrete survival function ì— ëŒ€í•´ ë¨¼ì € ì„¤ëª…í•˜ê³  ìˆë‹¤. ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ëœë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/5ad27610-8e18-47dd-8d0b-378f788c4442/image.png" alt=""></p> <p>ì—¬ê¸°ì„œ ì„¤ëª…ì„ ë†“ì¹˜ë©´ ì•ìœ¼ë¡œë„ ê³„ì† ì´í•´ê°€ ì•ˆê°ˆí…Œë‹ˆ ê¼¼ê¼¼í•˜ê²Œ ì§šê³  ë„˜ì–´ê°€ëŠ” ê²ƒì´ ì¢‹ë‹¤. T ëŠ” í™˜ìë“¤ì˜ event time ì„ categorical value ë¡œ ë§Œë“¤ì–´ ë†“ì€ discrete time variable ì´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ t_1 ì„ 0 ë¶€í„° 100ì¼ ì´ëŸ°ì‹ìœ¼ë¡œ ì¡ì„ ìˆ˜ ìˆëŠ” ê²ƒì´ë‹¤. X ëŠ” í™˜ìì˜ time, event ì •ë³´ ì´ì™¸ì˜ age, stage ë“± í™˜ìì˜ survival ì„ ì¶”ì •í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” variables ì´ë‹¤. h(t|X) ëŠ” í•´ë‹¹ í™˜ìê°€ (ì¡°ê±´ë¶€) X ë¼ëŠ” variable ì„ ê°€ì§€ê³  ìˆê³  t ë¼ëŠ” ì‹œê°„ëŒ€ê¹Œì§€ ì‚´ì•„ë‚¨ì•˜ì„ ë•Œ, t ë¼ëŠ” ì‹œê°„ëŒ€ì— ì£½ì„ (event ê°€ ì¼ì–´ë‚ ) í™•ë¥  ì´ë‹¤. ì´ ë•Œ, 1-h(t|X) ëŠ” ê·¸ ì—¬ì§‘í•©ìœ¼ë¡œ, ë™ì¼ ì¡°ê±´ì—ì„œ t ë¼ëŠ” ì‹œê°„ëŒ€ì— ì£½ì§€ ì•Šì„ í™•ë¥ ë¡œ í•´ì„í•  ìˆ˜ ìˆë‹¤. S(t|X) ëŠ” t ë¼ëŠ” ì‹œê°„ëŒ€ì— ì£½ì§€ ì•Šì•˜ì„ í™•ë¥  ì´ë‹¤. ì¦‰ ì´ë¥¼ ë‹¤ì‹œ í‘œí˜„í•˜ë©´, ì²«ë²ˆì§¸ ì‹œê°„ëŒ€ë¶€í„° t-1 ì‹œê°„ëŒ€, t ì‹œê°„ëŒ€ì— ì£½ì§€ ì•Šì„ í™•ë¥ ì˜ joint probability ë¡œ ë³¼ ìˆ˜ ìˆë‹¤. ê²°êµ­ deep survival network ë¥¼ í†µí•´ ìœ„ í™˜ìë§ˆë‹¤ ê³„ì‚°ëœ output layer ì˜ real-valued output ë¡œë¶€í„° hazard function h(t|X) ì˜¤ë¥¸ìª½ ì‚¼ì§€ì°½ (0,1] ë¥¼ ì¶”ì •í•˜ëŠ” ê²ƒì´ ëª©ì ì´ë‹¤. </p> <p>ê·¸ë ‡ë‹¤ë©´ ê¸°ì¡´ ì‚¬ìš©ë˜ë˜ cross-entropy loss ëŠ” ì–´ë–¤ í˜•íƒœë¥¼ ë„ê³  ìˆì„ì§€ê°€ ê¶ê¸ˆí•´ì§„ë‹¤. survival analysis ëŠ” right-censored data ì´ê¸° ë•Œë¬¸ì—, censored data ì™€ uncensored data ê°€ ë‹¤ë¥´ê²Œ ê³„ì‚°ë˜ì–´ loss function ì— ë“¤ì–´ê°€ì•¼ í•  ê²ƒì´ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/1ba9b810-8614-4ad5-85e6-350b1e81041a/image.png" alt=""></p> <p>(xi, ti) ëŠ” í™˜ì í•œ ëª…ì˜ ì •ë³´ì´ë‹¤. ci ëŠ” censored ë˜ì—ˆëŠ”ì§€ ì¦‰ event ê°€ ì¼ì–´ë‚¬ëŠ”ì§€ë¥¼ ì˜ë¯¸í•œë‹¤. censored data, event ê°€ ì¼ì–´ë‚˜ì§€ ì•Šì€ patient ëŠ” ci = 1 ë¡œ í‘œê¸°ë˜ê¸° ë•Œë¬¸ì—, ci ê°€ ì•ì— ë¶™ì€ í•­ì€ event ê°€ ì¼ì–´ë‚˜ì§€ ì•Šì€ patient ì— ëŒ€í•´ì„œë§Œ ê³„ì‚°ë˜ëŠ” í•­ì´ë‹¤. ë°˜ëŒ€ë¡œ (1-ci) ê°€ ì•ì— ë¶™ì€ í•­ì€ event ê°€ ì¼ì–´ë‚œ patient ì— ëŒ€í•´ì„œë§Œ ê³„ì‚°ë˜ëŠ” í•­ì´ë‹¤. ìœ„ ì‹ì˜ ci ê°€ ë¶™ì€ í•­ S(ti|xi) ëŠ”, &quot;event ê°€ ì¼ì–´ë‚˜ì§€ ì•Šì€ patient ê°€, ti ì— ì•ˆ ì£½ì–´ ìˆì„ í™•ë¥ &quot; ì´ë‹¤. ê·¸ë¦¬ê³  (1-ci) ê°€ ì•ì— ë¶™ì€ í•­ (1-S(ti|xi)) ì€ &quot;event ê°€ ì¼ì–´ë‚œ patient ê°€, (ì–¸ì œ ì£½ì—ˆëŠ”ì§€ëŠ” ëª¨ë¥´ì§€ë§Œ) ti ì— ì£½ì–´ìˆì„ í™•ë¥ &quot; ì´ë‹¤. ë…¼ë¬¸ì˜ ì €ìëŠ” ì´ (ì–¸ì œ ì£½ì—ˆëŠ”ì§€ëŠ” ëª¨ë¥´ì§€ë§Œ) ë•Œë¬¸ì— bias ê°€ ë‚€ë‹¤ ì„¤ëª…í•œë‹¤. ê·¸ í™˜ìëŠ” t_i ì‹œê°„ëŒ€ì— ë”± ì£½ì€ í™˜ìì¸ë°, loss ì—ëŠ” ì–¸ì œ ì£½ì—ˆë“  t_i ì— ì‚´ì•„ìˆê¸°ë§Œ í•˜ë©´ ê³„ì‚°ì´ ë˜ì§€ ì•Šë„ë¡ ì„¤ê³„ë˜ì–´ ìˆê¸° ë•Œë¬¸ì´ë‹¤.</p> <h2 id="theoretical-analysis-of-the-cross-entropy-loss">Theoretical Analysis of the Cross-Entropy loss</h2> <h3 id="comparison-of-the-cross-entrop-loss-and-the-negative-log-likelihood-loss">Comparison of the Cross-Entrop loss and the Negative Log-Likelihood loss</h3> <p>ì €ìëŠ” ë‹¤ë¥¸ ë…¼ë¬¸ì˜ discrete survival model ì—ì„œ ì‚¬ìš©ëœ log-likelihood function ì„ ë²¤ì¹˜ë§ˆí‚¹í•˜ì—¬ loss ë¥¼ ì„¤ê³„í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/21e806c9-e321-4831-83b0-396efc9f7aae/image.png" alt=""></p> <p>(1-ci) event ê°€ ì¼ì–´ë‚œ í™˜ìê°€ ti ë¼ëŠ” ì‹œê°„ëŒ€ì— ë”± ì‚¬ë§í•  í™•ë¥  + ci event ê°€ ì¼ì–´ë‚˜ì§€ ì•Šì€ í™˜ìê°€ ti ë¼ëŠ” ì‹œê°„ëŒ€ì— ìƒì¡´í•´ ìˆì„ í™•ë¥  ì´ë‹¤. ì´ë¥¼ ì´ë¦¬ì €ë¦¬ ì˜ ë°”ê¾¸ê³  negative log likelihood ê¼´ë¡œ ë§Œë“¤ì–´ ë‹¤ìŒê³¼ ê°™ì€ loss ë¡œ ë³€í˜•í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/d1d722a0-319b-476d-a728-c37cdde5aa4c/image.png" alt=""></p> <p>ci event ê°€ ì¼ì–´ë‚˜ì§€ ì•Šì€ í™˜ìê°€ ti ì‹œê°„ëŒ€ì— ìƒì¡´í•´ ìˆì„ í™•ë¥  + (1-ci) event ê°€ ì¼ì–´ë‚œ í™˜ìê°€ ti-1 ì‹œê°„ëŒ€ê¹Œì§€ ê³„ì† ìƒì¡´í•´ ìˆì„ í™•ë¥  + (1-ci) event ê°€ ì¼ì–´ë‚œ í™˜ìê°€ ti ì‹œê°„ëŒ€ì— ë”± ì‚¬ë§í•  í™•ë¥  ë¡œ í•´ì„í•  ìˆ˜ ìˆë‹¤. </p> <p>ê¸°ì¡´ ì‚¬ìš©ë˜ë˜ cross-entropy loss ì™€ ìƒˆë¡­ê²Œ ê³ ì•ˆí•œ negative log-likelihood loss ì˜ ì°¨ë¥¼ ê³„ì‚°í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/708c462d-19cd-4eed-9981-324b09013baf/image.png" alt=""></p> <p>í¬ê²Œ ë´¤ì„ ë•Œ ë‘ loss ì˜ ì°¨ì´ëŠ” (1-ci), event ê°€ ì¼ì–´ë‚œ í™˜ìë“¤ì— ì˜í•´ ì¼ì–´ë‚œë‹¤. ë§Œì•½ ëª¨ë‘ censored ë˜ì–´ ëª¨ë“  í™˜ìì˜ ci=0 ì´ë¼ë©´ ë‘ loss ëŠ” ê°™ì„ ê²ƒì´ë‹¤. ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ë³´ë©´, (1-S(ti|xi) ê°€ S(ti-1|xi) * h(ti|xi) ì— ê°€ê¹Œì›Œ ì§ˆìˆ˜ë¡ ë‘ loss ì˜ ì°¨ì´ëŠ” ì¤„ì–´ë“ ë‹¤. ì´ ë‘ ì‹ì„ í•´ì„í•˜ê¸° í¸í•˜ê²Œ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/e0297e90-4f4f-4238-b324-f880e1c09a7b/image.png" alt=""></p> <p>ì²«ë²ˆì§¸ëŠ” ti ì— ì´ë¯¸ í™˜ìê°€ ì£½ì–´ìˆì„ í™•ë¥ ì„, ti ì— ì£½ì„ í™•ë¥ ê³¼ ti ì´ì „ì— ì£½ì„ í™•ë¥ ë¡œ ë‚˜ëˆˆ ê²ƒì´ë‹¤. ê·¸ ì•„ë˜ì˜ hazard function ì€ ì¡°ê±´ë¶€ë¥¼ ë¶„ëª¨ë¡œ ë³´ë‚¸ ê²ƒì´ë‹¤. ë‘ ì°¨ì´ëŠ” P(T &lt; ti|xi) ë¡œ ì •ë¦¬ë˜ê³ , ì´ ì‹ì´ 0ìœ¼ë¡œ ê°€ë©´ ë‘ loss ì˜ ì°¨ì´ê°€ 0 ìœ¼ë¡œ ê°„ë‹¤. ê²°êµ­ event ê°€ ì¼ì–´ë‚œ í™˜ìì— ëŒ€í•´, ëª¨ë“  ti ì— ëŒ€í•´, P(T &gt;= ti | xi) = 1 ì¼ìˆ˜ë¡ ì°¨ì´ê°€ ì¤„ì–´ë“ ë‹¤ëŠ” ëœ»ì´ê³ , ì´ë¥¼ ë‹¤ì‹œ í•´ì„í•˜ë©´, &quot;large event times for all instances&quot; ë¥¼ ëœ»í•œë‹¤. í•˜ì§€ë§Œ large event times ë¥¼ ê°€ì§„ í™˜ìëŠ” (ë³´í†µ ì˜¤ë˜ ì¶”ì í•˜ê¸° ì–´ë ¤ìš°ë¯€ë¡œ) ëŒ€ê²Œ censoring rate ê°€ ë†’ì•„ censoring rate ê°€ ë‚®ìœ¼ë©´ ì–´ì©” ìˆ˜ ì—†ì´ ë°œìƒí•˜ëŠ” ì˜¤ì°¨ë¼ê³  ì„¤ëª…í•œë‹¤. </p> <h3 id="bias-in-cross-entropy-based-hazard-estimates">Bias in Cross-Entropy-Based Hazard Estimates</h3> <p>cross-entropy loss ë¡œë¶€í„° ë°œìƒí•˜ëŠ” biasë¥¼ ì„¤ëª…í•˜ê¸° ìœ„í•´, constant hazard function h(t|X)=h for all t ë¥¼ ì¡ê³  simulation í•œë‹¤. ë˜í•œ censoring rate ë¥¼ 0 ë¶€í„° 1ê¹Œì§€ ë‹¤ë¥´ê²Œ í•˜ì—¬, ì–´ë–»ê²Œ ì¶”ì •ì¹˜ê°€ ë‹¬ë¼ì§€ëŠ”ì§€ë¥¼ plot í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/8c3c665e-ff96-4cc2-8b71-94054388a5ff/image.png" alt=""></p> <p>ê²°ê³¼, ê³„ì‚°ëŒ€ë¡œ censoring rate ê°€ ë‚®ì„ìˆ˜ë¡ (event ê°€ ì¼ì–´ë‚œ í™˜ìê°€ ë§ì„ìˆ˜ë¡) cross-entropy ì™€ negative log-likelihood ì‚¬ì´ í° ì°¨ì´ê°€ ì¡´ì¬í–ˆê³ , censoring rate ê°€ 1 ì— ê°€ê¹Œì›Œ ì§ˆìˆ˜ë¡ ê·¸ ì°¨ì´ëŠ” ì¤„ì–´ë“¤ì–´ ê°”ë‹¤. ë˜, cross-entropy loss ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ hazard rateì˜ overestimation ê³¼ survival function ì˜ underestimation ì„ ê´€ì°°í•˜ì˜€ë‹¤. </p> <h2 id="empirical-evidence">Empirical Evidence</h2> <p>ì´ë¡ ì ìœ¼ë¡œ difference ë° bias ê°€ ì¡´ì¬í•¨ì„ ë³´ì´ê³ , ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” deep survival network (DRSA network, DeepHit network) ì—ì„œ ì‚¬ìš©ë˜ëŠ” cross entropy loss ë¥¼ ê³ ì•ˆí•œ negative log-likelihood loss ë¡œ ëŒ€ì²´í•˜ì—¬ ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ë‹¤. c-indexì™€ calibration ì •ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” GND test, survival functionê³¼ KM curve ì˜ ë¹„êµë¥¼ í†µí•´ performance ë¥¼ ë¹„êµí•˜ì˜€ë‹¤. ë˜í•œ ë‹¤ìŒê³¼ ê°™ì€ regularization term ì•ì— alpha ë¥¼ ê³±í•´ ë‘ loss ì— ì¶”ê°€í•˜ì—¬ ì„±ëŠ¥ì„ ë¹„êµí•˜ì˜€ë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/a17ae725-be14-4b12-b0cb-e70684d9dc8c/image.png" alt=""></p> <p>ì´ alpha ê°€ ì»¤ì§ˆ ìˆ˜ë¡, uncensored data ì— ë” weightë¥¼ í¬ê²Œ í•œ loss ê°€ ê³„ì‚°ë˜ì–´ networkì— update ëœë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/3a42fa80-981e-459a-a560-e2600a5eaac1/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/ada1e397-bda1-461e-b0aa-31efed1d0726/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/42c32c66-a93a-49be-b67d-d7a4ce76ca59/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/92f8b340-2a9b-42c6-bede-15ee284f19ca/image.png" alt=""></p> <p>ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ì—ˆê³ , alpha ëŠ” ì „ë°˜ì ìœ¼ë¡œ ì¢‹ì€ ê²°ê³¼ë¥¼ ë‚´ì—ˆì§€ë§Œ íŠ¹íˆ unbalance ëœ ë°ì´í„° ì¼ ë•Œ ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì—ˆë‹¤. GND test ê²°ê³¼ëŠ” í¬ë©´ í´ìˆ˜ë¡ ëœ calibration ëœ, ì¦‰ bias ê°€ ê»´ìˆìŒì„ ë‚˜íƒ€ë‚´ëŠ”ë°, ìƒˆë¡­ê²Œ ê³ ì•ˆëœ loss ì™€ alpha ë¥¼ ì ìš©í–ˆì„ ë•Œ calibration ì´ í›¨ì”¬ ì˜ ë¨ì„ ë³´ì—¬ì¤€ë‹¤. ë˜í•œ ranking performance ë˜í•œ ì „ë°˜ì ìœ¼ë¡œ ê°œì„ ë˜ì—ˆë‹¤. </p> <h2 id="conclusion">Conclusion</h2> <p>ë³¸ ë…¼ë¬¸ì—ì„œ ì§„í–‰í•œ theortical / empirical analysis ê²°ê³¼ë¥¼ í†µí•´, cross-entropy-based training of deep survival network ëŠ” large prediction error ê³¼ í•¨ê»˜ bias ë¥¼ ì´ˆë˜í•¨ì„ ì¦ëª…í•˜ì˜€ë‹¤. ì´ì™€ ë°˜ëŒ€ë¡œ ìƒˆë¡­ê²Œ ê³ ì•ˆí•œ loss ë¥¼ ì ìš©í–ˆì„ ë•Œ better calibrated prediction rule ì„ ë³´ì˜€ê³ , predicted survival probabilities ì—ì„œ smaller bias ì™€ í•¨ê»˜ reduce prediction error í•¨ì„ ë³´ì˜€ë‹¤. </p> <p>cf) êµ¬í˜„ë„ ë§¤ìš° ê°„ë‹¨í–ˆë‹¤..! --&gt; ce_l ã„±ã„± <img src="https://velog.velcdn.com/images/jaeheon-lee/post/13e786ac-abf3-45fd-aaa0-2fea2156e821/image.png" alt=""></p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; August 15, 2022 &nbsp; &middot; &nbsp; jaeheon-lee </p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p></li> </ul> <nav aria-label="Blog page naviation"> <ul class="pagination pagination-lg justify-content-center"> <li class="page-item "> <a class="page-link" href="/blog/page/4/" tabindex="-1" aria-disabled="4">Newer</a> </li><li class="page-item "><a class="page-link" href="/blog/page/4/index.html" title="blog - page 4">4</a></li> <li class="page-item active"><a class="page-link" href="/blog/page/5/index.html" title="blog - page 5">5</a></li> <li class="page-item "><a class="page-link" href="/blog/page/6/index.html" title="blog - page 6">6</a></li> <li class="page-item "><a class="page-link" href="/blog/page/7/index.html" title="blog - page 7">7</a></li> <li class="page-item "><a class="page-link" href="/blog/page/8/index.html" title="blog - page 8">8</a></li> <li class="page-item "> <a class="page-link" href="/blog/page/6/">Older</a> </li> </ul> </nav> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> &copy; Copyright 2023 JaeHeon Lee. Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>