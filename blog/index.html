<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> blog | JaeHeon Lee</title> <meta name="author" content="JaeHeon Lee"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ğŸ§ </text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://jaeheon-lee486.github.io/blog/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">JaeHeon&nbsp;</span>Lee</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <div class="header-bar"> <h1>al-folio</h1> <h2>a simple whitespace theme for academics</h2> </div> <div class="tag-category-list"> <ul class="p-0 m-0"> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/formatting">formatting</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/images">images</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/links">links</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/math">math</a> </li> <p>&bull;</p> <li> <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/code">code</a> </li> <p>&bull;</p> <li> <i class="fas fa-tag fa-sm"></i> <a href="/blog/category/blockquotes">blockquotes</a> </li> </ul> </div> <br> <div class="container featured-posts"> <div class="row row-cols-2"> <div class="card-item col"> <a href="/blog/2021/distill/"> <div class="card hoverable"> <div class="row g-0"> <div class="col-md-12"> <div class="card-body"> <div class="float-right"> <i class="fa-solid fa-thumbtack fa-xs"></i> </div> <h3 class="card-title text-lowercase">a distill-style blog post</h3> <p class="card-text">an example of a distill-style blog post and main elements</p> <p class="post-meta"> 8 min read &nbsp; &middot; &nbsp; <a href="/blog/2021"> <i class="fas fa-calendar fa-sm"></i> 2021 </a> </p> </div> </div> </div> </div> </a> </div> <div class="card-item col"> <a href="/blog/2015/code/"> <div class="card hoverable"> <div class="row g-0"> <div class="col-md-12"> <div class="card-body"> <div class="float-right"> <i class="fa-solid fa-thumbtack fa-xs"></i> </div> <h3 class="card-title text-lowercase">a post with code</h3> <p class="card-text">an example of a blog post with some code</p> <p class="post-meta"> 4 min read &nbsp; &middot; &nbsp; <a href="/blog/2015"> <i class="fas fa-calendar fa-sm"></i> 2015 </a> </p> </div> </div> </div> </div> </a> </div> </div> </div> <hr> <ul class="post-list"> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-Rethinking-Multiple-Instance-Learning-for-Whole-Slide-Image-Classification-A-Good-Instance-Classifier-is-All-You-Need" target="_blank">[Paper Review] Rethinking Multiple Instance Learning for Whole Slide Image Classification: A Good Instance Classifier is All You Need</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="rethinking-multiple-instance-learning-for-whole-slide-image-classification-a-good-instance-classifier-is-all-you-need">Rethinking Multiple Instance Learning for Whole Slide Image Classification: A Good Instance Classifier is All You Need</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/71dca4c3-a330-454a-9817-ba46f85c154e/image.png" alt=""></p> <p>contrastive learning ê³¼ prototype learning, joint training strategy ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ MIL ì˜ ë¬¸ì œì ì„ ì™„í™”í•œ ì—°êµ¬ê°€ ê³µê°œë˜ì—ˆë‹¤. ìµœê·¼ì—ëŠ” attention pooling ì„ í™œìš©í•œ aggregation ê¸°ë²•ë“¤ì´ ë§ì´ ì‚¬ìš©ë˜ì—ˆëŠ”ë°, attention score ê°€ êµ‰ì¥íˆ ì¼ë¶€ instanceì— ëŒ€í•´ì„œë§Œ ë†’ì•„ gradientê°€ ì œí•œì ìœ¼ë¡œ íë¥´ê¸° ë•Œë¬¸ì— ì¢€ ë” ê´œì°®ì€ instance classifier ë¥¼ ë§Œë“¤ì–´ mean pooling í•˜ëŠ” ì „ëµì„ ì‚¬ìš©í•˜ì˜€ë‹¤.</p> <h2 id="introduction">Introduction</h2> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/825c4554-e20c-4879-bb6c-00e0871c4184/image.png" alt=""></p> <p>1) Low performance in instance-level classificaion : only the most easily identifiable positive instances are found while other more difficult ones are missed : instance pseudo labels contain a lot of noise 2) Bag-level classification performance is not robust : A typical example is the bias that occurs in classifying bags with a large number of difficult positive instances while very few easy positive instances</p> <p>The main contributions of this paper are as follows:</p> <ul> <li>We propose INS, an instance-based MIL framework that combines contrastive learning and prototype learning. This framework serves as an efficient instance classifier, capable of effectively addressing instance-level and bag-level classifi- cation tasks at the finest-grained instance level.</li> <li>We propose instance-level weakly supervised contrastive learning (IWSCL) for the first time in the MIL setting to learn good feature representations for each instance. We also propose the Prototype-based Pseudo Label Generation (PPLG) strategy, which generates high-quality pseudo labels for each instance through prototype learning. We further propose a joint training strategy for IWSCL, PPLG, and the instance classifier. </li> <li>We comprehensively evaluated the performance of INS on six tasks of four datasets. Extensive experiments and visualization results demonstrate that INS achieves the best performance of instance and bag classification.</li> </ul> <h2 id="related-work">Related work</h2> <h3 id="instance-based-mil-methods">Instance-based MIL Methods</h3> <ul> <li>ì£¼ë¡œ ê° instance ì— pseudo label ì„ ë¶™ì´ê³  instance classifier ë¥¼ í•™ìŠµí•˜ê³ , bag ë‚´ë¶€ì˜ ëª¨ë“  instance prediction ì„ aggregateí•˜ì—¬ bag classification ì„ ìˆ˜í–‰í•œë‹¤.</li> <li>í•˜ì§€ë§Œ positive bag ì˜ ìƒë‹¹ ìˆ˜ì˜ negative instance ê°€ positive label ê´€ë ¨ noise ë¥¼ ë°›ê²Œ ëœë‹¤.</li> </ul> <h3 id="bag-based-mil-methods">Bag-based MIL Methods</h3> <ul> <li>instance feature ë¥¼ ì¶”ì¶œí•˜ê³  aggregate í•˜ì—¬ bag feature ë¡œ bag classification ì„ ìˆ˜í–‰í•œë‹¤. íŠ¹íˆ attention-based method ê°€ main stream ì´ê³ , ë…ë¦½ëœ scoring network ì˜ learnable attention weight ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° instance feature ì ìˆ˜ë¥¼ ë§¤ê¸´ë‹¤.</li> <li>í•˜ì§€ë§Œ ì‰¬ìš´ instance ì—ëŠ” attention score ê°€ ì˜ ë°˜ì˜ë˜ëŠ”ë°, difficult instance ì—ëŠ” ê·¸ë ‡ì§€ ì•Šë‹¤.</li> </ul> <h3 id="prototype-learning-for-wsi-classification">Prototype Learning for WSI classification</h3> <ul> <li>derived from Nearest Mean Classifier, concise representation for instance</li> <li>(ë‚´ê²ŒëŠ”) ì¹œìˆ™í•˜ì§€ ì•Šì€ ê°œë…ì´ë¼ ë ˆí¼ëœ ë…¼ë¬¸ì„ ì¢€ ì‚´í´ë´¤ë‹¤.</li> </ul> <p>TPMIL (TPMIL: Trainable Prototype Enhanced Multiple Instance Learning for Whole Slide Image Classification)</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/bb8bd6ee-72ef-4433-8078-fa4abc6b9b70/image.png" alt=""></p> <p>create learnable prototype vectors í›„, attention score ë¡œë¶€í„° ì–»ì€ soft pseudo label ê³¼ KL divergence ë¥¼ ê³„ì‚°í•˜ì—¬ update í•˜ëŠ” í”„ë ˆì„ì›Œí¬ ì´ë‹¤.</p> <ul> <li>í•˜ì§€ë§Œ attention score ëŠ” challenging positive instance ë¥¼ ì‹ë³„í•˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œì ì´ ìˆë‹¤.</li> <li>ì´ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´, PPLG (prototype-based pseudo label generation) strategy ë¥¼ ì·¨í•´, high-quality pseudo-label ì„ ìƒì„±í•˜ê³ , instance contrastive representation learning, prototype learning, instance classifier ê°„ì˜ joint training ì„ ìˆ˜í–‰í•œë‹¤.</li> <li>íŠ¹íˆ negative bags ì—ì„œ sampling í•œ instance ëŠ” true negative instance ì¸ ì ì„ í™œìš©í•˜ì—¬ instance classifier ë¡œë¶€í„° prototype learing ì— ê°€ì´ë“œë¥¼ ì¤€ë‹¤.</li> </ul> <h2 id="methods">Methods</h2> <h3 id="problem-formulation">Problem Formulation</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/6b3c8fb4-948f-4dc7-bbd5-6c2aa0e3a222/image.png" alt=""></p> <p>binary setting ì´ë‹¤. ì´ setting ì—ì„œëŠ” negative bags ì˜ ëª¨ë“  instance ëŠ” negative instance ì´ë‹¤. </p> <h3 id="framework-overview">Framework Overview</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/40981dd0-3afe-437a-a583-5f596987d2b3/image.png" alt=""></p> <p>bag ìœ¼ë¡œë¶€í„° instance $x_{i,j}$ ë¥¼ sampling í•˜ê³  query view ì™€ key view ë¥¼ two augmentation ìœ¼ë¡œë¶€í„° ì–»ëŠ”ë‹¤. query view branch ì—ì„œ encoder ë¥¼ ê±°ì¹œ feature ë¥¼ instane classifier ì™€ projector (MLP-based) ì— ë„£ê³ , ê°ê°ìœ¼ë¡œë¶€í„° predicted class ${\hat{y}<em>{i,j} \in R^2}$, feature embedding ${q</em>{i,j}\in R^d}$ ë¥¼ ì–»ëŠ”ë‹¤. key view branch ì—ëŠ” gradient ê°€ íë¥´ì§€ ì•ŠëŠ” ëŒ€ì‹ , query branch ë¡œë¶€í„° momentum update ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ì´ ì—…ë°ì´íŠ¸ ëœë‹¤. ê·¸ë¦¼ì²˜ëŸ¼ encoder ì™€ projector ë¥¼ ê±°ì³ ${k_{i,j}}$ ë¥¼ ì–»ëŠ”ë‹¤. ì—¬ê¸°ì„œ ì¡°ê¸ˆ ë³µì¡í•œë°, ìœ„ query branch ë¡œë¶€í„° ì–»ì—ˆë˜ predicted class ${\hat{y}<em>{i,j} \in R^2}$ ì™€ í•¨ê»˜ ë„£ì–´ì£¼ëŠ” ê²ƒì´ í¬ì¸íŠ¸ì´ë‹¤. ì´ë¥¼ embedding queue ì— enqueue í•œ í›„, ë‚´ë¶€ì—ì„œ contrastive learning loss ë¥¼ ê³„ì‚°í•œë‹¤. ì´ ë¶€ë¶„ì€ ì•„ë˜ ë‹¤ë¥¸ ì„¹ì…˜ì—ì„œ ë” ì„¤ëª…í•˜ë„ë¡ í•˜ê² ë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ë‹¤ì‹œ query branch ë¡œë¶€í„° ë‚˜ì˜¨ ${\hat{y}</em>{i,j} \in R^2}$ ì™€, prototype vectorì™€ loss ë¥¼ ê³„ì‚°í•œë‹¤. PPLG module ë‚´ì—ì„œëŠ” two representative feature vector ë¥¼ positive, negative class training ê³¼ì •ì—ì„œ ê³„ì†í•´ì„œ ì—…ë°ì´íŠ¸ í•œë‹¤. ì´ ë˜í•œ ì•„ë˜ ì„¹ì…˜ì—ì„œ ë” ì„¤ëª…í•˜ë„ë¡ í•˜ê² ë‹¤.</p> <h3 id="instance-level-weakly-supervised-contrastive-learning">Instance-level Weakly Supervised Contrastive Learning</h3> <p>ëª©ì : ì¢‹ì€ feature representation ì„ ì–»ëŠ” ê²ƒ.</p> <p>ë…¼ë¬¸ì—ì„œë„ ì–¸ê¸‰í•˜ì§€ë§Œ, ì‚¬ì‹¤ contrastive learning ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€, ì‹ì´ ì–´ë–»ê³ ë¥¼ ë– ë‚˜ì„œ ì–´ë–»ê²Œ negative, positive sample set ì„ construction í•˜ëŠëƒê°€ í•µì‹¬ì´ë‹¤. ê¸°ì¡´ self-supervised learning setting ì—ì„œëŠ” ë³¸ì¸ê³¼ ë³¸ì¸ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ë¡œ ë³´í†µ ì…‹ì„ êµ¬ì„±í–ˆì§€ë§Œ, MIL setting ì—ì„œëŠ” negative bag in the training set ìœ¼ë¡œë¶€í„° ë½‘ì€ all instance ëŠ” true negative label ì„ ê°–ê³  ê°™ì€ ì…‹ì— ì†í•˜ë„ë¡ í•  ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ íŠ¸ë¦­ì„ ë‹¤ë¥¸ ì–´ëŠ ë…¼ë¬¸ì—ì„œë„ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ë‹¤ê³  í•œë‹¤. ì´ weak label ì •ë³´ëŠ” instance-level contrastive learning ì„ íš¨ìœ¨ì ìœ¼ë¡œ guideí•  ìˆ˜ ìˆì—ˆë‹¤ê³  í•œë‹¤. </p> <p>íŠ¹íˆ large Embedding Queue ì—ì„œ feature embedding $k_{i,j}$ ì™€ ê·¸ê²ƒë“¤ì˜ class $\hat{y}_{i,j}$ ë¥¼ í•¨ê»˜ ì €ì¥í–ˆê³ , ì´ ë•Œ, true negative instance ê°™ì€ ê²½ìš°ì—ëŠ”, predicted class ë¥¼ ì €ì¥í•˜ì§€ ì•Šê³ , ë°”ë¡œ directly assign them a definite negative class ë¡œ í•˜ì˜€ë‹¤. ì´ ë¶€ë¶„ì„ ê³„ì† ê°•ì¡°í•˜ëŠ” ì´ìœ ëŠ”,, ë‚˜ì¤‘ì— framework ë¥¼ ì¢€ ë” ìì„¸íˆ ë´¤ì„ ë•Œ, &#39;ì„ì˜ë¡œ ë§Œë“  ê²ƒ&#39; ê³¼ &#39;ì„ì˜ë¡œ ë§Œë“  ê²ƒ&#39; ê°„ì˜ ê±°ë¦¬ë¥¼ ë¹„êµí•˜ê³  ë˜ &#39;ì„ì˜ë¡œ&#39; ë§Œë“œëŠ” ê³¼ì •ì´ ë“¤ì–´ê°€ëŠ”ë°, ê·¸ê²ƒì˜ base... ê¸°ë°˜ì´ ë˜ì–´ì£¼ëŠ” true basic label ìœ¼ë¡œì¨ êµ‰ì¥íˆ ì¤‘ìš”í•œ ì—­í• ì„ ìˆ˜í–‰í•œë‹¤.</p> <ul> <li>Family and Non-family sample selection</li> </ul> <p>large embedding queue ì—ì„œ family set $F(q_{i,j})$ ì™€ non family set $F&#39;(q_{i,j})$ ë¥¼ êµ¬ì„±í•˜ê³ , $q_{i,j}$ ì— ê¸°ë°˜í•˜ì—¬ contrastive loss ë¥¼ ê³„ì‚°í•œë‹¤. ì´ ë•Œ, $F(q_{i,j})$ ëŠ” q, k ì™€ embedding queue whose class label equals $\hat{y}<em>{i,j}$ ë¡œë¶€í„° êµ¬ì„±ë˜ê³ , ê·¸ ë‚˜ë¨¸ì§€ëŠ” ëª¨ë‘ $F&#39;(q</em>{i,j})$ ê°€ ëœë‹¤. ì´ê²ƒì´ ì „ë¶€ì´ë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/d17534eb-e4bd-4883-bef0-59e1a7738962/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/959709b9-49ed-4eca-9e1c-3721c2d3359b/image.png" alt=""></p> <p>B ëŠ” minibatch ë¥¼ ëœ»í•œë‹¤. QëŠ” embedding queue ì´ë‹¤. ìœ„ family set ê³¼ non-family set ì„ ì´ìš©í•´ ë‹¤ìŒê³¼ ê°™ì€ loss ë¥¼ ê³„ì‚°í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/3dcdc6e4-8ec6-4be4-a084-a1d8aa215c32/image.png" alt=""></p> <ul> <li>Embedding Queue Updating</li> </ul> <p>iteration ëë§ˆë‹¤, current instance&#39;s momentum embedding $k_{i,j}$ ì™€ predicted label ë˜ëŠ” true negative label ì€ embedding queue Q ì— ë“¤ì–´ê°€ê³  ì˜¤ë˜ëœ ê±´ dequeue ëœë‹¤.</p> <h3 id="prototype-based-pseudo-label-generation">Prototype-based Pseudo Label Generation</h3> <p>ëª©ì : assign more accurate pseudo labels to instances by prototype learning</p> <p>ì•„ì§ ì„¤ëª… ì „ì´ì§€ë§Œ, ì´ ê³¼ì •ì„ í†µí•´, maintain two representative feature vector ë¥¼ ì–»ëŠ”ë‹¤. $\mu_r \in R^d$, $r=0,1$. ì‚¬ì‹¤ pseudo label ì˜ ìƒì„±ê³¼ prototype ì˜ updating process ì—­ì‹œ (ì•„ê¹Œ ë§í–ˆë“¯) true negative instance ì™€ instance classifier (predicted labelì„ ë§Œë“¤ì–´ ì£¼ê¸° ë•Œë¬¸) ì— ì˜í•´ guide ëœë‹¤. </p> <p>ë§Œì•½ $x_{i,j}$ ê°€ positive bag ìœ¼ë¡œ ë¶€í„° ì™”ë‹¤ë©´, embedding $q_{i,j}$ ê³¼ prototype vectors $\mu_{r}$ ë¡œ pseudo label $s_{i,j}\in R^2$ ë¥¼ ìƒì„±í•œë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/ddf25a44-87be-45d5-be1f-5b3def66053a/image.png" alt=""></p> <p>ë™ì‹œì—, prototype vector $\mu_{?}$ of the corresponding class ë¥¼ predicted label ê³¼ embedding q ë¡œ update í•œë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/49c2743a-3c39-4044-b697-c98c97f8db7b/image.png" alt=""></p> <p>ë§Œì•½ negative bag ìœ¼ë¡œë¶€í„° ì™”ë‹¤ë©´, directly assign negative label í›„, embedding q ë¥¼ í™œìš©í•˜ì—¬ negative prototype vector ë¥¼ update í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/0ac4dcdc-fb4e-436a-a69f-2b25d96ff8b4/image.png" alt=""></p> <p>ë§ˆì§€ë§‰ìœ¼ë¡œ, generated pseudo label ì„ ì‹¤ì œ encoder ë¡œë¶€í„° ë‚˜ì˜¨ smoothed predicted value $p_{i,j} \in R^2$ ê°„ì˜ cross-entropy loss ë¥¼ ê³„ì‚°í•˜ì—¬ iteration ì„ ë§ˆì¹˜ê²Œ ëœë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/c13cfd64-a742-4a94-92d3-aa95f9fa3df2/image.png" alt=""></p> <h3 id="bag-constraint-and-total-loss">Bag Constraint and Total Loss</h3> <p>ì •ë§ ë§ˆì§€ë§‰ ë‹¨ê³„ë¡œ, bag label ì„ ì¡°ê¸ˆ ë” í™œìš©í•˜ê¸° ìœ„í•´ embedding vector $q_{i,j}$ ë¥¼ mean pooling í•´ì„œ bag label ê³¼ cross entropy loss ë¥¼ ê³„ì‚°í•´ì„œ total loss ì— ë”í•´ì¤€ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/ea76cea5-ede7-4e00-ae03-fb9360ad33a7/image.png" alt=""></p> <p>ìš”ì¦˜ íŠ¸ë Œë“œì¸ attention weight ë¥¼ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•Šì€ ë¶€ë¶„ì´ ìƒë‹¹íˆ ì¸ìƒì ì´ë‹¤. </p> <h2 id="experimental-settings">Experimental Settings</h2> <h3 id="dataset">Dataset</h3> <ol> <li>Simulated CIFAR-MIL Dataset : 32x32 ì´ë¯¸ì§€ í•©ì³ì„œ WSI ì²˜ëŸ¼ í•©ì„±, í•˜ë‚˜ì˜ category label ì„ positive ë¡œ ì •ì˜.</li> <li>Camelyon16 Public Dataset : 512x512 image patches under 10x mag, total 186604 instances.</li> <li>TCGA LUNG Cancer Dataset : 1054 WSIs, 5.2 million patches at 20x mag.</li> <li>Cervical Cancer Dataset : 374 WSIs, 5x mag, 224x224 patches</li> </ol> <h3 id="evaluation-metrics-and-comparision-methods">Evaluation Metrics and Comparision Methods</h3> <p>in both instance and bag classification, AUC &amp; acc are used. compared out INS to 11 competitors: MILRNN, Chi-MIL, DGMIL (instance) ABMIL, Loss-ABMIL, CLAM, DSMIL, TransMIL, DTFD-MIL, TPMIL, WENO (bag)</p> <h2 id="results">Results</h2> <h3 id="synthetic-dataset-cifar-mil">Synthetic Dataset CIFAR-MIL</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/ff074367-7960-42c8-bdb6-a0578a1cdf23/image.png" alt=""></p> <h3 id="camelyon-16-dataset">Camelyon 16 Dataset</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/11bdf6ef-5393-41b8-bb02-c629b5d5a4ed/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/8fbb55b8-9ea7-4acc-8d57-3faf8b98b179/image.png" alt=""></p> <h3 id="tcga-lung-cancer-dataset">TCGA-LUNG cancer Dataset</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/f9cb45e8-0b8b-4c92-9bcd-d43b097b8457/image.png" alt=""></p> <h3 id="cervical-cancer-dataset">Cervical Cancer Dataset</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/24f31a41-828e-4df8-aba5-5d9291c53906/image.png" alt=""></p> <h3 id="interpretability-study-of-the-lymph-node-metastasis">Interpretability Study of the Lymph Node Metastasis</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/9b947cb0-070d-4b2b-84ef-711d56835539/image.png" alt=""></p> <p>INS to predict the probability of each instance being positive within the positive bags and visuazualied the top 0.1% instances with the highest and lowest probilities separately.</p> <ul> <li>lymph node metastasis &quot;micropapillae&quot; are more prevalent</li> <li>íŠ¹íˆ, small clusters of infiltrating cancer cells forming hollow or mulberry-like nests without a central fibrovascular axis, surrounded by blank lacunae or lacunae between interstitial components</li> <li>negative lymph node more commonly exhibits a sheet-like pattern</li> </ul> <p>ë‚˜ë¨¸ì§€ê°€ ì¡°ê¸ˆ ìˆê¸´ í•œë° ì¶”í›„ì— ì—…ë°ì´íŠ¸ í•˜ê² ë‹¤.</p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; July 24, 2023 &nbsp; &middot; &nbsp; jaeheon-lee </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p></li> <li><h3> <a class="post-title" href="/blog/2023/post-bibliography/">a post with bibliography</a> </h3> <p>an example of a blog post with bibliography</p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; July 12, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> &nbsp; &middot; &nbsp; <a href="/blog/tag/formatting"> <i class="fas fa-hashtag fa-sm"></i> formatting</a> &nbsp; <a href="/blog/tag/bib"> <i class="fas fa-hashtag fa-sm"></i> bib</a> &nbsp; &nbsp; &middot; &nbsp; <a href="/blog/category/sample-posts"> <i class="fas fa-tag fa-sm"></i> sample-posts</a> &nbsp; </p></li> <li><h3> <a class="post-title" href="/blog/2023/jupyter-notebook/">a post with jupyter notebook</a> </h3> <p>an example of a blog post with jupyter notebook</p> <p class="post-meta"> 2 min read &nbsp; &middot; &nbsp; July 4, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> &nbsp; &middot; &nbsp; <a href="/blog/tag/formatting"> <i class="fas fa-hashtag fa-sm"></i> formatting</a> &nbsp; <a href="/blog/tag/jupyter"> <i class="fas fa-hashtag fa-sm"></i> jupyter</a> &nbsp; &nbsp; &middot; &nbsp; <a href="/blog/category/sample-posts"> <i class="fas fa-tag fa-sm"></i> sample-posts</a> &nbsp; </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-Self-Supervised-Learning-from-Images-with-a-Joint-Embedding-Predictive-Architecture" target="_blank">[Paper Review] Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="self-supervised-learning-from-images-with-a-joint-embedding-predictive-architecture">Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture</h1> <p>SNS í”¼ë“œë¥¼ ë³´ë‹¤ê°€ I-JEPA ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë´¤ë‹¤. ì œëª© ìì²´ê°€ êµ‰ì¥íˆ intriguing í–ˆëŠ”ë° <a href="https://ai.facebook.com/blog/yann-lecun-ai-model-i-jepa/">https://ai.facebook.com/blog/yann-lecun-ai-model-i-jepa/</a> &#39;I-JEPA: The first AI model based on Yann LeCun&#39;s vision for more human-like AI&#39; ì˜€ë‹¤.. ê²Œì¬ëœì§€ëŠ” ê½¤ ë˜ì—ˆì§€ë§Œ ì´ë²ˆ CVPR 2023 ë°œí‘œì™€ í•¨ê»˜ ë‹¤ì‹œ í•œë²ˆ ìˆ˜ë©´ìœ¼ë¡œ ì˜¬ë¼ì™”ë‹¤. paper ì˜ í•µì‹¬ architecture ë¥¼ ì´í•´í•˜ë©´ì„œ human-like AI ë¼ëŠ” term ì— ëŒ€í•´ ê³µê°ì´ ê°”ëŠ”ë°, ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. ê¸°ì¡´ generative approach for SSL ë°©ì‹ì—ì„œëŠ” reconstruction ì„ í•œ í›„ì— loss ë¥¼ ê³„ì‚°í–ˆëŠ”ë°, I-JEPA ì—ì„œëŠ” representation space ì—ì„œ reconstruction (?) ë° loss ê³„ì‚°ì´ ì´ë£¨ì–´ì§„ë‹¤. augmentation ì´ ë”°ë¡œ í•„ìš”ì—†ë‹¤ëŠ” ì ë„ í¬í•¨ë  ìˆ˜ ìˆë‹¤. </p> <h2 id="introduction">Introduction</h2> <p>computer vision field ì—ì„œ two common families of approches for self-supervised learning ë°©ì‹ì„ ì†Œê°œí•œë‹¤.</p> <ol> <li>Invariance-based pretraining methods (MoCo, SimSiam, VICReg, BarlowTwins...)</li> <li>Generative methods (MAE, language models)</li> </ol> <p>ë¨¼ì € 1ë²ˆ ë°©ì‹ì˜ ë¬¸ì œì ì„ ì–¸ê¸‰í•œë‹¤. pretraining methods can produce high semantic representations but introduce strong biases that may be detremental for certain downstream tasks. unclear how to generalize these biases for tasks requiring different levels of abstraction. (ex, segmentation &amp; classification do not require the same invariances.) (ë„ë•ë„ë•)</p> <p>ë˜í•œ í•„ìëŠ” Cognitive learning ì´ë¡ ì—ì„œëŠ” biological system ì—ì„œì˜ representation learning ì˜ í•µì‹¬ì€ &quot;the adaptation of an internal model to predict sensory input responses&quot; ì´ë‹¤. ë¼ê³  í•˜ë©° core of generative SSL model ì˜ í•µì‹¬ì¸ &quot;remove or corrupt portions of the input and learn to predict the corrupted content&quot; ì™€ ê°™ì€ ì„ ìƒì— ìˆë‹¤ê³  ì£¼ì¥í•œë‹¤. </p> <p>ì´ì–´ì„œ ì´ ë°©ì‹ì˜ ë¬¸ì œì ë„ í•¨ê»˜ ì–¸ê¸‰í•œë‹¤. lower sementic level ì˜ representation ì„ ë„ì¶œí•˜ê³ , ì¢…ì¢… underperform invariance-based pretraining inf off-the-shelf evaluation (ex linear probing) í•˜ë‹¤ê³  ì§€ì í•œë‹¤.</p> <p>ë³¸ ë…¼ë¬¸ì—ì„œëŠ” SSL representation ì˜ semantic level ì„ prior knowledge (encoded through augmentatino) ì—†ì´ ê°œì„ í•  ìˆ˜ ìˆëŠ”ê°€ì— ëŒ€í•œ ê³ ë¯¼ì„ ë‹´ê³  ìˆê³ , ì´ë¥¼ &quot;predict missing information in ab abstract representation space&quot; í•˜ëŠ” ê²ƒìœ¼ë¡œ ì¢‹ì€ ì„±ëŠ¥ì„ ë§Œë“¤ì—ˆë‹¤ê³  í•œë‹¤.</p> <p>ë‹¤ìŒì€ introduction ë§¨ ë§ˆì§€ë§‰ì— ìˆëŠ” we demonstrate that ~ ì´ë‹¤.</p> <ul> <li>I-JEPA learns strong off-the-shelf representation without the use of hand-crafted view augmentations. </li> <li>I-JEPA outperforms pixel-reconstruction methods (like MAE) on ImageNet01K linear probing, etc</li> <li>I-JEPA ëŠ” view-invariant pretraining model ê³¼ semantic task ì—ì„œ competitive í–ˆê³ , low-level vision task ë¥¼ outperform í•¨. (applicable to a wider set of tasks)</li> <li>I-JEPA is also scalable and efficient</li> </ul> <h2 id="background">Background</h2> <p>ë³´í†µ background ëŠ” ê°„ë‹¨íˆ í•˜ê³  ë„˜ì–´ê°€ëŠ”ë° ì½ëŠ” ê²ƒë§Œìœ¼ë¡œ ë„ì›€ì´ ë§ì´ ë˜ëŠ” ë‚´ìš©ë“¤ì´ë¼ ìì„¸íˆ ì‘ì„±í•˜ë ¤ í•œë‹¤.</p> <p>Self-supervised learning ì€ &quot;inputs ë“¤ ê°„ì˜ relationship ì„ capture&quot; í•˜ëŠ” í•™ìŠµ ë°©ì‹ì´ë‹¤. ì´ëŠ” framework of Energy-Based Models (EBM) ìœ¼ë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆë‹¤. incompatible input ì— ëŒ€í•´ì„œëŠ” high energyë¥¼, compatible inputs ì— ëŒ€í•´ì„œëŠ” low energy ë¥¼ í• ë‹¹í•˜ëŠ” ê²ƒì´ë‹¤. í˜„ì¡´í•˜ëŠ” generative ë° non-generative model ì—ì„œëŠ” ì•„ë˜ ì„¸ê°€ì§€ framework ë¡œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/25514140-d043-491e-abdc-edfbe6543fe0/image.png" alt=""></p> <h3 id="joint-embedding-architectures">Joint Embedding Architectures</h3> <p>JEA ëŠ” ë¹„ìŠ·í•œ input ì— ëŒ€í•´ ë¹„ìŠ·í•œ embedding, ë‹¤ë¥¸ input ì— ëŒ€í•´ ì„œë¡œ ë‹¤ë¥¸ embedding ì„ ë§Œë“¤ë„ë¡ í•™ìŠµí•œë‹¤. Main Challenge with JEA ëŠ” &quot;representaion collapse&quot; (aka dimensional collapse) ì´ë‹¤. energy landscape ê°€ flat í•œ ê²½ìš°, ì¦‰ encoder ê°€ trivial embedding ì„ ë§Œë“œëŠ” í˜„ìƒì´ë‹¤. ì´ëŸ¬í•œ dimensional collapse ë¥¼ ë§‰ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ loss ë“¤ì´ ì—°êµ¬ë˜ì—ˆì—ˆë‹¤. </p> <ul> <li>contrastive losses : push apart embeddings of negative examples</li> <li>non-contrastive losses : minimize informational redundancy</li> <li>clustering-based approches : maximize the entropy of the average embedding</li> </ul> <p>ê·¸ë¦¼ì˜ (a)ì— í•´ë‹¹í•˜ëŠ” êµ¬ì¡°ì´ë‹¤. representation space ì—ì„œ ë³´í†µ lossê°€ ê³„ì‚°ëœë‹¤. (ì „ì—ë„ ë¦¬ë·°í•œ ì ì´ ìˆëŠ” ë‚´ìš©ì¸ë°) dimensional collapse ë¥¼ í”¼í•˜ëŠ” ê°€ì¥ í•µì‹¬ì€ leverage an assymmetric architectural design between x-encoder and y-encoder í•˜ëŠ” ê²ƒì´ì—ˆë‹¤.</p> <h3 id="generative-architectures">Generative Architectures</h3> <p>ì—¬íƒœ ë¦¬ë·°í–ˆë˜ ë…¼ë¬¸ë“¤ì€ ëŒ€ë¶€ë¶„ JEA ì˜€ê³  ìƒì„± ê¸°ë°˜ êµ¬ì¡°ë¥¼ ê°€ì§„ ë…¼ë¬¸ì€ MAE ì •ë„ë§Œ ì½ì–´ë³¸ ê²ƒ ê°™ë‹¤. (b) ë‚´ìš©ì¸ë°, ì´ êµ¬ì¡°ëŠ” additional variable z (cGAN (SSLì€ ì•„ë‹ˆì§€ë§Œ) ì—ì„œì˜ conditionì— í•´ë‹¹í•  ìˆ˜ë„ ìˆê³  MAE ì˜ mask ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ ë˜ëŠ” position token ì¼ ìˆ˜ë„ ìˆë‹¤) condition ìœ„ì—ì„œ, directly reconstruct a signal y from a compatible signal x ì´ê³ , loss ëŠ” reconstructed signal ê³¼ ì›ë˜ ìˆë˜ ê¸°ì¡´ signal ì‚¬ì´ì—ì„œ ê³„ì‚°ëœë‹¤. </p> <h3 id="joint-embedding-predictive-architectures">Joint-Embedding Predictive Architectures</h3> <p>I-JEPA ì—ì„œ ì œì•ˆí•˜ëŠ” êµ¬ì¡°ì´ë‹¤. (c) ë‚´ìš©ì´ê³ , (b) êµ¬ì¡°ì™€ ìƒë‹¹íˆ ë‹®ì•„ ìˆìœ¼ë©´ì„œ, loss function is applied in embedding space (not input space) ë¼ëŠ” ì ì´ key difference ì´ë‹¤. ë˜í•œ hand-crafted augmentation ì„ ì—†ì• ëŠ” ëŒ€ì‹ , representation ìƒì—ì„œì˜ &quot;mask&quot;, ì¦‰ additional information &quot;z&quot; ë¥¼ ë‹¬ë¦¬í•˜ì—¬ conditionëœ representation ì„ predict í•œë‹¤. ë¬¼ë¡  representation space ìƒì—ì„œì˜ ì‘ì—…ì´ê¸° ë•Œë¬¸ì— dimensional collapse ë¥¼ ì—¼ë‘ì— ë‘ê³  asymmetric architecture ë¥¼ ì„¤ì •í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•¨ì„ ê°•ì¡°í–ˆë‹¤.</p> <h2 id="method">Method</h2> <p>now describe the proposed Image-based Joint-Embedding Predictive Architecture (I-JEPA) <img src="https://velog.velcdn.com/images/jaeheon-lee/post/95b31d60-6ce4-428a-a71e-7bb3279bf935/image.png" alt=""></p> <p>context-encoder ì™€ target-encoder, ê·¸ë¦¬ê³  predictor (ê°€ ì•„ì§ ë­”ì§€ ëª¨ë¥´ì§€ë§Œ) ì—ì„œ ViT architecture ë¥¼ ì‚¬ìš©í–ˆë‹¤. ì•„ë˜ ë‘ ì¤„ë¡œ Overall objective ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.</p> <ul> <li>given a context block</li> <li>predict the representations of various target blocks (in the same image)</li> </ul> <p>ë­”ê°€ MAE ì™€ ë¹„ìŠ·í•´ë³´ì¸ë‹¤. ê·¸ëŸ¼ context block ê³¼ target block ì€ ë­˜ê¹Œ ë¼ëŠ” ì§ˆë¬¸ì´ ë“ ë‹¤. ê·¸ ì „ì— target ì´ ë­”ì§€ë¶€í„° ê·œëª…í•œë‹¤.</p> <h3 id="targets">Targets</h3> <p>how we produce the targets? ìš°ì„  y ë¼ëŠ” image ë¥¼, N non-overlapping patches ë¥¼ ìƒì„±í•œë‹¤. ì´í›„ ì´ë¥¼ target-encoder $f_{\hat{\theta}}$ ì— ì§‘ì–´ë„£ê³ , patch-level representation $s_y$ = {$s_{y_1},,, s_{y_N}$} ì„ ì–»ëŠ”ë‹¤. ê·¸ë¦¬ê³  ì—¬ê¸°ì„œ loss ì— ì‚¬ìš©í•  M ê°œì˜ block ì„ ë½‘ëŠ”ë°, 1 ê°œì˜ block ë§ˆë‹¤ ì—¬ëŸ¬ê°œì˜ patch ê°€ ë“¤ì–´ìˆê³  ì´ëŠ” overlap ì´ ê°€ëŠ¥í•˜ë‹¤. ì´ block ì„ ì§€ì¹­í•˜ëŠ” &quot;mask&quot; í•˜ë‚˜ë¥¼ $B_i$ ë¼ê³  ë¶€ë¥´ê³ , ê·¸ì— í•´ë‹¹í•˜ëŠ” ië²ˆì§¸ block ì˜ patch set ì„ $s_y(i) = {S_{y_j}}_{j\in B{i}}$ ë¼ê³  ë¶€ë¥¸ë‹¤. ë³´í†µ M ì€ 4ê³  aspect ratio ëŠ” (ì•„ë§ˆ ë„ˆë¹„&amp;ë†’ì´) (0.75, 1.5) ì´ê³ , random scale (ì•„ë§ˆ í¬ê¸°) ëŠ” (0.15,0.2) ì´ë‹¤. ì €ìëŠ” &quot;target block&quot; ì€ masking the &quot;output of the target-encoder&quot; ì´ì§€ not &quot;input&quot; ì´ë¼ê³  ê°•ì¡°í•œë‹¤. ì¦‰ input ì— ë°”ë¡œ mask ì”Œìš°ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ embedding ëœ ê²ƒì— ì”Œìš°ëŠ” ê²ƒì´ë¼ê³  ê°•ì¡°í•œë‹¤.</p> <h3 id="contexts">Contexts</h3> <p>Recall, the goal behind I-JEPA is to predict the target block representations from <strong>single context block</strong>. image ì—ì„œ random scale (0.85, 1.0) ìœ¼ë¡œ ê·¸ë¦¬ê³  unit aspect ratio ë¡œ a single block x ë¥¼ ë½‘ê³  ì´ mask ë¥¼ $B_x$ ë¼ê³  ë¶€ë¥¸ë‹¤. target block ê³¼ context block ëª¨ë‘ random í•˜ê²Œ ë½‘ì•˜ìœ¼ë‹ˆ ë‹¹ì—°íˆ ê²¹ì¹  ìˆ˜ ìˆë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/f332368a-426f-4750-a3a2-e824c690cdca/image.png" alt=""></p> <p>ìœ„ ê·¸ë¦¼ì€ target block ê³¼ context block ì˜ ì˜ˆì‹œì´ë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ context block ì—­ì‹œ context encoder $f_\theta$ ì— ë„£ì–´ $s_x = {S_{x_j}}_{j\in B{x}}$ ë¥¼ ë§Œë“ ë‹¤. ìœ„ì˜ target encoder ì™€ëŠ” ë…ë¦½ëœ ë„¤íŠ¸ì›Œí¬ì´ë‹¤. </p> <h3 id="prediction">Prediction</h3> <p>ì´ì œ $s_x$ë„ ë½‘ì•˜ê³  Mê°œì˜ target block ì— í•´ë‹¹í•˜ëŠ” patch representation setì¸ $s_y(1), ... , s_y(M)$ ë„ ë½‘ì•˜ë‹¤. ì´ ë•Œ, ì£¼ì–´ì§„ ê° $s_y(i)$ì— ëŒ€í•´, predictor $g_\phi(-,-)$ ëŠ” context encoder ì˜ output ì¸ $s_x$ ì™€ mask token for each patch ${m_j}_{j\in B_i}$ ë¥¼ ë°›ì•„ì„œ $\hat{s}_y(i)$ ë¥¼ ë§Œë“ ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/572c6b6a-acf3-4cfe-8168-80e1ab3d8e66/image.png" alt=""></p> <p>mask token is parameterized by a shared learnable vector with an added positional embedding. ì¦‰, mask ëŠ” constant ê°€ ì•„ë‹ˆë¼ parameter ì´ë‹¤. ì²˜ìŒì—ëŠ” ì´ ë¶€ë¶„ì´ êµ‰ì¥íˆ í—·ê°ˆë ¸ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/01b2f476-44f0-4d2c-bd95-8b53248ae139/image.png" alt=""></p> <p>ìœ„ ê·¸ë¦¼ì„ ë³´ë©´, context block ê³¼ target block ì´ ì „í˜€ ê²¹ì¹˜ì§€ ì•Šê³  ìˆëŠ”ë° ì–´ë–»ê²Œ masking ì„ í•œë‹¤ëŠ”ê±°ì§€? ë¼ëŠ” ì˜ë¬¸ì´ ë“¤ì–´ í—·ê°ˆë ¸ë‹¤. í•˜ì§€ë§Œ ë¬¼ë¦¬ì ì¸ masking ì„ ì˜ë¯¸í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, í•˜ë‚˜ì˜ parameter z ì¦‰ condition (ë„ˆëŠ” ì´ ë¶€ë¶„ì„ ì˜ˆì¸¡í•´ì•¼ í•´ ë¼ëŠ” ì •ë³´) ë¡œ ë°›ì•„ ë“¤ì´ê³  ë‚˜ë‹ˆ ì´í•´ê°€ ìˆ˜ì›”í–ˆë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/424905bd-4266-4a18-963a-5232ddb0fb17/image.png" alt=""></p> <p>ê·¸ëƒ¥ concatì´ë‹¤. context block patch representation ê³¼ mask token, positional encoding ì„ concat, add í•´ì„œ predictor network ì— í†µê³¼ì‹œí‚¤ê³ , ì´ë¥¼ target block patch representation ê³¼ ë¹„êµí•˜ëŠ” ê²ƒì´ë‹¤.</p> <h3 id="loss">Loss</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/86de9a88-6f55-4539-a3af-3a036d483119/image.png" alt=""> L2 loss ë¥¼ ì‚¬ìš©í–ˆë‹¤.</p> <h2 id="image-classification">Image Classification</h2> <p> I-JEPA ê°€ ì¢‹ì€ high-level representation ì„ augmentation ì—†ì´ë„ ì˜ í•™ìŠµí•œë‹¤ëŠ” ê²ƒì„ ë³´ì´ê¸° ìœ„í•´, linear probing ê³¼ partial fine-tuning protocol ì„ í†µí•œ image classificaion task ë¥¼ ìˆ˜í–‰í•˜ì˜€ë‹¤. ImageNet-1K dataset ìœ¼ë¡œë¶€í„° pretrained ëœ ë‹¤ë¥¸ self-supervised model ì„ ë¹„êµêµ°ìœ¼ë¡œ ì‚¬ìš©í–ˆê³ , ëª¨ë“  I-JEPA ëª¨ë¸ì€ resolution 224 x 224 pixels ë¡œ train ë˜ì—ˆë‹¤.</p> <h3 id="imagenet-1k">ImageNet-1K</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/222db1f4-476d-4667-9ca6-b36c6f3f774c/image.png" alt=""></p> <p>Table1. ì€ common ImageNet-1K linear-evaluation benchmark ì— ë”°ë¥¸ ì„±ëŠ¥ ê¸°ë¡ì´ë‹¤. SSL ì‚¬ì „í•™ìŠµ í›„ frozen ëœ í›„ linear classifier ê°€ í•™ìŠµë˜ì—ˆë‹¤. data augmentation ì—†ëŠ” MAEì™€ CAE (context autoencoder), data2vec ì´ ë¹„êµ ì‹¤í—˜ ëª¨ë¸ë¡œ ì‚¬ìš©ë˜ì—ˆë‹¤. augmentation ì´ ì—†ì—ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  invariant approach (like iBOT) ê³¼ competitive í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆë‹¤.</p> <h3 id="low-shot-imagenet-1k">Low-shot ImageNet-1K</h3> <p> <img src="https://velog.velcdn.com/images/jaeheon-lee/post/23929fd2-4171-4ff9-b317-7b614a348777/image.png" alt=""></p> <p>Table2 ëŠ” 1% ImageNet benchmark performance ì´ë‹¤. 1%ì˜ available ImageNet label ì„ ì‚¬ìš©í•˜ì˜€ë‹¤. I-JEPA ëŠ” MAE ë³´ë‹¤ less pretraining epoch ì„ ì‚¬ìš©í•˜ì—¬ outperform í•˜ì˜€ê³ , data2vec ë³´ë‹¤ ë” ì‘ì€ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë‚´ì—ˆë‹¤. input resolution ì„ ë†’ì—¬ (to 448) í•™ìŠµí–ˆì„ ë•Œ ì´ì „ data augmentation ì„ ì‚¬ìš©í–ˆì–´ì•¼ë§Œ í–ˆë˜ invariance approach SSL ë°©ì‹ë“¤ì˜ ê²°ê³¼ë¥¼ ëª¨ë‘ ë›°ì–´ë„˜ì—ˆë‹¤. í ..</p> <h3 id="transfer-learning">Transfer learning</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/f9e5a5dd-bbb9-4eca-8d2b-1ea49b71d37d/image.png" alt=""></p> <h2 id="local-prediction-tasks">Local Prediction Tasks</h2> <p>ìœ„ì—ì„  classification task ì— ëŒ€í•´ í™•ì¸í–ˆëŠ”ë°, ê¸°ì¡´ generative ì„±ëŠ¥ì„ ë›°ì–´ë„˜ì„ ë¿ë§Œ ì•„ë‹ˆë¼ high semantic task ì— íŠ¹í™”ëœ invariance based method ì—ë„ competitive í•œ ì„±ëŠ¥ì„ ê¸°ë¡í–ˆë‹¤. ì´ì œ local image features ë„ ì˜ í•™ìŠµí•˜ëŠ”ì§€ë¥¼ ì•Œì•„ë³´ì•˜ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/45dfe475-4d2e-40ef-bd59-eb3431c98068/image.png" alt=""></p> <p>object countingê³¼ depth prediction ì—ì„œ view-invariance based method ë¥¼ outperform í–ˆë‹¤. </p> <h2 id="scalability">Scalability</h2> <h3 id="model-efficiency">Model Efficiency</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/074e1927-a415-4951-9dcb-491c94b44f71/image.png" alt=""></p> <p>I-JEPA ëŠ” ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ highly scalable í•¨ì„ ë³´ì´ê³  ìˆë‹¤. ì´ì „ ë°©ì‹ë“¤ë³´ë‹¤ ë” ì ì€ ì‹œê°„ìœ¼ë¡œ ë” ë†’ì€ ì„±ëŠ¥ì„ ê¸°ë¡í•˜ê³  ìˆë‹¤. (task: semi-supervised evaluation on 1% ImageNet-1K) </p> <h3 id="scaling-data-size--model-size">Scaling data size &amp; model size</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/c673d1fb-bb91-4355-a34c-41a720b8ba27/image.png" alt=""></p> <p>I-JEPA ëŠ” larger dataset ì—ì„œ pretraining ë ìˆ˜ë¡ benefit ì´ ìˆë‹¤ëŠ” ê²ƒì„ í™•ì¸í–ˆê³ , larger model size ë¡œë¶€í„° í•™ìŠµí–ˆì„ ë•Œ ë” ë†’ì€ ì„±ëŠ¥ì„ ê¸°ë¡í•¨ì„ í™•ì¸í•˜ì˜€ë‹¤. (scalability)</p> <h2 id="predictor-visualization">Predictor Visualization</h2> <p>I-JEPAì—ì„œ predictorì˜ ì—­í• ì€, predictorì— context encoder ì˜ output ê³¼ í•¨ê»˜, positional mask token ì„ í†µê³¼ì‹œì¼°ì„ ë•Œ target block representation ì„ ì˜ˆì¸¡í•˜ë„ë¡ í•˜ëŠ” ê²ƒì´ë‹¤. ì´ê²ƒì´ representation space level ì—ì„œ ì´ë£¨ì–´ì§€ê¸° ë•Œë¬¸ì— ì´ë¥¼ visualization í•´ë³´ì•˜ë‹¤. ìº¬</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/04c3323e-7092-4b63-a91b-7cd4775aba25/image.png" alt=""> </p> <p>ë„ˆë¬´ ë©‹ì§€ë‹¤ ë°©ë²•ì€ RCDM framework ì— ë”°ë¼ decoder ë¥¼ í•™ìŠµí–ˆë‹¤ê³  í•˜ëŠ”ë°, ì •í™•íˆ ì´í•´ëŠ” ëª»í–ˆë‹¤. (ë…¼ë¬¸ reference ë¥¼ ì°¸ê³ í•˜ë„ë¡ í•˜ì)</p> <h2 id="ablations">Ablations</h2> <h3 id="predicting-in-representation-space">Predicting in representation space</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/d79b4685-ec7d-454a-ac0b-d15e1e2ceaea/image.png" alt=""></p> <p>I-JEPA ì˜ í•µì‹¬ ì¤‘ í•˜ë‚˜ëŠ” representation space ì—ì„œ loss ë¥¼ ê³„ì‚°í•œë‹¤ëŠ” ê²ƒì´ë‹¤. ì´ê²ƒì´ íš¨ìš©ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ pixel-space ì™€ representation-space ì—ì„œ loss ê³„ì‚°í•´ì„œ ì„±ëŠ¥ì„ ë¹„êµí•˜ì˜€ë‹¤. </p> <h3 id="masking-strategy">Masking strategy</h3> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/06ea2b2e-4c17-45b7-bb89-8203e7a21a1c/image.png" alt=""></p> <p>mask ë°©ì‹ì„ ë‹¬ë¦¬í•˜ì—¬ ì‹¤í—˜ì„ ì—¬ëŸ¿ ëŒë ¸ë‹¤.</p> <h2 id="conclusion">Conclusion</h2> <p>ì¬ë°Œêµ¬ë§Œ..</p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; June 21, 2023 &nbsp; &middot; &nbsp; jaeheon-lee </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p></li> <li><h3> <a class="post-title" href="https://velog.io/@jaeheon-lee/Paper-Review-RetCCL-Clustering-guided-contrastive-learning-for-whole-slide-image-retrieval" target="_blank">[Paper Review] RetCCL: Clustering-guided contrastive learning for whole-slide image retrieval</a> <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </h3> <p><h1 id="retccl-clustering-guided-contrastive-learning-for-whole-slide-image-retrieval">RetCCL: Clustering-guided contrastive learning for whole-slide image retrieval</h1> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/844b3d38-4281-4d55-a435-b351f64821cc/image.png" alt=""></p> <p>ë””ì§€í„¸ ë³‘ë¦¬ AI ì‹¬í¬ì§€ì›€ì—ì„œ reference ë˜ì—ˆë˜ breast npj 2023 ë…¼ë¬¸ì—ì„œ ì°¨ìš©í•œ SSL ë°©ë²•ì´ë‹¤. WSI ì—ì„œ SSL ë°©ì‹ì„ ë„ì…í•  ë•Œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¬¸ì œì ì„ ì¸ì§€í•˜ê³  ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ fancy í•œ ë°©ë²•ì„ ì‚¬ìš©í–ˆë‹¤. ê²°ê³¼ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ì—ˆê³  ë§ì€ ë…¼ë¬¸ì—ì„œ ì¸ìš©ë˜ê³  ìˆì–´ ì˜ë¯¸ ìˆëŠ” ë…¼ë¬¸ì´ë¼ ìƒê°í•œë‹¤.</p> <h2 id="introduction">Introduction</h2> <ul> <li>WSI annotation ë° computation cost ë†’ìŒ.</li> <li>SSL ë°©ì‹ì„ ì‚¬ìš©í•˜ë©´ ì´ ë¬¸ì œë¥¼ alleviate í•  ìˆ˜ ìˆìŒ.</li> <li>ê¸°ì¡´ SimCLR ë“±ì˜ ë°©ì‹ì—ì„œ patch ë¥¼ instance ë¡œ ì—¬ê²¨ í•™ìŠµí•˜ë©´, serious bias ìƒê¹€.</li> <li>unbalanced tissue type distribution ì™€ large portion of similar tissues</li> <li>ì´ë¥¼ ìœ„í•´ ë‹¤ìŒ ë‘ê°€ì§€ ë°©ë²•ì„ ì‚¬ìš©í•œ framework ë¥¼ ì œì•ˆí•¨. 1) clustering-guided contrastive learning (CCL) for feature extraction 2) distinctive query patch selection, ranking for searched pathes, and aggregation algorithm for interpretable WSI searching</li> </ul> <h2 id="related-works">Related works</h2> <h3 id="self-supervised-representation-learning">Self-supervised representation learning</h3> <ul> <li>natural image application to the histopathology domain : domain shift</li> <li>focus on semantic features within the specific task : limited model generalization</li> <li>not tested on large and diverse histopathological image datasets</li> </ul> <h3 id="histopathological-image-retrieval">Histopathological image retrieval</h3> <ul> <li>traditional hand-craft features</li> <li>DL method based high-level features</li> <li>suboptimal performance due to the domain shift btw natural and histopathological images</li> </ul> <h2 id="methods">Methods</h2> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/15bf65b7-5608-429c-b489-3482bc2ff118/image.png" alt=""></p> <p>ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¡œ ë˜ì–´ìˆë‹¤.</p> <ol> <li>weighted InfoNCE, group-level InfoNCE í™œìš©í•œ feature extraction</li> <li>1) offline database construction for WSI retrieval</li> <li>2) online WSI query process</li> </ol> <h3 id="contrastive-learning-based-feature-extractor">Contrastive learning based feature extractor</h3> <h4 id="preliminary-of-contrastive-learning">Preliminary of contrastive learning</h4> <p>x: image, x_q, x_k: augmented views ë¼ í•  ë•Œ, contrastive learning ì€ q &amp; k+ sample ì„ ê°€ê¹Œì´ì—, q &amp; k- sample ì„ ë©€ë¦¬ ë‘ë„ë¡ í•™ìŠµí•œë‹¤. ê°€ì¥ ê¸°ë³¸ì ì¸ loss ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì“¸ ìˆ˜ ìˆë‹¤. <img src="https://velog.velcdn.com/images/jaeheon-lee/post/a3f4b1cf-e2af-474b-963d-610d0c43c6c3/image.png" alt=""></p> <p>sigma L ì´ í¬í•¨ëœ ë¬¶ìŒì€ memory bank ë‚´ negative samples ì„ ì˜ë¯¸í•œë‹¤. ì´ë¥¼ í†µí•´ momentum encoder ì´ moving average ë°©ì‹ìœ¼ë¡œ update ëœë‹¤.</p> <h4 id="proposed-clustering-guided-contrastive-learning">proposed clustering-guided contrastive learning</h4> <p>ìœ„ì™€ ê°™ì€ ë°©ì‹ì„ ì‚¬ìš©í–ˆì„ ë•Œ ë‹¤ë¥¸ ë°ì´í„°ì…‹ì—ì„  ì˜ ë‚˜ì˜¬ì§€ ëª°ë¼ë„ WSI ë°ì´í„°ì—ëŠ” ë§ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤. ìœ„ ì‹ìœ¼ë¡œ ë´¤ì„ ë•Œ, negative sample memory bankì— positive sample ë¡œ consider ë˜ì–´ì•¼ í•  highly correlated sample ì´ í¬í•¨ë˜ì–´ ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤. ë˜, different patch ë“¤ì´ ê°™ì€ tissue ë¡œë¶€í„° ìƒ˜í”Œë§ ë˜ì—ˆê³  strikingly similar appearance ë¥¼ ê°€ì¡Œë‹¤ë©´ ë¬¸ì œëŠ” ë” ì‹¬ê°í•´ì§„ë‹¤. ì´ëŠ” histopathology ë¶„ì•¼ì—ì„œ SSL ë°©ì‹ì„ ë„ì…í•  ë•Œ ì¤„ê³§ ì–¸ê¸‰ë˜ì–´ ì™”ë˜ í•œê³„ì ì´ê¸°ë„ í•˜ë‹¤.</p> <p>ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ë‘ê°€ì§€ loss (weighted InfoNCE &amp; group-level InfoNCE) ë¡œ êµ¬ì„±ëœ clustering-based contrastive learning method ë¥¼ ì œì•ˆí•œë‹¤. W-InfoNCE loss ëŠ” possible false-negative sample ì˜ ì˜í–¥ì„ ì¤„ì´ê¸° ìœ„í•¨ì´ê³ , G-InfoNCE loss ëŠ” distinctive group center ë¼ë¦¬ëŠ” ë©€ë„ë¡ í•˜ê³  ë‹¤ë¥¸ instance ëŠ” group ìœ¼ë¡œ ëª¨ìœ¼ëŠ” ì—­í• ì„ í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/844b3d38-4281-4d55-a435-b351f64821cc/image.png" alt=""></p> <p>ë¨¼ì € three augmented images ë¥¼ ì–»ëŠ”ë‹¤. (xp, xk, xq) ê·¸ë¦¬ê³  ë‘ê°œì˜ encoder h (xp, xq) ì™€ f (xk) ë¥¼ í†µê³¼ì‹œì¼œ feature (hp, fk, hq) ë¥¼ ì–»ëŠ”ë‹¤. ì´í›„ two MLP heads g1, g2 ë¥¼ ì´ìš©í•´, hp ë¥¼ gp1, gp2 ë¡œ encoding í•˜ê³ , hq ë¥¼ hq1, hq2 ë¡œ encoding í•œë‹¤. fk ì˜ ê²½ìš° g2 ë¥¼ ì´ìš©í•´ gk ë¥¼ ì–»ëŠ”ë‹¤. MLP head g2 ë¥¼ í†µê³¼ì‹œì¼œ ë‚˜ì˜¨ ì„¸ ê°œì˜ feature gp2, gq2, gk ë¥¼ ì´ìš©í•´ weighted InfoNCE loss ë¥¼ ê³„ì‚°í•˜ê²Œ ë˜ê³ , MLP head g1 ì„ í†µê³¼ì‹œì¼œ ë‚˜ì˜¨ ë‘ ê°œì˜ feature gp1, gq1 ì€ cluster í•˜ëŠ” ë°ì— ì‚¬ìš©ë˜ì–´ í–¥í›„ group-level infoNCE loss ì— í™œìš©ëœë‹¤. ì´í›„ final loss function ì€ ë‘ loss ì˜ ì¡°í•©ìœ¼ë¡œ ê³„ì‚°ëœë‹¤.</p> <h4 id="online-clustering-guided-memory-bank-construction">Online clustering-guided memory bank construction</h4> <p>weight ë¥¼ ì£¼ì–´ false-negative-like sample ì˜ ì˜í–¥ì„ ì¤„ì„ìœ¼ë¡œì¨ ê¸°ì¡´ memory bank ì™€ëŠ” ì°¨ë³„ëœ online clustering-guided memory bank ë¥¼ ì œì•ˆí•œë‹¤.</p> <p>ë§¤ training epoch ë§ˆë‹¤, two positive pairs {gp2, gk}, {gq2, gk} ë¥¼ í™œìš©í•´, shared memory bank ë¡œ contrastive learning ì„ ìˆ˜í–‰í•œë‹¤. ìš°ì„  negative sample ì„ k-means clusering ì„ í™œìš©í•´ Q classes ë¡œ ë‚˜ëˆ„ê³ , ì´ë¥¼ Q sub-memory queues ë¡œ ë³¸ë‹¤. ì´ ë•Œ, ê° centroid c (qê°œ) ì™€ gk ê°„ì˜ similarity ë¥¼ ê³„ì‚°í•˜ê³ , ì´ similarity ê°’ ì¤‘ ê°€ì¥ í° ê°’ì„ ê°–ëŠ” Q ë¥¼ Q_max ë¼ê³  ì§€ì •í•œë‹¤. ì´í›„ negative sample ê³¼ì˜ similarity ë¥¼ ê³„ì‚°í•  ë•Œ ë‹¤ìŒ $\phi (g_k-)$ ì„ ì”Œì›Œì„œ ì˜í–¥ë ¥ì„ ì¡°ì ˆí•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/ad090da4-8b36-4d95-85e8-eb8b43cdd43a/image.png" alt=""></p> <p>ì¦‰ ê°€ì¥ ê°€ê¹Œìš´ Q cluster ì— í•´ë‹¹í•˜ëŠ” negative sample, ì¦‰ false-negative-like sample ì˜ ì˜í–¥ë ¥ì„ ì¤„ì´ëŠ” ê²ƒì´ë‹¤. ë‹¤ìŒê³¼ ê°™ì€ ì‹ìœ¼ë¡œ weighted infoNCE loss ë¥¼ í‘œí˜„í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/4ab0665e-df97-46e3-87f7-b17c1d54a031/image.png" alt=""></p> <h4 id="group-level-discrimination">Group-level discrimination</h4> <p>ì´ ì‹ì€ 2021 CVPR ì— ì˜¬ë¼ì™”ë˜ cross-level discrimination (CLD) loss function ìœ¼ë¡œë¶€í„° ë”°ì™”ë‹¤. ì—¬ê¸°ì— auxiliary branch ë¥¼ ë¶™ì—¬ unbalanced positive/negative sample ratio ë¥¼ í•´ì†Œí•˜ë ¤ í•˜ì˜€ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/844b3d38-4281-4d55-a435-b351f64821cc/image.png" alt=""></p> <p>ë‹¤ì‹œ ìœ„ ê·¸ë¦¼ì—ì„œ, ì´ë²ˆì—” g1 MLP head ë¥¼ ë³´ì. hp ì™€ hq ëŠ” ë‹¤ì‹œ g1 ì„ ê±°ì³ gp1, gp2 vector ë¥¼ ìƒì„±í•œë‹¤. mini-batch ë‚´ì— ìˆëŠ” embedding ë“¤ì€ ê° ë‘ branch ì—ì„œ Sê°œì˜ cluster ë¡œ clustering ë˜ê³ , ê°ê°ì˜ cluster centroid ë„ í• ë‹¹í•œë‹¤. ì´ë•Œ ìš” cluster centroid ë¥¼ ì´ìš©í•´ì„œ ë‹¤ì‹œ positive negative sample ì„ branch ì—ì„œ ì •ì˜í•˜ê³  group-level InfoNCE loss ë¥¼ ê³„ì‚°í•˜ê²Œ ëœë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, g__p__1 (p branchì´ë‹¤) ì´ ìˆì„ ë•Œ, ì´ê²ƒì˜ positive sample ì€ Sê°œì˜ cluster ì¤‘ ê°€ì¥ ê°€ê¹Œìš´ 1ê°œì˜ cluster centroid ($S^{q+}$, q branch ì„) ì˜ sample ì´ ë˜ëŠ” ê²ƒì´ê³ , ë‚˜ë¨¸ì§€ S-1 cluster ëŠ” negative sample ì´ ëœë‹¤. ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/ffbd62fb-16c7-452a-8aca-03cf5a6704c5/image.png" alt=""></p> <p>Group-level infoNCE loss ì™€ ìœ„ì—ì„œ ê³„ì‚°í–ˆë˜ weighted InfoNCE loss ì˜ combination ìœ¼ë¡œ final loss ë¥¼ ê¼ì‚°í•˜ê³  update í•œë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/96ffeeee-4f92-45bd-bf75-19b07bcc5da7/image.png" alt=""></p> <h3 id="wsi-retrieval-method">WSI retrieval method</h3> <h4 id="preliminary-of-wsi-retrieval">Preliminary of WSI retrieval</h4> <p>WSI retrievalì˜ background ë¥¼ ì•Œë ¤ì£¼ê³  ìˆê¸´ í•œë° ìš°ì„  ë‚˜ëŠ” WSI retrieval ì´ ë¬´ì—‡ì¸ì§€ë„ ì˜ ëª°ëë‹¤. retrievalì€ ëŒ€ëµ &quot;ê²€ìƒ‰&quot; ì´ë¼ëŠ” ëœ»ì„ ê°€ì§€ê³  ìˆëŠ”ë°, ë‹¤ë¥¸ reference ë…¼ë¬¸ì„ íƒ€ê³  ë“¤ì–´ê°€ë³´ë‹ˆ, ë‹¤ìŒê³¼ ê°™ì€ ì‘ì—…ì„ ê°€ë¦¬í‚¤ëŠ” ê²ƒ ê°™ì•˜ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/0494bd6e-856c-41f8-a16d-49af3961d668/image.png" alt=""></p> <p>ê²°êµ­ feature extraction ì„ ì˜ ìˆ˜í–‰í•˜ê³ , similarity ê³„ì‚°ì„ ì˜ ìˆ˜í–‰í•´ì„œ WSI ë‚´ì—ì„œ ë¹ ë¥´ê²Œ ì˜ ì°¾ì•„ë‚´ëŠ” ê²ƒì´ task ì˜ í•µì‹¬ì´ë¼ê³  ìƒê°í•˜ë©´ ë  ê²ƒ ê°™ë‹¤. ë‘ê°€ì§€ ë°©ì‹ì„ ì†Œê°œí•˜ê³  ìˆë‹¤. </p> <ul> <li>Yottixel method (Y)</li> <li>FISH</li> </ul> <p>ê³µí†µì ìœ¼ë¡œ ë‘ ë°©ì‹ì€ WSI ë¥¼ patch ë¡œ ë‚˜ëˆ„ê³  clustering ì„ í•œ í›„ query ì—ì„œ patch-by-patch matching í›„ database ì—ì„œ ê°€ì¥ ë¹„ìŠ·í•œ patch ë¥¼ ì„ ì •í•œë‹¤ê³  í•œë‹¤. ì´ ë•Œ Y ëŠ” pretrained DenseNet ìœ¼ë¡œ featureë¥¼ ë½‘ê³ , ì´ë¥¼ binary code ë¡œ compression í•˜ëŠ” ë°˜ë©´, FISH ëŠ” VQ-VAE pretrained on TCGA ë¡œ generate texture feature í•œë‹¤. ë˜í•œ Y ëŠ” false match ë¥¼ ì¤„ì´ê¸° ìœ„í•´ Hamming distance ë¥¼ ê³„ì‚°í•˜ê³ , FISH ëŠ” Van Emde Boas tree with an uncertainty-based ranking algorithm ì„ ì‚¬ìš©í•œë‹¤ê³  í•œë‹¤.</p> <h4 id="proposed-wsi-retrieval-method">Proposed WSI retrieval method</h4> <p>overall procedure ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. í¬ê²Œ offline database construction, online WSI query process ë‘ê°€ì§€ë¡œ ë‚˜ë‰œë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/7ada49e8-5f46-46e8-b6e9-5b683506ee86/image.png" alt=""></p> <h4 id="database-construction-for-wsi-retrieval">Database Construction for WSI Retrieval</h4> <p>offline database construction ì—ì„œ ë¨¼ì € patchify í•˜ê³  CCL-based feature extractor ë¥¼ ê±°ì³ ë‚˜ì˜¨ feature ë¡œ mosaic generation ì„ í•˜ëŠ”ë°, mosaic generation ì€ dual clustering ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤. ë¨¼ì € CCL-feature-based K-means clustering ì„ ìˆ˜í–‰í•˜ê³ , ê·¸ coordinate ë¥¼ ë°›ì•„ spatial-coordinate-based clustering algorithm ì„ ìˆ˜í–‰í•œë‹¤. ê·¸ ê²°ê³¼ distinctive patches (called a mosaic) ì´ ìƒì„±ë˜ê³  full WSI ë¥¼ ëŒ€í‘œí•˜ê²Œ ë˜ëŠ” ê²ƒì´ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/730be0ef-a675-4d6a-b2ee-75a975a8f0b5/image.png" alt=""></p> <p>ì—­ì‹œ ë§ë³´ë‹¨ ì•Œê³ ë¦¬ì¦˜ì´ì§€. FeatureKMeans í•¨ìˆ˜ë¡œ K1 ê°œì˜ cluster ë¡œ ë‚˜ëˆˆ ë’¤, ì´ë¥¼ SpatialKMeans ë¥¼ ê±°ì³ ë‹¤ì‹œ ê° cluster ë¥¼ 4-5ê°œì˜ cluster ë¡œ ë‚˜ëˆˆë‹¤. ì¦‰, 4-5ê°œ * K1 ê°œì˜ cluster centroid ê°€ ìƒê¸°ê³  ì´ê²ƒì´ distinctive patch ê°€ ë˜ëŠ” ê²ƒì´ë‹¤. </p> <h4 id="wsi-query-process">WSI Query Process</h4> <p>WSI database construction ì´ ì™„ë£Œë˜ê³ , online ìœ¼ë¡œ patch-level retrieval ì„ ì‹œì‘í•œë‹¤. nearest neighbor searching method ë¥¼ ì‚¬ìš©í•˜ê³ , ì´ retrieved patch ì™€ meta-information ìœ¼ë¡œ ranking and aggregation algorithm ì„ í™œìš©í•´ ê°€ì¥ ë¹„ìŠ·í•œ WSI ë¥¼ ì°¾ì•„ì¤€ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/e0a9cd48-1639-4c0e-b0e4-a671c699743a/image.png" alt=""></p> <p>ì´ ë¶€ë¶„ë„ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë³´ëŠ”ê²Œ ì´í•´ê°€ ì˜ëœë‹¤. WSI image query ë¥¼ ë°›ìœ¼ë©´, ê° patch k ê°œì— ëŒ€í•´ feature vector ë¥¼ ì–»ê³ , ì´ì— ëŒ€í•œ retrieval bag ì„ kê°œ ì–»ëŠ”ë‹¤. bag 1ê°œ ë‹¹ t ê°œì˜ retrieved patch ê°€ ìˆëŠ”ë° bag ë§ˆë‹¤ ë‹¤ë¥´ë‹¤ê³  í•œë‹¤. bag 1ê°œì˜ retrieved patch ì™€ WSI ì˜ patch ì‚¬ì´ì˜ cosine similarity d ë¥¼ êµ¬í•˜ê³ , ì´ d ì™€ diagnosis ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ probability pm ì„ ê³„ì‚°í•œë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/783a7b23-8571-4c3d-aec2-d732f4789b7c/image.png" alt=""></p> <p>ì´ pm ì€ ê²°êµ­ ìš”ì•½í•´ì„œ ë§í•˜ë©´, bag ì•ˆì—ì„œ më²ˆì§¸ diagnosis type ì˜ í™•ë¥ ì´ë‹¤. yj ëŠ” database ë¡œë¶€í„° ë‚˜ì˜¨ diagnosis information (bag ì˜ ì •ë³´) ì´ë‹¤. $\delta()$ ëŠ” ë‘ ê°œì˜ input ì´ ê°™ìœ¼ë©´ 1 ì„ ë±‰ê³  ë‹¤ë¥´ë©´ 0ì„ ë±‰ëŠ” ì¼ì¢…ì˜ indicator function ì´ë‹¤. $w_{y_j}$ ëŠ” occurrence frequency (normalized probability) ì¸ë°, ì´ê²ƒë„ ì—­ì‹œ jth diagnosis type ì´ ì–¼ë§ˆë‚˜ database ì— ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. $(d^j +1)/2$ ëŠ” [-1,1] ì¸ cosine similarity ì˜ range ë¥¼ [0,1] ë¡œ transform í•´ì¤€ ê²ƒì´ë‹¤. ê°„ë‹¨íˆ ìƒê°í•´ì„œ $w_{y_j}(d^j +1)/2$ ìì²´ë¥¼ j ë²ˆì§¸ sample ì— ëŒ€í•œ score ë¼ê³  ì¹˜í™˜í•´ì„œ ìƒê°í•˜ë©´ ëœë‹¤. ê·¸ëŸ¼ ì‹ ìì²´ëŠ” ì „ì²´ score ì˜ í•© ì¤‘ì—ì„œ, m ë²ˆì§¸ diagnosis subtype ì— í¬í•¨ëœ score ì˜ í•©ì´ ë˜ì–´ m ë²ˆì§¸ diagnosis type ì˜ í™•ë¥ ë¡œ ì—¬ê¸¸ ìˆ˜ ìˆë‹¤. </p> <p>ì´ pm ì„ ì´ìš©í•´ì„œ entropy ë¥¼ ê° bag ì— ëŒ€í•´ì„œ ê³„ì‚°í•˜ê³ , ranking ì¦‰ reorder í•œë‹¤. ì´í›„ procedure REMOVE BAGS WITH LOW QUALITY ì—ì„œ, AveTop function ì„ ì´ìš©í•´ì„œ criterion $\eta$ ë¥¼ êµ¬í•˜ëŠ”ë°, AveTop function ì€ ê° bag ë§ˆë‹¤ ìƒìœ„ 5ê°œì˜ cosine similarity ë¥¼ í‰ê·  ë‚¸ ê²ƒì´ë‹¤. ì´ criterion ì„ ë„˜ì§€ ëª»í•˜ëŠ” bag ë“¤ì€ remove í•œë‹¤. ì´ bag ë‚´ë¶€ì—ì„œ top 5ê°œì˜ patch ë¥¼ ê³ ë¥´ëŠ” ê²ƒìœ¼ë¡œ ë§ˆë¬´ë¦¬ê°€ ëœë‹¤. </p> <h2 id="experimental-results-and-discusions">Experimental results and discusions</h2> <h3 id="datasets">Datasets</h3> <ul> <li>TCGA</li> <li>PAIP</li> <li>UniToPatho</li> <li>TissueNet</li> <li>DiagSet-A.2.</li> </ul> <h3 id="experimental-metric">Experimental metric</h3> <p>ë‹¤ìŒ ë‘ê°€ì§€ (ë§ì´ ì“°ì¸ë‹¤ê³  í•˜ëŠ”) Acc@k (top-k accuracy) and mMV@k(majority vote at the top k search results) ë¥¼ ì¼ë‹¤.</p> <ul> <li>Acc@k: retrieved similar image ê°€ query imageì™€ correct label ì´ë©´ ë†’ê²Œ ì¸¡ì •</li> <li>mMV@k: more strict metric, majority ê°€ query image ì™€ correct label ì´ì–´ì•¼ ë†’ê²Œ ì¸¡ì •</li> </ul> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/819d0682-b40a-4a07-a9a6-569f7408fb84/image.png" alt=""></p> <h3 id="results-of-patch-level-retrieval">Results of patch-level retrieval</h3> <h4 id="effect-of-network-components">Effect of network components</h4> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/b98e5516-2a70-49f5-8e06-cd6047a9b167/image.png" alt=""></p> <p>key innovation ì¸ clustering-based memory bank construction (Mem) ì„ ì¶”ê°€í–ˆì„ ë•Œì™€ group-level InfoNCE (Gro) ë¥¼ ì¶”ê°€í–ˆì„ ë•Œ baseline ë³´ë‹¤ ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆê³  ê°™ì´ í˜¼í•©í•´ì„œ ì‚¬ìš©í–ˆì„ ë•Œ ê°€ì¥ ë†’ì•˜ë‹¤. </p> <p>ì´ì™¸ì—ë„ ë‹¤ì–‘í•œ hyperparameter ë° setting ì— ëŒ€í•œ abltation study ë¥¼ ì§„í–‰í–ˆê³ , ë…¼ë¬¸ì— ìì„¸íˆ ì–¸ê¸‰ë˜ì–´ ìˆë‹¤.</p> <h4 id="comparison-between-our-ccl-and-other-ssl-based-feature-extractors">Comparison between our CCL and other SSL-based feature extractors</h4> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/75c28ab2-5186-41de-b1e6-90132ecaaa99/image.png" alt=""></p> <p>SimCLR v1, SwAV, Moco v2 ê³¼ CCL-based feature extractor ì˜ retrieval ì„±ëŠ¥ì„ ë¹„êµí–ˆë‹¤. ì„±ëŠ¥ë©´ì—ì„œ ì¸¡ì •í•œ ëª¨ë“  metric ì— ëŒ€í•´ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤¬ê³ , íŠ¹íˆ ê°€ì¥ strict í•œ metric ì¸ mMV ì—ì„œì˜ ì„±ëŠ¥ í–¥ìƒì´ ì»¸ë‹¤. </p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/e58dc0a2-9b0a-4a79-abfc-99dcd2f7093e/image.png" alt=""></p> <p>UniToPatho (normal, hyperplastic polyp, tubular adenoma, tubulo-villous adenoma) ì—ì„œ ê° subtype ì„ nice í•˜ê²Œ ì˜ ì°¾ì€ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. ë˜í•œ TissueNetì˜ ê²°ê³¼ë¥¼ ë´¤ì„ ë•Œ, texture ì™€ color ê°€ ë§ì´ ë‹¤ë¦„ì—ë„ ì˜ ì°¾ì€ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. ê·¸ ì•„ë˜ failed case ê°€ ì†Œê°œ ë˜ì–´ ìˆëŠ”ë°, ì €ìëŠ” ì‹¤íŒ¨í–ˆìŒì—ë„ morphological feature ê°€ pathologists ê°„ì˜ disconcordance ë¥¼ ì•¼ê¸°í•  ì •ë„ë¡œ êµ‰ì¥íˆ ë¹„ìŠ·í–ˆë‹¤ê³  ì£¼ì¥í•œë‹¤. </p> <h3 id="results-of-wsi-retrieval">Results of WSI retrieval</h3> <p>1) searching for anatomic sites 2) searching for cancer subtypes based on the same human site</p> <h4 id="results-of-anatomic-site-retrieval">Results of anatomic site retrieval</h4> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/888d2459-ab82-4406-a423-b856d35f3520/image.png" alt=""></p> <p>ì•ì„  Yottixel ê³¼ FISH ì—ì„œ ì‚¬ìš©í–ˆë˜ frozen and FFPE WSIs in TCGA ë¥¼ ì‚¬ìš©í•´ì„œ ì„±ëŠ¥ ì¸¡ì •ì´ ì´ë£¨ì–´ì¡Œë‹¤. ë‹¹ì—°í•˜ê²Œë„ database ëŠ” ëª¨ë“ ê²Œ í¬í•¨ëœ database ê°€ ì•„ë‹ˆë¼ TCGA 3ë§Œì¥ (FFPE 11791, frozen 15237) ì´ í¬í•¨ëœ database ì—ì„œ ì§„í–‰í–ˆë‹¤ê³  í•œë‹¤. ê²°ê³¼ 20% ë„˜ëŠ” ì„±ëŠ¥í–¥ìƒê¹Œì§€ ë³´ì—¬ì£¼ì—ˆë‹¤.</p> <h4 id="results-of-cancer-subtype-retrieval">Results of cancer subtype retrieval</h4> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/2c5efbfe-e6e7-41cf-9cb1-388c0d435c29/image.png" alt=""></p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/9e58c2f9-8926-4a95-83b6-7ee3397342ab/image.png" alt=""></p> <p>ê° frozen ê³¼ FFPE WSI ì— ëŒ€í•´ì„œ +10% than Yottixel and +3% than FIST in FFPE, +40% improvement on specific subtype such as MESO ë“± í° ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ë‹¤.</p> <h4 id="interpretability-analysis">Interpretability analysis</h4> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/fdac3fd9-b09c-4668-9b3a-cd97c84734fe/image.png" alt=""></p> <h3 id="results-of-downstream-classification-task">Results of downstream classification task</h3> <p>ì œì•ˆí•œ SSL pre-trained feature extractor ê°€ ë‹¤ë¥¸ downstream task ì—ì„œë„ ìœ ìš©í•˜ê²Œ ì‚¬ìš©ë  ìˆ˜ ìˆìŒì„ ë³´ì˜€ë‹¤.</p> <p><img src="https://velog.velcdn.com/images/jaeheon-lee/post/6a239abf-7f35-4c5c-989a-c7ad34032635/image.png" alt=""></p> <p>DiagSet-A.2 dataset ì—ì„œ four-class classification task ë¥¼ ì§„í–‰í–ˆê³  ê·¸ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚´ì—ˆë‹¤. highest ë¥¼ ë³´ì˜€ë˜ SwAV ë³´ë‹¤ë„ ì„±ëŠ¥ì´ ë†’ê²Œ ì¸¡ì •ë˜ì—ˆê³ , 20% ë°ì´í„°ë¥¼ training ì— ì‚¬ìš©í–ˆì„ ë•Œ ImageNet ì´ 100% ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ (supervised learning setting) ë³´ë‹¤ ì„±ëŠ¥ì´ ë†’ê²Œ ì¸¡ì •ë˜ì–´, SSL ë°©ì‹ì˜ íš¨ìš©ì„±ì„ ë³´ì˜€ë‹¤. </p> <h2 id="conclusion">Conclusion</h2> <p>WSI-level, patch-level ì—ì„œ ì‚¬ìš©ê°€ëŠ¥í•œ histopathological image retrieval algorithm ì„ ì œì•ˆí–ˆê³ , visually interpretable result ë¥¼ ë³´ì—¬ì£¼ì—ˆë‹¤. CCL-based backbone model ì„ ìƒˆë¡œ ê³ ì•ˆí–ˆìœ¼ë©°, database construction í›„ ranking, curation, and aggregation ì´ í¬í•¨ëœ retrieval algorithm ì„ ì‚¬ìš©í–ˆë‹¤. ì´ëŠ” current WSI retrieval methodì—ì„œ ë³´ì—¬ì£¼ëŠ” ì„±ëŠ¥ì„ í° í­ìœ¼ë¡œ ë›°ì–´ë„˜ì—ˆê³  feature ëŠ” ë‹¤ë¥¸ downstream task ì—ì„œ ì‚¬ìš©ë  ìˆ˜ ìˆì„ë§Œí¼ì˜ potential ì„ ë³´ì—¬ì£¼ì—ˆë‹¤. </p> <p>ì™€ ì§„ì§œ ì‹¤í—˜í•˜ëŠë¼ í˜ë“¤ì—ˆê² ë‹¤</p> </p> <p class="post-meta"> 1 min read &nbsp; &middot; &nbsp; May 19, 2023 &nbsp; &middot; &nbsp; jaeheon-lee </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p></li> </ul> <nav aria-label="Blog page naviation"> <ul class="pagination pagination-lg justify-content-center"> <li class="page-item disabled"> <a class="page-link" href="" tabindex="-1" aria-disabled="">Newer</a> </li><li class="page-item active"><a class="page-link" href="/blog/index.html" title="blog">1</a></li> <li class="page-item "><a class="page-link" href="/blog/page/2/index.html" title="blog - page 2">2</a></li> <li class="page-item "><a class="page-link" href="/blog/page/3/index.html" title="blog - page 3">3</a></li> <li class="page-item "><a class="page-link" href="/blog/page/4/index.html" title="blog - page 4">4</a></li> <li class="page-item "><a class="page-link" href="/blog/page/5/index.html" title="blog - page 5">5</a></li> <li class="page-item "> <a class="page-link" href="/blog/page/2/">Older</a> </li> </ul> </nav> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> &copy; Copyright 2023 JaeHeon Lee. Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>